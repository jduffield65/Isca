{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Shaw 2023\n",
    "This looks at high percentiles of upper troposphere (200hPa) zonal wind, to see how they vary with warming. Shaw 2023 indicated that the fastest winds increase the most."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import copy\n",
    "import sys\n",
    "import os\n",
    "# REMOTE - So can access functions in isca_tools which is in home/Isca directory\n",
    "# sys.path.append(os.path.join(os.environ['HOME'], 'Isca'))\n",
    "# LOCAL - So can access functions in isca_tools which is in StAndrews/Isca\n",
    "sys.path.append(os.environ['PWD'])\n",
    "import isca_tools\n",
    "from isca_tools.convection import lapse_moist, equivalent_potential_temp\n",
    "from isca_tools.utils.moist_physics import moist_static_energy, clausius_clapeyron_factor, sphum_sat\n",
    "from isca_tools.utils.constants import L_v, c_p, R, radius_earth, rot_earth, g\n",
    "from isca_tools.utils import area_weighting\n",
    "from isca_tools.papers.byrne_2021 import get_quant_ind\n",
    "from isca_tools.utils.calculus import grad_x, grad_y\n",
    "from isca_tools.thesis.aquaplanet_theory import get_delta_temp_quant_theory, get_gamma\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import scipy.optimize\n",
    "from tqdm import tqdm\n",
    "from scipy import integrate\n",
    "import numpy_indexed\n",
    "from scipy.stats import percentileofscore\n",
    "import copy\n",
    "# Use custom matplotlib style for publishing\n",
    "plt.style.use('/Users/joshduffield/Documents/StAndrews/Isca/jobs/tau_sweep/aquaplanet/publish_figures/publish.mplstyle')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:40:45.722197Z",
     "start_time": "2024-03-25T15:40:41.233568Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Load dataset - one at surface and one in free troposphere\n",
    "var_keep = ['temp', 'ucomp', 'height', 'vcomp', 'ps', 'sphum']        # only keep variables required to compute relative humidity and MSE\n",
    "# Load dataset\n",
    "tau_lw_ref = 1\n",
    "tau_lw_warm = 1.5\n",
    "# exp_dir = 'tau_sweep/aquaplanet/'\n",
    "exp_dir = 'aquaplanet/vary_depth/depth=1/'\n",
    "exp_names = [f\"k={str(tau_lw_ref).replace('.','_')}\", f\"k={str(tau_lw_warm).replace('.','_')}\"]\n",
    "n_exp = len(exp_names)\n",
    "ds = []\n",
    "albedo = []\n",
    "tau_sw = []\n",
    "tau_lw = []\n",
    "for i in range(n_exp):\n",
    "    ds_use = isca_tools.load_dataset(exp_dir + exp_names[i])[var_keep]\n",
    "    ds += [ds_use]      # only keep the surface values\n",
    "    namelist = isca_tools.load_namelist(exp_dir + exp_names[i])  # Need this for albedo_value\n",
    "    albedo += [namelist['mixed_layer_nml']['albedo_value']]\n",
    "    tau_sw += [namelist['two_stream_gray_rad_nml']['atm_abs']]\n",
    "    tau_lw += [namelist['two_stream_gray_rad_nml']['odp']]\n",
    "sigma_levels = np.asarray(namelist['vert_coordinate_nml']['bk'])         # make first value the surface\n",
    "# Sigma levels are at half pressure levels, so need to convolve to get pressure at full pressure levels.\n",
    "sigma_levels = np.convolve(sigma_levels, np.ones(2)/2, 'valid')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:40:50.346174Z",
     "start_time": "2024-03-25T15:40:45.724252Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get datasets\n",
    "Get one surface dataset for summer for each $\\kappa$, combining all latitudes: `ds_all`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# If true, will save all figures to desktop - option to save specific figures later on.\n",
    "save_fig = False\n",
    "# if publishing figure, use high dpi\n",
    "publish_fig = True\n",
    "\n",
    "ar = 4/3        # aspect ratio (width/height)\n",
    "# Details required for Journal of Climate Figures\n",
    "low_dpi = 100\n",
    "dpi = {'monochrome': 1100, 'combination': 800, 'halftone': 300}\n",
    "width = {'one_col': 3.2, 'two_col': 5.5}        # width in inches \n",
    "save_pad_inches = 0.05\n",
    "\n",
    "# Default parameters\n",
    "default_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "ax_linewidth = plt.rcParams['axes.linewidth']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:40:50.349367Z",
     "start_time": "2024-03-25T15:40:50.346798Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Load in dataset with surface and free troposphere across all latitudes, for given season\n",
    "pressure_ft = 500           # Desired approximate pressure of free troposphere (hPa)\n",
    "pressure_ft_ind = int(np.abs(ds[0].pfull-pressure_ft).argmin())\n",
    "use_time_start = 360*2\n",
    "\n",
    "# Chose whether to only consider summer days or consider all days\n",
    "summer_months = {'nh': [6, 7, 8], 'sh': [12, 1, 2]}   # JJA for NH and DJF for SH\n",
    "\n",
    "def get_summer_ds(dataset):\n",
    "    ds_nh_summer = isca_tools.utils.annual_time_slice(dataset, summer_months['nh']).sel(lat=slice(0, 90))  \n",
    "    ds_sh_summer = isca_tools.utils.annual_time_slice(dataset, summer_months['sh']).sel(lat=slice(-90, 0)) \n",
    "    # Combine hemispheres and average over longitude, time and latitude.\n",
    "    return xr.concat([ds_sh_summer, ds_nh_summer], dim='lat')\n",
    "\n",
    "# season = 'all'\n",
    "season = 'summer'   # NOTE - if summer, does not give many days corresponding to high percentiles as only 5 years of data used\n",
    "\n",
    "# Use zhang definition of extratropics\n",
    "# lat_min = 0\n",
    "# lat_max = 20\n",
    "lat_min = 40\n",
    "lat_max = 65\n",
    "# lat_min = 80\n",
    "# lat_max = 88\n",
    "\n",
    "ds_all = []\n",
    "ds_z_ft = []         # keep 'lon' and 'time' separate for z at ft level so can compute gradient\n",
    "# ds_sigma_correction = []        # need pressure levels either side of p_ft to compute gradient wrt pressure\n",
    "with tqdm(total=n_exp, position=0, leave=True) as pbar:\n",
    "    for i in range(n_exp):\n",
    "        # ds_use = ds[i].sel(pfull=[np.inf, pressure_ft], method='nearest').sel(time=slice(use_time_start, np.inf))\n",
    "        # Keep all latitudes, so can do geostrophic wind calc without large gap between hemispheres\n",
    "        ds_use = ds[i].sel(time=slice(use_time_start, np.inf))    \n",
    "        # ds_sigma_correction += [ds_use.isel(pfull=[pressure_ft_ind-1, pressure_ft_ind, pressure_ft_ind+1]\n",
    "        #                                     ).stack(lon_time=(\"lon\",\"time\"), \n",
    "        #                                             create_index=False).chunk(dict(lon_time=-1))[['vcomp', 'height', 'temp', 'ucomp']].load()]\n",
    "        ds_use = ds_use.sel(pfull=[pressure_ft, np.inf], method='nearest')\n",
    "        ds_z_ft += [ds_use.height.isel(pfull=0).transpose('lat', 'lon', 'time').load()]     # make time the last index\n",
    "        \n",
    "        ds_use = ds_use.where((np.abs(ds_use.lat) <= lat_max) & (np.abs(ds_use.lat) >= lat_min), drop=True)\n",
    "        if season == 'summer':\n",
    "            ds_use = get_summer_ds(ds_use)\n",
    "        ds_use = ds_use.stack(lon_time=(\"lon\",\"time\"), create_index=False).chunk(dict(lon_time=-1))\n",
    "        ds_all += [ds_use.load()]\n",
    "        pbar.update(1)\n",
    "p_surface = float(ds_all[0].pfull[1]) * 100\n",
    "pressure_ft_actual = float(ds_all[0].pfull[0]) * 100       # Actual pressure of free troposphere (Pa)\n",
    "sigma_level_ft = sigma_levels[pressure_ft_ind]\n",
    "# sigma_levels_use = sigma_levels[:len(ds_all[0].pfull)]      # Not all sigma levels are kept\n",
    "\n",
    "n_lat = ds_all[0].lat.shape[0]\n",
    "lat_weights = np.cos(np.deg2rad(ds_all[0].lat))     # latitude area weighting is just the cosine\n",
    "lat_keep_ind = np.where((np.abs(ds_z_ft[0].lat) <= lat_max) & (np.abs(ds_z_ft[0].lat) >= lat_min))[0]\n",
    "# Only keep used latitudes for sigma correction\n",
    "# ds_sigma_correction = [ds_sigma_correction[i].isel(lat=lat_keep_ind) for i in range(n_exp)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:41:12.376251Z",
     "start_time": "2024-03-25T15:40:50.350716Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Check Equation 7 of Zhang 2023\n",
    "In the paper, it suggests we can approximate $z_{500} \\approx \\frac{\\overline{z_{500}}}{\\overline{T_{500}}}T_{500}$. Below I show that this seems reasonable for both $\\kappa=1$ and the $\\kappa=1.5$ simulations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "z_ft_mean = [float(area_weighting(ds_all[i].height[0]).mean()) for i in range(n_exp)]\n",
    "temp_ft_mean = [float(area_weighting(ds_all[i].temp[0]).mean()) for i in range(n_exp)]\n",
    "\n",
    "temp_bins = np.linspace(ds_all[0].temp[0].min(), ds_all[1].temp[0].max(), 30)\n",
    "z_bins = np.linspace(ds_all[0].height[0].min(), ds_all[1].height[0].max(), 30)\n",
    "z_hist = [np.histogram2d(ds_all[i].temp[0].to_numpy().flatten(), ds_all[i].height[0].to_numpy().flatten(), \n",
    "                         bins=[temp_bins, z_bins])[0] for i in range(n_exp)]\n",
    "# Check that z_ft vs temp_ft relationship is approximately valid\n",
    "temp_ft_array = np.arange(200, 300)\n",
    "\n",
    "save_z_t_hist_fig = False\n",
    "fig, ax = plt.subplots(2,1, figsize=(width['one_col'], 2 * width['one_col']/ar), sharex=True, sharey=True)\n",
    "for i in range(n_exp):\n",
    "    im = ax[i].imshow(z_hist[i].T/z_hist[i].sum(), origin='lower', aspect='auto', \n",
    "                      extent=[temp_bins[0], temp_bins[-1], z_bins[0], z_bins[-1]], vmin=0, vmax=0.05)\n",
    "    ax[i].plot(temp_ft_array, (z_ft_mean[i]/temp_ft_mean[i] * temp_ft_array), color='w', linestyle=':',\n",
    "            label='$\\\\frac{\\overline{z_{500}}}{\\overline{T_{500}}} T_{500}$')\n",
    "    ax[i].set_title(f'$\\kappa={tau_lw[i]}$')\n",
    "    fig.colorbar(im)\n",
    "fig.supylabel(f\"$z_{'{'+str(pressure_ft)+'}'}$ / m\", fontsize=7)\n",
    "ax[-1].set_xlabel(f\"$T_{'{'+str(pressure_ft)+'}'}$ / K\")\n",
    "ax[0].legend(labelcolor='w')\n",
    "ax[0].set_xlim(temp_bins[0], temp_bins[-1])\n",
    "ax[0].set_ylim(z_bins[0], z_bins[-1])\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_fig or save_z_t_hist_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/z_t_hist.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:41:13.082177Z",
     "start_time": "2024-03-25T15:41:12.377184Z"
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below, I look at the difference between the simulations to see if $\\delta z_{500} \\approx \\frac{\\delta \\overline{z_{500}}}{\\delta \\overline{T_{500}}}\\delta T_{500}$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "z_ft_diff_mean = float(area_weighting(ds_all[1].height[0]-ds_all[0].height[0]).mean())\n",
    "temp_ft_diff_mean = float(area_weighting(ds_all[1].temp[0]-ds_all[0].temp[0]).mean())\n",
    "\n",
    "temp_diff_bins = np.linspace((ds_all[1].temp[0] - ds_all[0].temp[0]).min(), (ds_all[1].temp[0] - ds_all[0].temp[0]).max(), 30)\n",
    "z_diff_bins = np.linspace((ds_all[1].height[0] - ds_all[0].height[0]).min(), (ds_all[1].height[0] - ds_all[0].height[0]).max(), 30)\n",
    "\n",
    "z_diff_hist = np.histogram2d((ds_all[1].temp[0] - ds_all[0].temp[0]).to_numpy().flatten(), \n",
    "                             (ds_all[1].height[0] - ds_all[0].height[0]).to_numpy().flatten(), bins=[temp_diff_bins, z_diff_bins])[0]\n",
    "temp_ft_diff_array = np.arange(-50, 50)\n",
    "\n",
    "save_z_t_diff_hist_fig = False\n",
    "fig, ax = plt.subplots(1,1, figsize=(width['one_col'], width['one_col']/ar))\n",
    "im = ax.imshow(z_diff_hist.T/z_diff_hist.sum(), origin='lower', aspect='auto', \n",
    "               extent=[temp_diff_bins[0], temp_diff_bins[-1], z_diff_bins[0], z_diff_bins[-1]], vmin=0, vmax=0.06)\n",
    "ax.plot(temp_ft_diff_array, (z_ft_diff_mean/temp_ft_diff_mean * temp_ft_diff_array), color='w', linestyle=':',\n",
    "            label='$\\\\frac{\\delta \\overline{z_{500}}}{\\delta \\overline{T_{500}}} \\delta T_{500}$')\n",
    "ax.set_xlim(temp_diff_bins[0], temp_diff_bins[-1])\n",
    "ax.set_ylim(z_diff_bins[0], z_diff_bins[-1])\n",
    "ax.legend(labelcolor='w')\n",
    "ax.set_ylabel(f\"$\\delta z_{'{'+str(pressure_ft)+'}'}$ / m\", fontsize=7)\n",
    "ax.set_xlabel(f\"$\\delta T_{'{'+str(pressure_ft)+'}'}$ / K\")\n",
    "ax.set_title(f'$(\\kappa={tau_lw[1]}) - (\\kappa={tau_lw[0]})$')\n",
    "fig.colorbar(im)\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_fig or save_z_t_diff_hist_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/z_t_diff_hist.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:41:13.434987Z",
     "start_time": "2024-03-25T15:41:13.082952Z"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check as function of percentile\n",
    "Below I check the relationship between $\\delta z_{500}(x)$ vs $\\delta T_{500}(x)$ where $x$ is near-surface temperature percentile. The approximation seems to do a decent job at predicting the magnitude of $\\delta z_{500}(x)$ but not the trend with $x$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Sanity check that way of reshaping ds_z_ft is consitent with lon_time coordinate\n",
    "if season == 'summer':\n",
    "    print(float(np.abs(get_summer_ds(ds_z_ft[0]).isel(lat=lat_keep_ind).to_numpy().reshape(n_lat, -1) - ds_all[0].height[0]).max()))\n",
    "else:\n",
    "    print(float(np.abs(ds_z_ft[0].isel(lat=lat_keep_ind).to_numpy().reshape(n_lat, -1) - ds_all[0].height[0]).max()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:41:13.587279Z",
     "start_time": "2024-03-25T15:41:13.435714Z"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_geostrophic_wind(z_height, lat, lon, lat_axis=-2, lon_axis=-1):\n",
    "    \"\"\"\n",
    "    Returns the geostrophic approximation for the zonal and meridional wind at \n",
    "    a given sigma level in the atmosphere.\n",
    "    \n",
    "    Args:\n",
    "        z_height: [n_lat x n_lon x n_time]\n",
    "            Geopotential height in m at a given sigma level.\n",
    "        lat: [n_lat] in deg\n",
    "        lon: [n_lon] in deg\n",
    "\n",
    "    Returns:\n",
    "        u_geo: [n_lat x n_lon x n_time]\n",
    "        v_geo: [n_lat x n_lon x n_time]\n",
    "    \"\"\"\n",
    "    z_shape = np.ones(len(z_height.shape), dtype=int)\n",
    "    z_shape[lat_axis] = len(lat)\n",
    "    f_coriolis = 2 * rot_earth * np.sin(np.deg2rad(lat).to_numpy()).reshape(z_shape)\n",
    "    return -(g/f_coriolis) * grad_y(z_height, lat, lat_axis), (g/f_coriolis) * grad_x(z_height, lat, lon, lat_axis, lon_axis), "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:41:13.591380Z",
     "start_time": "2024-03-25T15:41:13.588351Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Get all data needed to compute theoretical temp change and to plot actual temp change for each quantile of temperature\n",
    "quant_plot = np.arange(1, 100)     # avoid 0 quantile as it gives weird results\n",
    "n_quant = len(quant_plot)\n",
    "\n",
    "take_abs_v = True       # whether to consider speed or velocity of winds\n",
    "if take_abs_v:\n",
    "    v_func = lambda x: np.abs(x) \n",
    "else:\n",
    "    v_func = lambda x: x\n",
    "    \n",
    "take_abs_u = True       # whether to consider speed or velocity of winds\n",
    "if take_abs_u:\n",
    "    u_func = lambda x: np.abs(x) \n",
    "else:\n",
    "    u_func = lambda x: x\n",
    "\n",
    "temp_mean = np.zeros((n_exp, 2, n_lat))         # second index: 0 is free trop, 1 is surface\n",
    "z_mean = np.zeros((n_exp, n_lat))\n",
    "lapse_mean = np.zeros((n_exp, n_lat))\n",
    "\n",
    "# quant2 is the actual quantile value rather than the average above a given quantile\n",
    "temp_quant3 = np.zeros((n_exp, 2, n_lat, n_quant))\n",
    "# upper troposphere geopotential height as function of T percentile\n",
    "z_quant3 = np.zeros((n_exp, n_lat, n_quant))\n",
    "z_quant3_diff = np.zeros((n_exp, n_lat, n_quant))       # difference between quant3 and mean at that latitude.\n",
    "# upper troposphere zonal wind as function of temperature percentile\n",
    "# u_quant3 = np.zeros((n_exp, n_lat, n_quant))\n",
    "# upper troposphere meridional wind as function of temperature percentile\n",
    "v_quant3 = np.zeros((n_exp, n_lat, n_quant))\n",
    "# FT geostrophic wind\n",
    "v_geo_quant3 = np.zeros((n_exp, n_lat, n_quant))\n",
    "# upper troposphere zonal wind as function of temperature percentile\n",
    "u_quant3 = np.zeros((n_exp, n_lat, n_quant))\n",
    "# FT geostrophic wind\n",
    "u_geo_quant3 = np.zeros((n_exp, n_lat, n_quant))\n",
    "# Surface pressure\n",
    "p_surface_quant3 = np.zeros((n_exp, n_lat, n_quant))\n",
    "lapse_quant3 = np.zeros((n_exp, n_lat, n_quant))\n",
    "lapse_mse_quant3 = np.zeros((n_exp, n_lat, n_quant))\n",
    "\n",
    "ds_use = ds_z_ft[0].copy(deep=True)\n",
    "with tqdm(total=n_exp*n_quant*n_lat, position=0, leave=True) as pbar:\n",
    "    for i in range(n_exp):\n",
    "        temp_mean[i] = ds_all[i].temp.mean(dim='lon_time')       # surface temp at both pressure levels\n",
    "        z_mean[i] = ds_all[i].height[0].mean(dim='lon_time')      \n",
    "        lapse_mean[i] = -((ds_all[i].temp[0]-ds_all[i].temp[1])/(ds_all[i].height[0]-ds_all[i].height[1])).mean(dim='lon_time')\n",
    "        u_geo_use, v_geo_use = get_geostrophic_wind(ds_z_ft[i], ds_z_ft[i].lat, ds_z_ft[i].lon, lat_axis=0, lon_axis=1)\n",
    "        # Reshape so can take average on day corresponding to given quantile\n",
    "        if season == 'summer':\n",
    "            # ds_z_ft is a dataset including all latitudes and times so can compute meridional gradient.\n",
    "            # Here, I need to remove all but the summer months in each hemisphere\n",
    "            ds_use.values = u_geo_use\n",
    "            u_geo_use = get_summer_ds(ds_use).to_numpy()\n",
    "            ds_use.values = v_geo_use\n",
    "            v_geo_use = get_summer_ds(ds_use).to_numpy()\n",
    "        u_geo_use = u_geo_use[lat_keep_ind].reshape(n_lat, -1)\n",
    "        v_geo_use = v_geo_use[lat_keep_ind].reshape(n_lat, -1)\n",
    "        for k in range(n_lat):\n",
    "            for j, quant in enumerate(quant_plot):\n",
    "                use_ind = get_quant_ind(ds_all[i].temp[1, k], quant, 0.5, 0.5)\n",
    "                temp_quant3[i, :, k, j] = ds_all[i].temp[:, k, use_ind].mean(dim='lon_time', skipna=True)  \n",
    "                z_quant3[i, k, j] = ds_all[i].height[0, k, use_ind].mean(skipna=True)      \n",
    "                z_quant3_diff[i, k, j] = v_func(ds_all[i].height[0, k, use_ind]-z_mean[i,k]).mean(skipna=True)\n",
    "                v_quant3[i, k, j] = v_func(ds_all[i].vcomp[0, k, use_ind]).mean(skipna=True)    \n",
    "                v_geo_quant3[i, k, j] = v_func(v_geo_use[k, use_ind]).mean()\n",
    "                u_quant3[i, k, j] = u_func(ds_all[i].ucomp[0, k, use_ind]).mean(skipna=True)    \n",
    "                u_geo_quant3[i, k, j] = u_func(u_geo_use[k, use_ind]).mean()\n",
    "                p_surface_quant3[i, k, j] = ds_all[i].ps[k, use_ind].mean(skipna=True)   \n",
    "                lapse_quant3[i, k, j] = -((ds_all[i].temp[0]-ds_all[i].temp[1])/(ds_all[i].height[0]-ds_all[i].height[1]))[k, use_ind].mean(skipna=True)   \n",
    "                lapse_mse_quant3[i, k, j] = ((moist_static_energy(ds_all[i].temp[0],sphum_sat(ds_all[i].temp[0], pressure_ft_actual),\n",
    "                                                                  ds_all[i].height[0]) - \n",
    "                                              moist_static_energy(ds_all[i].temp[1],ds_all[i].sphum[1], ds_all[i].height[1])) /\n",
    "                                              (ds_all[i].height[0]-ds_all[i].height[1]))[k, use_ind].mean(skipna=True)   \n",
    "                pbar.update(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:44:17.456620Z",
     "start_time": "2024-03-25T15:41:13.592255Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Checking at pressure levels as well as sigma.\n",
    "Isca outputs data at $\\sigma = p/p_s$ levels. Here, I account for the variation of surface pressure, $p_s$, by obtaining the variables on a given pressure level.\n",
    "\n",
    "To find a variable, $\\Phi$, at pressure $p$ from the value at $\\sigma$, I use:\n",
    "$\\Phi(p) = \\Phi(\\sigma) + (p - \\sigma p_s)\\frac{\\partial \\Phi}{\\partial p}(\\sigma)$\n",
    "\n",
    "It doesn't appear to make much difference though."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Obtain quantile data but at pressure_ft_actual, rather than at a sigma level\n",
    "\n",
    "# # quant2 is the actual quantile value rather than the average above a given quantile\n",
    "# temp_p_quant3 = np.zeros((n_exp, n_lat, n_quant))\n",
    "# # upper troposphere geopotential height as function of T percentile\n",
    "# z_p_quant3 = np.zeros((n_exp, n_lat, n_quant))\n",
    "# # upper troposphere zonal wind as function of temperature percentile\n",
    "# # u_quant3 = np.zeros((n_exp, n_lat, n_quant))\n",
    "# # upper troposphere meridional wind as function of temperature percentile\n",
    "# v_p_quant3 = np.zeros((n_exp, n_lat, n_quant))\n",
    "# u_p_quant3 = np.zeros((n_exp, n_lat, n_quant))\n",
    "# \n",
    "# temp_p_mean = np.zeros((n_exp, n_lat)) \n",
    "# z_p_mean = np.zeros((n_exp, n_lat))\n",
    "# \n",
    "# with tqdm(total=n_exp*n_quant*n_lat, position=0, leave=True) as pbar:\n",
    "#     for i in range(n_exp):\n",
    "#         p_diff = pressure_ft_actual - sigma_level_ft * ds_all[i].ps     # difference sigma level pressure and a given pressure\n",
    "#         temp_grad = p_diff * np.gradient(ds_sigma_correction[i].temp, ds_sigma_correction[i].pfull*100, axis=0)[1]\n",
    "#         z_grad = p_diff * np.gradient(ds_sigma_correction[i].height, ds_sigma_correction[i].pfull*100, axis=0)[1]\n",
    "#         v_grad = p_diff * np.gradient(ds_sigma_correction[i].vcomp, ds_sigma_correction[i].pfull*100, axis=0)[1]\n",
    "#         u_grad = p_diff * np.gradient(ds_sigma_correction[i].ucomp, ds_sigma_correction[i].pfull*100, axis=0)[1]\n",
    "#         \n",
    "#         temp_p_mean[i] = (ds_all[i].temp[0]+temp_grad).mean(dim='lon_time')       # surface temp at both pressure levels\n",
    "#         z_p_mean[i] = (ds_all[i].height[0]+z_grad).mean(dim='lon_time')      \n",
    "#         for k in range(n_lat):\n",
    "#             for j, quant in enumerate(quant_plot):\n",
    "#                 use_ind = get_quant_ind(ds_all[i].temp[1, k], quant, 0.5, 0.5)\n",
    "#                 temp_p_quant3[i, k, j] = (ds_all[i].temp[0] + temp_grad)[k, use_ind].mean(dim='lon_time', skipna=True)  \n",
    "#                 z_p_quant3[i, k, j] = (ds_all[i].height[0] + z_grad)[k, use_ind].mean(skipna=True)      \n",
    "#                 v_p_quant3[i, k, j] = v_func((ds_all[i].vcomp[0] + v_grad)[k, use_ind]).mean(skipna=True)       \n",
    "#                 u_p_quant3[i, k, j] = u_func((ds_all[i].ucomp[0] + u_grad)[k, use_ind]).mean(skipna=True)   \n",
    "#                 pbar.update(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:44:17.462298Z",
     "start_time": "2024-03-25T15:44:17.459648Z"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## $\\kappa = z_{500}/T_{500}$\n",
    "Here, I look at the $z$ factor and how it changes with near-surface temperature percentile $x$. The factor is important for obtaining a useful equation for $\\lambda_2(x)$ and simplifying it by assuming the wind is geostrophic and stays constant with warming.\n",
    "\n",
    "The first plot below shows the computation of $\\kappa$ using three different methods.\n",
    "Equations 11 and 12 in Zhang 2023 can be combined to give the equation for $\\kappa(x)$ as:\n",
    "$$\\kappa(x) = \\frac{[1 + \\overline{\\Gamma} \\frac{\\overline{z}}{\\overline{T}}]^{\\frac{\\Gamma(x)}{\\overline{\\Gamma}}}-1}{\\Gamma(x)}$$\n",
    "where $\\Gamma=-dT/dz$ is the lapse rate.\n",
    "\n",
    "The *Fixed lapse* method assumes $\\Gamma(x) = \\overline{\\Gamma}$ so the above equation reduces to $\\kappa = \\frac{\\overline{z}}{\\overline{T}}$ and is constant for all $x$.\n",
    "\n",
    "The *Varying lapse* method computes the lapse rate for each $x$ and uses the full equation.\n",
    "\n",
    "The *Empirical* method finds $\\kappa$ through a straight line fit to $z(x)$ vs $T(x)$ using data from both simulations ($\\tau=1$ and $\\tau=1.5$). In the top plot below, I only use the data points marked with crosses ($x>30$) to compute this empirical value. Because I combine simulations, this $\\kappa$ stays constant with warming unlike the other methods. There is also an intercept, $C$, that I find empirically so $z(x)$ can be predicted empirically through: $z(x) = \\kappa T(x) + C$.\n",
    "\n",
    "In the bottom plot below, I show the difference between the $\\tau=1$ and $\\tau=1.5$ simulations in $z(x)$ and the prediction using each of the methods above i.e. $\\delta z(x) = \\kappa_{\\tau=1.5}(x)T_{\\tau=1.5}(x) - \\kappa_{\\tau=1}(x)T_{\\tau=1}(x)$. For the empirical method, this reduces to $\\delta z(x) = \\kappa\\delta T(x)$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_kappa(z_mean, temp_mean, lapse_mean, lapse_x):\n",
    "    \"\"\"\n",
    "    Returns the analytical ratio between z(x) and T(x) assuming varying lapse rate with x.\n",
    "    \n",
    "    Args:\n",
    "        z_mean: [n_lat]\n",
    "            Mean geopotential height at 500hPa for each latitude.\n",
    "        temp_mean: [n_lat]\n",
    "            Mean temperature at 500hPa for each latitude.\n",
    "        lapse_mean: [n_lat]\n",
    "            Mean lapse rate (-dT/dz) between surface and 500hPa for each latitude.\n",
    "        lapse_x: [n_lat x n_quant]\n",
    "            Lapse rate (-dT/dz) between surface and 500hPa for each latitude, conditioned on each near-surface temperature quantile x.\n",
    "    Returns:\n",
    "        [n_lat x n_quant]\n",
    "            Ratio between z(x) and T(x) for each latitude, conditioned on each near-surface temperature quantile x.\n",
    "    \"\"\"\n",
    "    z_mean = np.expand_dims(z_mean, axis=1)\n",
    "    temp_mean = np.expand_dims(temp_mean, axis=1)\n",
    "    lapse_mean = np.expand_dims(lapse_mean, axis=1)\n",
    "    return ((1+lapse_mean * (z_mean/temp_mean))**(lapse_x/lapse_mean)-1) / lapse_x\n",
    "\n",
    "kappa_lapse = np.asarray([get_kappa(z_mean[i], temp_mean[i, 0], lapse_mean[i], lapse_quant3[i]) for i in range(n_exp)])\n",
    "kappa_quant3 = np.asarray([z_quant3[i] / temp_quant3[i, 0] for i in range(n_exp)])\n",
    "kappa_mean = np.asarray([np.expand_dims(z_mean[i]/temp_mean[i, 0], axis=-1) for i in range(n_exp)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:44:17.469443Z",
     "start_time": "2024-03-25T15:44:17.462946Z"
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "kappa_quant_ind_thresh = 30         # Use all days larger than this x to fit kappa\n",
    "kappa_empirical, intercept = np.polyfit(np.concatenate([np.average(temp_quant3[0, 0], weights=lat_weights, axis=0)[kappa_quant_ind_thresh:], \n",
    "                                              np.average(temp_quant3[1, 0], weights=lat_weights, axis=0)[kappa_quant_ind_thresh:]]), \n",
    "                              np.concatenate([np.average(z_quant3[0], weights=lat_weights, axis=0)[kappa_quant_ind_thresh:], \n",
    "                                              np.average(z_quant3[1], weights=lat_weights, axis=0)[kappa_quant_ind_thresh:]]),\n",
    "                              deg=1)\n",
    "labels_kappa = ['Fixed lapse', 'Varying lapse', 'Empirical']\n",
    "linestyles_kappa = [':', '--', '-.']\n",
    "\n",
    "save_z_vs_temp_fig = False\n",
    "fig, ax = plt.subplots(2,1, figsize=(width['one_col'], 2*width['one_col']/ar))\n",
    "for i in range(n_exp):\n",
    "    ax[0].scatter(np.average(temp_quant3[i, 0], weights=lat_weights, axis=0)[kappa_quant_ind_thresh:], \n",
    "                  np.average(z_quant3[i], weights=lat_weights, axis=0)[kappa_quant_ind_thresh:], \n",
    "                  marker='x', alpha=0.2, s=50, color=default_colors[i])\n",
    "    ax[0].scatter(np.average(temp_quant3[i, 0], weights=lat_weights, axis=0)[:kappa_quant_ind_thresh], \n",
    "                  np.average(z_quant3[i], weights=lat_weights, axis=0)[:kappa_quant_ind_thresh], \n",
    "                  marker='.', alpha=0.2, s=30, color=default_colors[i])\n",
    "    ax[0].plot(np.average(temp_quant3[i, 0], weights=lat_weights, axis=0), \n",
    "              np.average(kappa_mean[i]*temp_quant3[i, 0], weights=lat_weights, axis=0), color=default_colors[i], linestyle=':')\n",
    "    ax[0].plot(np.average(temp_quant3[i, 0], weights=lat_weights, axis=0), \n",
    "          np.average(kappa_lapse[i]*temp_quant3[i, 0], weights=lat_weights, axis=0), color=default_colors[i], linestyle='--')\n",
    "ax[0].plot(np.arange(200, 300), kappa_empirical*np.arange(200, 300) + intercept, color='k', lw=ax_linewidth, linestyle='-.')\n",
    "\n",
    "ax[1].scatter(np.average(temp_quant3[1, 0]-temp_quant3[0, 0], weights=lat_weights, axis=0)[kappa_quant_ind_thresh:], \n",
    "              np.average(z_quant3[1]-z_quant3[0], weights=lat_weights, axis=0)[kappa_quant_ind_thresh:], \n",
    "              marker='x', alpha=0.2, s=50, color='k')\n",
    "ax[1].scatter(np.average(temp_quant3[1, 0]-temp_quant3[0, 0], weights=lat_weights, axis=0)[:kappa_quant_ind_thresh], \n",
    "              np.average(z_quant3[1]-z_quant3[0], weights=lat_weights, axis=0)[:kappa_quant_ind_thresh], \n",
    "              marker='.', alpha=0.2, s=30, color='k')\n",
    "for i, kappa_use in enumerate([kappa_mean, kappa_lapse, np.asarray([kappa_empirical]*n_exp)]):\n",
    "    ax[1].plot(np.average(temp_quant3[1, 0]-temp_quant3[0, 0], weights=lat_weights, axis=0), \n",
    "               np.average(kappa_use[1]*temp_quant3[1, 0]-kappa_use[0]*temp_quant3[0, 0], weights=lat_weights, axis=0), \n",
    "               color='k', lw=ax_linewidth, label=labels_kappa[i], linestyle=linestyles_kappa[i])\n",
    "ax[1].legend()\n",
    "ax[0].set_xlim(240, 275)\n",
    "ax[0].set_ylim(5400, 6050)\n",
    "ax[1].set_xlim(5.5, 8.2)\n",
    "ax[1].set_ylim(110, 165)\n",
    "ax[0].set_xlabel('$T$ [K]')\n",
    "ax[0].set_ylabel('$z$ [m]')\n",
    "ax[1].set_xlabel('$\\delta T$ [K]')\n",
    "ax[1].set_ylabel('$\\delta z$ [m]')\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_fig or save_z_vs_temp_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/z_vs_temp.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:44:17.620120Z",
     "start_time": "2024-03-25T15:44:17.470149Z"
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Comparison of $z(x)$ and $\\delta z(x)$\n",
    "Below is similar to above, but I change the x-axis to be the near-surface temperature percentile, $x$.\n",
    "\n",
    "The plots show that the *Varying lapse* method is best overall at matching the simulated thick lines. However, if we ignore the coldest days (when convection is not active), the *Empirical* method is best.\n",
    "\n",
    "In the bottom plot, for the *Fixed lapse* and *Varying lapse* methods, I plot in black the full $\\delta z(x) = \\kappa_{\\tau=1.5}(x)T_{\\tau=1.5}(x) - \\kappa_{\\tau=1}(x)T_{\\tau=1}(x)$.\n",
    "\n",
    "In grey though, I plot the sum of the linear terms in the taylor series i.e. $\\delta z(x) = \\kappa_{\\tau=1}(x) \\delta T(x) + T_{\\tau=1}(x) \\delta \\kappa(x)$. The two match up pretty well indicating that the non-linear $\\delta T(x) \\delta \\kappa(x)$ term is not that important."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "save_z_quant_fig = False\n",
    "plot_include_p = False\n",
    "fig, ax = plt.subplots(2,1, figsize=(width['one_col'], 2 * width['one_col']/ar), sharex=True)\n",
    "for i in range(n_exp):\n",
    "    ax[0].plot(quant_plot, np.average(z_quant3[i], axis=0, weights=lat_weights), color=default_colors[i], label=f'$\\\\tau={tau_lw[i]}$', \n",
    "               lw=2, alpha=0.5)\n",
    "    for j, kappa_use in enumerate([kappa_mean, kappa_lapse, np.asarray([kappa_empirical]*n_exp)]):\n",
    "        ax[0].plot(quant_plot, np.average(kappa_use[i] * temp_quant3[i, 0], axis=0, weights=lat_weights) + \n",
    "                   (1 if j==len(linestyles_kappa)-1 else 0)*intercept, color='k', linestyle=linestyles_kappa[j])\n",
    "    ax[0].axhline(np.average(z_mean[i], axis=0, weights=lat_weights), color=default_colors[i], lw=ax_linewidth, alpha=0.5)\n",
    "    if plot_include_p:\n",
    "        ax[0].plot(quant_plot, np.average(z_p_quant3[i], axis=0, weights=lat_weights), color='green', alpha=0.4)\n",
    "        ax[0].plot(quant_plot, np.average(np.expand_dims(z_p_mean[i]/temp_p_mean[i], axis=-1) * temp_p_quant3[i], axis=0, weights=lat_weights), \n",
    "                color='green', linestyle=':', alpha=0.4)\n",
    "ax[1].plot(quant_plot, np.average(z_quant3[1]-z_quant3[0], axis=0, weights=lat_weights), color='k', lw=2, alpha=0.5)\n",
    "for i, kappa_use in enumerate([kappa_mean, kappa_lapse, np.asarray([kappa_empirical]*n_exp)]):\n",
    "    ax[1].plot(quant_plot, np.average(kappa_use[1] * temp_quant3[1, 0] - \n",
    "                                      kappa_use[0] * temp_quant3[0, 0], axis=0, weights=lat_weights), \n",
    "            color='k', linestyle=linestyles_kappa[i], label=labels_kappa[i])\n",
    "    if i < len(linestyles_kappa)-1:\n",
    "        # Plot sum of linear taylor series terms to see if it matches up\n",
    "        ax[1].plot(quant_plot, np.average(kappa_use[0]*(temp_quant3[1, 0] - temp_quant3[0, 0]) + \n",
    "                                          (kappa_use[1]-kappa_use[0])*temp_quant3[0, 0],\n",
    "                                          axis=0, weights=lat_weights), color='k', linestyle=linestyles_kappa[i], alpha=0.2)\n",
    "if plot_include_p:\n",
    "    ax[1].plot(quant_plot, np.average(z_p_quant3[1]-z_p_quant3[0], axis=0, weights=lat_weights), color='green', alpha=0.4)\n",
    "    ax[1].plot(quant_plot, np.average(np.expand_dims((z_p_mean[1]-z_p_mean[0])/(temp_p_mean[1]-temp_p_mean[0]), axis=-1) * \n",
    "                                      (temp_p_quant3[1] - temp_p_quant3[0]), axis=0, weights=lat_weights), \n",
    "               color='green', linestyle=':', alpha=0.4)\n",
    "ax[1].axhline(np.average(z_mean[1]-z_mean[0], axis=0, weights=lat_weights), color='k', lw=ax_linewidth, alpha=0.5)\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "ax[0].set_xlim(0, 100)\n",
    "ax[0].set_ylabel('$z$ [m]')\n",
    "ax[1].set_ylabel('$\\delta z$ [m]')\n",
    "ax[1].set_xlabel('Near surface temperature percentile, $x$')\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_fig or save_z_quant_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/z_quant.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:44:17.765130Z",
     "start_time": "2024-03-25T15:44:17.620837Z"
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Comparison of $\\kappa(x)$\n",
    "For the *Fixed lapse* and *Varying lapse* methods, I can compute $\\kappa$ for each simulation. Clearly if we include the varying lapse rate, we get a much better match to the simulated thick line.\n",
    "\n",
    "For the *Empirical method*, we have a non-zero intercept so $z(x) = \\kappa T(x) + C$ so the $\\kappa$ value can not be directly compared. It is included as the dot-dash line at $\\delta \\kappa=0$ in the $\\delta \\kappa$ plot though as both $C$ and $\\kappa$ stay constant with this method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "save_kappa_quant_fig = False\n",
    "fig, ax = plt.subplots(2,1, figsize=(width['one_col'], 2*width['one_col']/ar), sharex=True)\n",
    "for i in range(n_exp):\n",
    "    ax[0].plot(quant_plot, np.average(kappa_quant3[i], weights=lat_weights, axis=0), color=default_colors[i], lw=2, alpha=0.5)\n",
    "    ax[0].axhline(np.average(kappa_mean.squeeze()[i], weights=lat_weights, axis=0), color=default_colors[i], \n",
    "                  linestyle=linestyles_kappa[0], label=labels_kappa[0] if i==0 else None)\n",
    "    ax[0].plot(quant_plot, np.average(kappa_lapse[i], weights=lat_weights, axis=0), color=default_colors[i], \n",
    "               linestyle=linestyles_kappa[1], label=labels_kappa[1] if i==0 else None)\n",
    "    # Don't include empirical as relies on interecept so kappa is not really comparable.\n",
    "ax[1].plot(quant_plot, np.average(kappa_quant3[1]-kappa_quant3[0], weights=lat_weights, axis=0), color='k', lw=2, alpha=0.5)\n",
    "ax[1].axhline(np.average(kappa_mean.squeeze()[1]-kappa_mean.squeeze()[0], weights=lat_weights, axis=0), \n",
    "              color='k', linestyle=linestyles_kappa[0])\n",
    "ax[1].plot(quant_plot, np.average(kappa_lapse[1]-kappa_lapse[0], weights=lat_weights, axis=0), color='k',\n",
    "           linestyle=linestyles_kappa[1])\n",
    "ax[1].axhline(0, linestyle=linestyles_kappa[2], color='k')\n",
    "ax[0].set_xlim(0, 100)\n",
    "ax[0].legend()\n",
    "ax[0].set_ylabel('$\\kappa$ [mK$^{-1}$]')\n",
    "ax[1].set_ylabel('$\\delta \\kappa$ [mK$^{-1}$]')\n",
    "ax[-1].set_xlabel('Near surface temperature percentile, $x$')\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_fig or save_kappa_quant_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/kappa_quant.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:44:17.892046Z",
     "start_time": "2024-03-25T15:44:17.765846Z"
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Contributions to $\\delta z(x)$\n",
    "If we take the linear taylor series, we can approximate $\\delta z(x) = \\kappa_{\\tau=1}(x) \\delta T(x) + T_{\\tau=1}(x) \\delta \\kappa(x)$.\n",
    "\n",
    "Below, the first term, $\\kappa_{\\tau=1}(x) \\delta T(x)$, is shown by a dashed line and the second term, $T_{\\tau=1}(x) \\delta \\kappa(x)$, is shown by a dotted line. For the empirical method, this second term is zero as $\\kappa$ is calculated by combining the $\\tau=1$ and $\\tau=1.5$ simulations.\n",
    "\n",
    "It is interesting that the first term $\\kappa_{\\tau=1}(x) \\delta T(x)$ is basically the same for the *Fixed lapse* and *Varying lapse* methods. However, the second term provides a significant difference, especially for cold days (small $x$).\n",
    "\n",
    "The light grey lines show the simulated taylor series factors i.e. the grey and black solid lines would be exactly the same if the non-linear $\\delta T(x) \\delta \\kappa(x)$ term was exactly zero."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "save_delta_z_decomp_fig = False\n",
    "fig, ax = plt.subplots(1,1, figsize=(width['one_col'], width['one_col']/ar), sharex=True, sharey=True)\n",
    "ax = [ax]\n",
    "ax[0].plot(quant_plot, np.average(z_quant3[1]-z_quant3[0], axis=0, weights=lat_weights), color='k', label='Simulated')\n",
    "for i, kappa_use in enumerate([kappa_mean, kappa_lapse, np.asarray([kappa_empirical]*n_exp), kappa_quant3]):\n",
    "    use_color = 'k' if i == 3 else default_colors[i]\n",
    "    ax[0].plot(quant_plot, np.average(kappa_use[0]*(temp_quant3[1, 0] - temp_quant3[0, 0]), axis=0, weights=lat_weights), \n",
    "               color=use_color, linestyle='--', alpha=0.2 if i==3 else 1)\n",
    "    ax[0].plot(quant_plot, np.average((kappa_use[1]-kappa_use[0])*temp_quant3[0, 0], axis=0, weights=lat_weights), \n",
    "               color=use_color, linestyle=':', alpha=0.2 if i==3 else 1)\n",
    "    ax[0].plot(quant_plot, np.average(kappa_use[0]*(temp_quant3[1, 0] - temp_quant3[0, 0]) + \n",
    "                                      (kappa_use[1]-kappa_use[0])*temp_quant3[0, 0], axis=0, weights=lat_weights), \n",
    "               color=use_color, label=None if i==3 else labels_kappa[i], alpha=0.2 if i==3 else 1)\n",
    "\n",
    "ax[0].scatter(1, np.average(z_mean[1]-z_mean[0], axis=0, weights=lat_weights), color='k', alpha=0.8, marker='o',linewidth=0)\n",
    "use_color = [default_colors[0], default_colors[2]]\n",
    "use_alpha = [1, 1]\n",
    "for i, kappa_use in enumerate([kappa_mean.squeeze(), np.asarray([kappa_empirical]*n_exp)]):\n",
    "    ax[0].scatter(1, np.average(kappa_use[0]*(temp_mean[1, 0] - temp_mean[0, 0]), axis=0, weights=lat_weights), \n",
    "                  color=use_color[i], alpha=use_alpha[i], marker='x')\n",
    "    ax[0].scatter(1, np.average(temp_mean[0, 0]*(kappa_use[1] - kappa_use[0]), axis=0, weights=lat_weights), \n",
    "                  color=use_color[i], alpha=use_alpha[i], marker='o', lw=0.5, facecolors='none', linewidth=0.5)\n",
    "    ax[0].scatter(1, np.average(kappa_use[0]*(temp_mean[1, 0] - temp_mean[0, 0]) + \n",
    "                                temp_mean[0, 0]*(kappa_use[1] - kappa_use[0]), axis=0, weights=lat_weights), \n",
    "                  color=use_color[i], alpha=0.8, marker='o',linewidth=0)\n",
    "\n",
    "ax[0].set_xlim(0, 100)\n",
    "ax[0].legend()\n",
    "ax[0].set_ylabel('$\\delta z$ [m]')\n",
    "ax[-1].set_xlabel('Near surface temperature percentile, $x$')\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_fig or save_delta_z_decomp_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/delta_z_decomp.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:44:18.004341Z",
     "start_time": "2024-03-25T15:44:17.892837Z"
    }
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Lapse Rate Changes\n",
    "The second term is related to changes in $\\delta \\kappa(x)$ and from the equation for $\\kappa(x)$ must be dominated by changes in lapse rate, $\\delta \\Gamma$. \n",
    "\n",
    "In the bottom left plot below, we see there is a large decrease in $\\delta \\Gamma$ for $x<30$ coinciding with the large contribution from the $\\delta \\kappa$ term for the *Varying lapse* method above.\n",
    "\n",
    "The picture here is shown more clearly by the moist static energy lapse rate, $\\Gamma_h=\\frac{h^*_{FT}(x)-h(x)}{z_{FT}(x) - z(x)}$, on the right. $\\Gamma_h=0$ for a convectively stable profile along the moist adiabat and becomes negative for a convectively unstable profile where $h(x)>h^*_{FT}(x)$.\n",
    "\n",
    "For $x<30$, convective becomes more active with warming and so shifts towards $\\Gamma_h=0$. The smaller $x$, the more positive $\\Gamma_h$ in the $\\tau=1$ simulation so the larger the permitted $\\delta \\Gamma_h$.\n",
    "\n",
    "For $x>30$, $\\delta \\Gamma_h$ is small because convection provides a limit on how much it cann decrease. I.e. it can't decrease to such an extent that $\\Gamma_h$ becomes very negative as it would be convectively unstable.\n",
    "\n",
    "The fact that $\\Gamma_h$ becomes negative means that some about of convective instability is permitted. We should look into why this is, but it may be a competition between local convection and large scale circulation, possibly an anticyclone which pushes the profile to become unstable. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "save_lapse_rate_fig = False\n",
    "fig, ax = plt.subplots(2,2, figsize=(2*width['one_col'], 2*width['one_col']/ar), sharex=True)\n",
    "for i in range(n_exp):\n",
    "    ax[0, 0].plot(quant_plot, np.average(lapse_quant3[i]*1000, weights=lat_weights, axis=0), color=default_colors[i])\n",
    "    # Convert MSE into kelvin per km units as well\n",
    "    ax[0, 1].plot(quant_plot, np.average(lapse_mse_quant3[i]*1000/c_p*1000, weights=lat_weights, axis=0), color=default_colors[i])\n",
    "ax[1, 0].plot(quant_plot, np.average((lapse_quant3[1]-lapse_quant3[0])*1000, weights=lat_weights, axis=0), color='k')\n",
    "ax[1, 1].plot(quant_plot, np.average((lapse_mse_quant3[1]-lapse_mse_quant3[0])*1000/c_p*1000, weights=lat_weights, axis=0), color='k')\n",
    "ax[0, 1].axhline(0, color='k', lw=ax_linewidth)\n",
    "ax[0, 0].set_xlim(0, 100)\n",
    "ax[0, 0].set_ylabel('Lapse rate, $\\Gamma = -dT/dz$ [K/km]')\n",
    "ax[0, 1].set_ylabel('$\\Gamma_h = dh/dz$ [K/km]')\n",
    "ax[1, 0].set_ylabel('$\\delta \\Gamma$ [K/km]')\n",
    "ax[1, 1].set_ylabel('$\\delta \\Gamma_h$ [K/km]')\n",
    "fig.supxlabel('Near surface temperature percentile, $x$', fontsize=7)\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_fig or save_lapse_rate_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/lapse_rate.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:44:18.337620Z",
     "start_time": "2024-03-25T15:44:18.005078Z"
    }
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## $\\lambda_2$ Analysis assuming $\\delta v_g = 0$\n",
    "\n",
    "$\\lambda_2 = \\frac{\\delta h_{FT}^*(x)}{\\delta \\overline{h_{FT}^*}} = \\frac{[c_p + L_v\\alpha(x)q^*(x)]\\delta T(x) + g\\delta z(x)}{[c_p + L_v\\overline{\\alpha q^*}]\\delta \\overline{T} + g\\delta \\overline{z}}$\n",
    "\n",
    "Writing $z = \\kappa T$ and assuming non-linear terms $\\delta T \\delta \\kappa = 0$, we can re-write this as:\n",
    "\n",
    "$\\lambda_2 \\approx \\frac{[g + \\frac{c_p + L_v\\alpha(x)q^*(x)}{\\kappa(x)}] \\delta z(x) - [c_p + L_v\\alpha(x)q^*(x)]\\frac{T(x)}{\\kappa(x)}\\delta \\kappa(x)}{[g + \\frac{c_p + L_v\\overline{\\alpha q^*}}{\\overline{\\kappa}}] \\delta \\overline{z} -[c_p + L_v\\overline{\\alpha q^*}]\\frac{\\overline{T}}{\\overline{\\kappa}}\\delta \\overline{\\kappa}}$\n",
    "\n",
    "If we were to assume that in both the numerator and denominator the $\\delta z$ term is much larger than the $\\delta \\kappa$ term, then we get:\n",
    "$\\lambda_2 \\approx \\frac{[g + \\frac{c_p + L_v\\alpha(x)q^*(x)}{\\kappa(x)}]}{[g + \\frac{c_p + L_v\\overline{\\alpha q^*}}{\\overline{\\kappa}}]} \\times \\frac{\\delta z(x)}{\\delta \\overline{z}}$\n",
    "\n",
    "And the assumption $\\delta z(x) = const = \\delta \\overline{z}$ is consistent with $\\delta v_g = 0$ hence the link to the geostrophic wind. If we assume this, $\\frac{\\delta z(x)}{\\delta \\overline{z}} \\approx 1$ and $\\lambda_2$ can be calculated with just the climatological term.\n",
    "\n",
    "So to assess this simplification of $\\lambda_2$, we need to assess two sets of approximations.\n",
    "1. $\\delta z >> \\delta \\kappa$: In the $\\delta h_{FT}^*$ equations, do the $\\delta z$ term dominate the $\\delta \\kappa$ term?\n",
    "2. $\\delta z(x) = \\delta \\overline{z}$: Does the geopotential height distribution change equally across the temperature distribution with warming, as we expect from constant geostrophic wind?\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "alpha_x = clausius_clapeyron_factor(temp_quant3[0, 0], pressure_ft_actual)\n",
    "alpha_mean = clausius_clapeyron_factor(temp_mean[0, 0], pressure_ft_actual)\n",
    "q_x = sphum_sat(temp_quant3[0, 0], pressure_ft_actual)\n",
    "q_mean = sphum_sat(temp_mean[0, 0], pressure_ft_actual)\n",
    "lambda_2_num = {}\n",
    "lambda_2_denom = {}\n",
    "lambda_2_num['sim'] = (c_p + L_v * alpha_x * q_x) * (temp_quant3[1, 0] - temp_quant3[0, 0]) + g * (\n",
    "            z_quant3[1] - z_quant3[0])\n",
    "labels_use = ['taylor', 'mean', 'lapse', 'empirical']\n",
    "for i, kappa_use in enumerate([kappa_quant3, kappa_mean, kappa_lapse, np.asarray([kappa_empirical]*n_exp)]):\n",
    "    lambda_2_num[labels_use[i] + '_z'] = (g + (c_p + L_v * alpha_x * q_x)/kappa_use[0]) \n",
    "    lambda_2_num[labels_use[i] + '_kappa'] = -(c_p + L_v * alpha_x * q_x) * (temp_quant3[0, 0]/kappa_use[0]) * (kappa_use[1] - kappa_use[0])\n",
    "    # lambda_2_num[labels_use[i] + '_kappa'] = (-(c_p + L_v * alpha_mean * q_mean) * (temp_mean[0, 0]/kappa_mean[0].squeeze()))[:, np.newaxis] * (kappa_use[1] - kappa_use[0])\n",
    "    lambda_2_num[labels_use[i]] = lambda_2_num[labels_use[i] + '_z'] * (z_quant3[1] - z_quant3[0]) + \\\n",
    "                                  lambda_2_num[labels_use[i] + '_kappa'] \n",
    "\n",
    "lambda_2_denom['sim'] = (c_p + L_v * alpha_mean * q_mean) * (temp_mean[1, 0] - temp_mean[0, 0]) + g * (\n",
    "            z_mean[1] - z_mean[0])\n",
    "for i, kappa_use in enumerate([kappa_mean.squeeze(), kappa_mean.squeeze(), kappa_mean.squeeze(), np.asarray([kappa_empirical]*n_exp)]):\n",
    "    lambda_2_denom[labels_use[i] + '_z'] = (g + (c_p + L_v * alpha_mean * q_mean)/kappa_use[0])\n",
    "    lambda_2_denom[labels_use[i] + '_kappa'] = -(c_p + L_v * alpha_mean * q_mean) * (temp_mean[0, 0]/kappa_use[0].squeeze()\n",
    "                                                                       ) * (kappa_use[1] - kappa_use[0]).squeeze()\n",
    "    lambda_2_denom[labels_use[i]] = lambda_2_denom[labels_use[i] + '_z']  * (z_mean[1] - z_mean[0]) + lambda_2_denom[labels_use[i] + '_kappa']\n",
    "\n",
    "z_delta_ratio = (z_quant3[1] - z_quant3[0]) / (z_mean[1] - z_mean[0])[:, np.newaxis]    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:44:18.343868Z",
     "start_time": "2024-03-25T15:44:18.338339Z"
    }
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Approximation 1: $\\delta z >> \\delta \\kappa$\n",
    "Below I assess the first approximation.\n",
    "\n",
    "In the top plot, the solid lines represent the numerator in the full $\\lambda_2$ equation i.e. $\\delta h_{FT}^*(x)$. The dashed line represents the $\\delta z(x)$ term and the dotted line represents the $\\delta \\kappa(x)$ term for the various $\\kappa$ methods. The grey line is to show the linear series is a good approximation.\n",
    "\n",
    "The markers represent the denominator: filled circles are the full $\\delta \\overline{h_{FT}^*}$, crosses are the $\\delta \\overline{z}$ contribution and hollow circles are the $\\delta \\overline{\\kappa}$ contribution.\n",
    "\n",
    "In the bottom plot, the solid lines show how the numerators and denomenators in the top plot combine to give $\\lambda_2$ when all terms are included. The dashed lines show the $\\lambda_2$ approximation without the $\\delta \\kappa$ terms.\n",
    "\n",
    "When we ignore the $\\delta \\kappa$ terms, all forms of $\\kappa$ basically collapse onto a single line. This means that the estimation of $\\kappa$ is only really important for the $\\delta \\kappa$ term. I.e. the fact that the varying lapse rate method is the best at capturing $\\kappa$ only makes a difference if we include the $\\delta \\kappa$ terms.\n",
    "\n",
    "Note by definition $\\delta \\kappa = 0$ for the empirical method, but it overestimates $\\delta \\overline{\\kappa}$ and $\\delta \\kappa(x)$ for small $x$, leading to a not great estimate of $\\lambda_2$.\n",
    "\n",
    "So overall, it seems that this approximation is problematic - we can't really ignore the $\\delta \\kappa$ term."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "save_lambda_2_fig = False\n",
    "\n",
    "use_color = ['k', 'grey', default_colors[0], default_colors[1], default_colors[2]]\n",
    "labels_use = ['Simulated', None] + labels_kappa\n",
    "fig, ax = plt.subplots(2, 1, figsize=(width['one_col'], 2 * width['one_col'] / ar), sharex=True)\n",
    "for i, key in enumerate(['sim', 'taylor', 'mean', 'lapse', 'empirical']):\n",
    "    ax[0].plot(quant_plot, np.average(lambda_2_num[key], weights=lat_weights, axis=0), color=use_color[i], \n",
    "               label=labels_use[i])\n",
    "    ax[1].plot(quant_plot, np.average(lambda_2_num[key] / lambda_2_denom[key][:, np.newaxis], \n",
    "                                      weights=lat_weights, axis=0), color=use_color[i], \n",
    "               label='$\\delta \\kappa \\\\neq 0$' if key=='mean' else None)\n",
    "    if key != 'sim':\n",
    "        ax[0].plot(quant_plot, np.average(lambda_2_num[key+'_z'] * (z_quant3[1] - z_quant3[0]), weights=lat_weights, axis=0),\n",
    "                   color=use_color[i], linestyle='--')\n",
    "        ax[0].plot(quant_plot, np.average(lambda_2_num[key+'_kappa'], weights=lat_weights, axis=0),\n",
    "                   color=use_color[i], linestyle=':')\n",
    "        ax[1].plot(quant_plot, np.average((lambda_2_num[key+'_z'] / lambda_2_denom[key+'_z'][:, np.newaxis]) * z_delta_ratio, \n",
    "                                          weights=lat_weights, axis=0), color=use_color[i], linestyle='--', alpha=0.5, \n",
    "                   label='$\\delta \\kappa = 0$' if key=='mean' else None)\n",
    "    if key in ['sim', 'mean', 'empirical']:\n",
    "        ax[0].scatter(1, np.average(lambda_2_denom[key], weights=lat_weights, axis=0), color=use_color[i], marker='o', alpha=0.8, \n",
    "                   linewidth=0)\n",
    "        if key != 'sim':\n",
    "            ax[0].scatter(1, np.average(lambda_2_denom[key+'_z'] * (z_mean[1] - z_mean[0]), weights=lat_weights, axis=0), \n",
    "                          color=use_color[i], marker='x')\n",
    "            ax[0].scatter(1, np.average(lambda_2_denom[key+'_kappa'], weights=lat_weights, axis=0), \n",
    "                          color=use_color[i], marker='o', facecolors='none', lw=0.5)\n",
    "ax[1].axhline(1, color='k', lw=ax_linewidth)\n",
    "ax[0].set_xlim(0, 100)\n",
    "ax[0].set_ylabel('$\\delta h^*_{FT}$ [kJ/kg]')\n",
    "ax[1].set_ylabel('$\\lambda_2 = \\delta h^*_{FT}(x) / \\delta \\overline{h^*_{FT}}$')\n",
    "ax[1].set_xlabel('Near surface temperature percentile, $x$')\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "if save_fig or save_lambda_2_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/lambda_2.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:44:18.518568Z",
     "start_time": "2024-03-25T15:44:18.344598Z"
    }
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Approximation 2: $\\delta z(x) = \\delta \\overline{z}$\n",
    "Below, the dashed lines show the estimates of $\\lambda_2$ excluding the $\\delta \\kappa$ terms. The dotted lines show the estimates if we further assume $\\delta z(x) = \\delta \\overline{z}$. It seems that this second approximation actually improves things. \n",
    "\n",
    "Again, we see that how $\\kappa$ is computed is not important - all coloured lines collapse onto each other.\n",
    "\n",
    "So it seems that the two approximations partially cancel out. I think we may have a slightly circular argument here as $\\kappa$ and $z$ are related so the two assumptions are not independent."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Assuming delta kappa terms are zero and see what lambda looks like\n",
    "labels_use = ['Simulated', None] + labels_kappa\n",
    "save_lambda_2_fix_kappa_fig = False\n",
    "fig, ax = plt.subplots(1, 1, figsize=(width['one_col'], width['one_col'] / ar))\n",
    "for i, key in enumerate(['sim', 'taylor', 'mean', 'lapse', 'empirical']):\n",
    "    if key == 'sim':\n",
    "        ax.plot(quant_plot, np.average(lambda_2_num[key] / lambda_2_denom[key][:, np.newaxis], weights=lat_weights, axis=0), \n",
    "                color=use_color[i], label=labels_use[i])\n",
    "    else:\n",
    "        ax.plot(quant_plot, np.average((lambda_2_num[key+'_z'] / lambda_2_denom[key+'_z'][:, np.newaxis]) * z_delta_ratio, \n",
    "                                       weights=lat_weights, axis=0), color=use_color[i], label=labels_use[i], linestyle='--')\n",
    "        ax.plot(quant_plot, np.average((lambda_2_num[key+'_z'] / lambda_2_denom[key+'_z'][:, np.newaxis]), \n",
    "                                   weights=lat_weights, axis=0), linestyle=':', color=use_color[i])\n",
    "ax.plot(quant_plot, np.average(z_delta_ratio, weights=lat_weights, axis=0), color='cyan', label='$\\delta z / \\delta \\overline{z}$')\n",
    "ax.axhline(1, color='k', lw=ax_linewidth)\n",
    "ax.set_ylabel('$\\lambda_2 = \\delta h^*_{FT}(x) / \\delta \\overline{h^*_{FT}}$')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Near surface temperature percentile, $x$')\n",
    "if save_fig or save_lambda_2_fix_kappa_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/lambda_2_fix_kappa.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:44:18.611777Z",
     "start_time": "2024-03-25T15:44:18.519254Z"
    }
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Separating $\\delta z$ and $\\delta \\kappa$ contributions to $\\lambda_2$\n",
    "Writing $\\mu_z = g + (c_p + L_v\\alpha q^*)/\\kappa$ and $\\mu_{\\kappa} = (c_p + L_v\\alpha q^*)T/\\kappa$ such that $\\mu_z = \\mu_{\\kappa}/T+g$, we can write $\\lambda_2$ as:\n",
    "$\\lambda_2 = \\frac{\\mu_z(x)\\delta z(x) - \\mu_{\\kappa}(x)\\delta \\kappa(x)}{\\overline{\\mu_z}\\delta \\overline{z} - \\overline{\\mu_{\\kappa}}\\delta \\overline{\\kappa}}$\n",
    "The denominator is equivalent to $\\overline{\\mu_z}\\delta \\overline{z} \\left[1 - \\frac{\\overline{\\mu_{\\kappa}}\\delta \\overline{\\kappa}}{\\overline{\\mu_z}\\delta \\overline{z}}\\right]$ or $-\\overline{\\mu_{\\kappa}}\\delta \\overline{\\kappa}\\left[1 - \\frac{\\overline{\\mu_z}\\delta \\overline{z}}{\\overline{\\mu_{\\kappa}}\\delta \\overline{\\kappa}}\\right]$ so we can write:\n",
    "$$\\lambda_2 = \\frac{\\mu_z(x)}{\\overline{\\mu_z} \\left[1 - \\frac{\\overline{\\mu_{\\kappa}}\\delta \\overline{\\kappa}}{\\overline{\\mu_z}\\delta \\overline{z}}\\right]}\\frac{\\delta z(x)}{\\delta \\overline{z}} + \n",
    "\\frac{\\mu_{\\kappa}(x)}{\\overline{\\mu_{\\kappa}}\\left[1 - \\frac{\\overline{\\mu_z}\\delta \\overline{z}}{\\overline{\\mu_{\\kappa}}\\delta \\overline{\\kappa}}\\right]}\\frac{\\delta \\kappa(x)}{\\delta \\overline{\\kappa}}$$\n",
    "\n",
    "This separates out the $\\delta z(x)$ and $\\delta \\kappa(x)$ terms. Next we need to see if it can be further simplified.\n",
    "\n",
    "Below I plot all the terms in this form of the equation for the actual and varying lapse rate $\\kappa$ estimate:\n",
    "* Solid line: full $\\lambda_2$ \n",
    "* Dashed line: $\\delta z(x)/\\delta \\overline{z}$ prefactor\n",
    "* Dotted line: $\\delta \\kappa(x)/\\delta \\overline{\\kappa}$ prefactor\n",
    "* Dashed-dotted line: $\\delta \\kappa(x)/\\delta \\overline{\\kappa}$\n",
    "\n",
    "From this, we see that $\\delta \\kappa(x)/\\delta \\overline{\\kappa}$ is over-estimated by the *Varying lapse* method, resulting in an over-estimate of $\\lambda_2$ for low $x$ and the opposite for high $x$.\n",
    "\n",
    "Looking at the dashed and dotted lines, the orange and black lines overlap almost exactly. This indicates that the way $\\kappa$ is computed doesn't seem to affect the prefactors - just the $\\delta \\kappa(x)$ term. Hence we may be able to provide a simplification through the prefactors.\n",
    "\n",
    "Also, the $\\delta \\kappa(x)/\\delta \\overline{\\kappa}$ prefactor looks quite constant with $x$, suggesting we may be able to replace $\\mu_{\\kappa}(x)$ with $\\overline{\\mu_{\\kappa}}$\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "mu_z = {'x': {}, 'mean': {}}\n",
    "mu_kappa = {'x': {}, 'mean': {}}\n",
    "z_delta = {'x': (z_quant3[1] - z_quant3[0]), 'mean': (z_mean[1] - z_mean[0])}\n",
    "kappa_delta = {'x': {}, 'mean': {}}\n",
    "lambda_z_prefactor = {}\n",
    "lambda_kappa_prefactor = {}\n",
    "labels_use = ['taylor', 'mean', 'lapse', 'empirical']\n",
    "for i, kappa_use in enumerate([kappa_quant3, kappa_mean, kappa_lapse, np.asarray([kappa_empirical]*n_exp)]):\n",
    "    mu_z['x'][labels_use[i]] = (g + (c_p + L_v * alpha_x * q_x)/kappa_use[0]) \n",
    "    mu_kappa['x'][labels_use[i]] = (mu_z['x'][labels_use[i]] - g) * temp_quant3[0, 0]\n",
    "    mu_z['mean'][labels_use[i]] = (g + (c_p + L_v * alpha_mean * q_mean)/kappa_mean[0].squeeze())\n",
    "    mu_kappa['mean'][labels_use[i]] = (mu_z['mean'][labels_use[i]] - g) * temp_mean[0, 0]\n",
    "    \n",
    "    kappa_delta['x'][labels_use[i]] = kappa_use[1] - kappa_use[0]\n",
    "    kappa_delta['mean'][labels_use[i]] = (kappa_mean[1] - kappa_mean[0]).squeeze()\n",
    "    \n",
    "for key in mu_z['x']:\n",
    "    lambda_z_prefactor[key] = mu_z['x'][key]/mu_z['mean'][key][:, np.newaxis]\n",
    "    lambda_z_prefactor[key] = lambda_z_prefactor[key] / (1-mu_kappa['mean'][key]/mu_z['mean'][key] * \n",
    "                                                         kappa_delta['mean'][key]/z_delta['mean'])[:, np.newaxis]\n",
    "    lambda_kappa_prefactor[key] = mu_kappa['x'][key]/mu_kappa['mean'][key][:, np.newaxis]\n",
    "    lambda_kappa_prefactor[key] = lambda_kappa_prefactor[key] / (1-mu_z['mean'][key]/mu_kappa['mean'][key] * \n",
    "                                                         z_delta['mean']/kappa_delta['mean'][key])[:, np.newaxis]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:44:18.617524Z",
     "start_time": "2024-03-25T15:44:18.612460Z"
    }
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "use_color = ['k', 'grey', default_colors[1]]\n",
    "labels_use = ['Simulated', None] + [labels_kappa[1]]\n",
    "\n",
    "save_lambda_2_additive_fig = False\n",
    "fig, ax = plt.subplots(1, 1, figsize=(width['one_col'], width['one_col'] / ar))\n",
    "ax.plot(quant_plot, np.average(lambda_2_num['sim'] / lambda_2_denom['sim'][:, np.newaxis], weights=lat_weights, axis=0), \n",
    "        color=use_color[0], label=labels_use[0])\n",
    "for i, key in enumerate(['taylor', 'lapse']):\n",
    "    ax.plot(quant_plot, np.average(lambda_z_prefactor[key] * z_delta['x'] / z_delta['mean'][:, np.newaxis] + \n",
    "                                   lambda_kappa_prefactor[key] * kappa_delta['x'][key] / kappa_delta['mean'][key][:, np.newaxis], \n",
    "                                   weights=lat_weights, axis=0), color=use_color[i+1], label=labels_use[i+1])\n",
    "    ax.plot(quant_plot, np.average(lambda_z_prefactor[key], weights=lat_weights, axis=0), color=use_color[i+1], linestyle='--', alpha=0.5)\n",
    "    if key != 'empirical':\n",
    "        # Leave out empirical as get no delta kappa contribution\n",
    "        ax.plot(quant_plot, np.average(lambda_kappa_prefactor[key], weights=lat_weights, axis=0), color=use_color[i+1], \n",
    "                linestyle=':', alpha=0.5)\n",
    "    if key in ['taylor', 'lapse']:\n",
    "        # delta kappa ratio is a function of x\n",
    "        ax.plot(quant_plot, np.average(kappa_delta['x'][key] / kappa_delta['mean'][key][:, np.newaxis], weights=lat_weights, axis=0), color=use_color[i+1], linestyle='-.', lw=ax_linewidth)\n",
    "    else:\n",
    "        # delta kappa ratio is a constant\n",
    "        ax.axhline(np.average(kappa_delta['x'][key] / kappa_delta['mean'][key][:, np.newaxis], weights=lat_weights, axis=0),\n",
    "                   color=use_color[i+1], linestyle='-.', lw=ax_linewidth)\n",
    "ax.plot(quant_plot, np.average(z_delta_ratio, weights=lat_weights, axis=0), color='cyan', label='$\\delta z / \\delta \\overline{z}$',\n",
    "        lw=ax_linewidth)    \n",
    "ax.axhline(1, color='k', lw=ax_linewidth)\n",
    "ax.axhline(0, color='k', lw=ax_linewidth)\n",
    "ax.legend(frameon=True, framealpha=1, edgecolor='white', fontsize=6)\n",
    "ax.set_xlim(0, 100)\n",
    "ax.set_ylabel('$\\lambda_2 = \\delta h^*_{FT}(x) / \\delta \\overline{h^*_{FT}}$')\n",
    "ax.set_xlabel('Near surface temperature percentile, $x$')\n",
    "\n",
    "if save_fig or save_lambda_2_additive_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/lambda_2_additive.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:44:18.715060Z",
     "start_time": "2024-03-25T15:44:18.618234Z"
    }
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### $\\lambda_2$ Approximations\n",
    "From above, we see that $\\delta \\kappa(x)/\\delta \\overline{\\kappa}$ is over-estimated by the *Varying lapse* method, resulting in an over-estimate of $\\lambda_2$ for low $x$ and the opposite for high $x$.\n",
    "\n",
    "Looking at the dashed and dotted lines, the orange and black lines overlap almost exactly. This indicates that the way $\\kappa$ is computed doesn't seem to affect the prefactors - just the $\\delta \\kappa(x)$ term. Hence we may be able to provide a simplification through replacing $\\kappa(x)$ with $\\overline{\\kappa}$. The very close match between the solid orange line and the dashed dark red line below shows that this approximation is very good. For all other dashed lines, I make this approximation too.\n",
    "\n",
    "Also, the $\\delta \\kappa(x)/\\delta \\overline{\\kappa}$ prefactor looks quite constant with $x$, suggesting we may be able to replace $\\mu_{\\kappa}(x)$ with $\\overline{\\mu_{\\kappa}}$. The dashed dark red and orange lines are actually fairly different suggesting this approximation is not brilliant.\n",
    "\n",
    "A taylor expansion of the denomenator of $\\lambda_2$ can be performed in the parameter $\\beta = \\frac{\\overline{\\mu_{\\kappa}}\\delta \\overline{\\kappa}}{\\overline{\\mu_z}\\delta \\overline{z}}$, which is small - below 0.25 for the latitudes considered. Keeping just terms linear in $\\beta$, we get:\n",
    "$$\\lambda_2 \\approx (1+\\beta)\\frac{\\mu_z(x)}{\\overline{\\mu_z}}\\frac{\\delta z(x)}{\\delta \\overline{z}} - \\beta \\frac{\\mu_{\\kappa}(x)}{\\overline{\\mu_{\\kappa}}}\\frac{\\delta \\kappa(x)}{\\delta \\overline{\\kappa}$$\n",
    "\n",
    "The close overlap between the dashed dark red and dashed light green lines below shows that this is a very good approximation. The light blue dashed line shows it is significantly worse if I further assume $\\mu_{\\kappa}(x) = \\overline{\\mu_{\\kappa}}$. Neglecting $\\beta$ altogether gives the dark blue dashed line which is worse still."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_lambda2_prefactors(use_mean_kappa=False, set_mu_kappa_constant=False, do_beta_taylor=False, beta_method='full', \n",
    "                           ignore_g=False, use_mean_T=False):\n",
    "    # Function to get lambda2 prefactors with various simplifications\n",
    "    if beta_method == 'full':\n",
    "        beta = (mu_kappa['mean']['mean']/mu_z['mean']['mean'] * kappa_delta['mean']['mean']/z_delta['mean'])[:, np.newaxis]\n",
    "    elif beta_method == 'simple':\n",
    "        beta = (temp_mean[0, 0] * kappa_delta['mean']['mean']/z_delta['mean'])[:, np.newaxis]\n",
    "    elif beta_method == 'zero':\n",
    "        beta = np.zeros_like(temp_mean[0, 0][:, np.newaxis])\n",
    "    else:\n",
    "        raise ValueError(f\"Beta method indicated = {beta_method}.\\nThis is not one of 'full', 'simple' or 'zero'\")\n",
    "        \n",
    "    if ignore_g:\n",
    "        g_factor = 0\n",
    "    else:\n",
    "        g_factor = g\n",
    "        \n",
    "    if use_mean_T or set_mu_kappa_constant:\n",
    "        temp_x_use = temp_mean[0, 0][:, np.newaxis]\n",
    "    else:\n",
    "        temp_x_use = temp_quant3[0, 0]\n",
    "        \n",
    "    if use_mean_kappa:\n",
    "        kappa_x_use = kappa_mean[0]\n",
    "    else:\n",
    "        kappa_x_use = kappa_quant3[0]\n",
    "        \n",
    "    mu_z_x = g_factor + (c_p + L_v * alpha_x * q_x)/kappa_x_use\n",
    "    mu_z_mean = g_factor + (c_p + L_v * alpha_mean * q_mean)/kappa_mean[0].squeeze()\n",
    "    \n",
    "    if set_mu_kappa_constant:\n",
    "        mu_kappa_x = (c_p + L_v * alpha_mean * q_mean)[:, np.newaxis] * temp_x_use/kappa_x_use\n",
    "    else:\n",
    "        mu_kappa_x = (c_p + L_v * alpha_x * q_x) * temp_x_use/kappa_x_use\n",
    "    mu_kappa_mean = (c_p + L_v * alpha_mean * q_mean) * temp_mean[0, 0]/kappa_mean[0].squeeze()\n",
    "    \n",
    "    if do_beta_taylor:\n",
    "        z_prefactor = (1 + beta) * mu_z_x / mu_z_mean[:, np.newaxis]\n",
    "        kappa_prefactor = -beta * mu_kappa_x / mu_kappa_mean[:, np.newaxis]\n",
    "    else:\n",
    "        z_prefactor = mu_z_x / mu_z_mean[:, np.newaxis] / (1-beta)\n",
    "        kappa_prefactor = mu_kappa_x / mu_kappa_mean[:, np.newaxis] / (1-1/beta)\n",
    "    return z_prefactor, kappa_prefactor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:44:18.720479Z",
     "start_time": "2024-03-25T15:44:18.715756Z"
    }
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "save_lambda_2_approx_fig = False\n",
    "colors_approx = plt.cm.jet(np.linspace(0,1,6))[::-1]\n",
    "fig, ax = plt.subplots(1, 1, figsize=(width['one_col'], width['one_col'] / ar))\n",
    "ax.plot(quant_plot, np.average(lambda_2_num['sim'] / lambda_2_denom['sim'][:, np.newaxis], weights=lat_weights, axis=0), \n",
    "        color='k', label=labels_use[0])\n",
    "for i, key in enumerate(['taylor', 'lapse']):\n",
    "    ax.plot(quant_plot, np.average(lambda_z_prefactor[key] * z_delta['x'] / z_delta['mean'][:, np.newaxis] + \n",
    "                                   lambda_kappa_prefactor[key] * kappa_delta['x'][key] / kappa_delta['mean'][key][:, np.newaxis], \n",
    "                                   weights=lat_weights, axis=0), color='grey' if i==0 else default_colors[1], label=labels_use[i+1])\n",
    "\n",
    "labels_approx = ['$\\kappa(x)=\\overline{\\kappa}$', '$\\mu_{\\kappa}(x)=\\overline{\\mu_{\\kappa}}$', \n",
    "                 'Taylor in $\\\\beta$ ($\\mu_{\\kappa}(x)\\\\neq\\overline{\\mu_{\\kappa}}$)', \n",
    "                 'Taylor in $\\\\beta$ ($\\mu_{\\kappa}(x)=\\overline{\\mu_{\\kappa}}$)', '$\\delta \\kappa(x)=0$']    \n",
    "args_approx = [[True], [True, True], [True, False, True], [True, True, True], [True, True, True, 'zero']]\n",
    "\n",
    "for i in range(len(labels_approx)):\n",
    "    z_prefactor_use, kappa_prefactor_use = get_lambda2_prefactors(*args_approx[i])\n",
    "    ax.plot(quant_plot, np.average(z_prefactor_use * z_delta['x'] / z_delta['mean'][:, np.newaxis] + \n",
    "                                   kappa_prefactor_use * kappa_delta['x']['lapse'] / kappa_delta['mean']['lapse'][:, np.newaxis], \n",
    "                                   weights=lat_weights, axis=0), color=colors_approx[i],\n",
    "        label=labels_approx[i], linestyle='--')\n",
    "\n",
    "ax.axhline(1, color='k', lw=ax_linewidth)\n",
    "ax.legend(frameon=True, framealpha=1, edgecolor='white', fontsize=6)\n",
    "ax.set_xlim(0, 100)\n",
    "ax.set_ylabel('$\\lambda_2 = \\delta h^*_{FT}(x) / \\delta \\overline{h^*_{FT}}$')\n",
    "ax.set_xlabel('Near surface temperature percentile, $x$')\n",
    "if save_fig or save_lambda_2_approx_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/lambda_2_approx.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:44:18.834764Z",
     "start_time": "2024-03-25T15:44:18.721240Z"
    }
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### $\\beta$ Approximation\n",
    "The light green line above looks like a good approximation. If we further assume $\\beta = \\frac{\\overline{\\mu_{\\kappa}}\\delta \\overline{\\kappa}}{\\overline{\\mu_z}\\delta \\overline{z}} \\approx \\frac{\\overline{T}\\delta \\overline{\\kappa}}{\\delta \\overline{z}}$ (this is equivalent to assuming $c_p + L_v \\overline{\\alpha}\\overline{q^*}>> g\\overline{\\kappa}$), we get:\n",
    "\n",
    "$$\\lambda_2 \\approx (1+\\frac{\\overline{T}\\delta \\overline{\\kappa}}{\\delta \\overline{z}})\\frac{\\mu_z(x)}{\\overline{\\mu_z}}\\frac{\\delta z(x)}{\\delta \\overline{z}} - \\frac{\\mu_{\\kappa}(x)}{\\overline{\\mu_{\\kappa}}}\\frac{\\overline{T} \\delta \\kappa(x)}{\\delta \\overline{z}}$$\n",
    "\n",
    "And putting in the expressions for $\\mu$ (always setting $\\kappa(x) = \\overline{\\kappa}$):\n",
    "\n",
    "$$\\lambda_2 \\approx (1+\\frac{\\overline{T}\\delta \\overline{\\kappa}}{\\delta \\overline{z}})\\frac{g \\overline{\\kappa} + c_p + L_v\\alpha(x) q^*(x)}{g \\overline{\\kappa} + c_p + L_v\\overline{\\alpha} \\overline{q^*}}\\frac{\\delta z(x)}{\\delta \\overline{z}} - \n",
    "\\frac{c_p + L_v\\alpha(x) q^*(x)}{c_p + L_v\\overline{\\alpha} \\overline{q^*}}\\frac{T(x) \\delta \\kappa(x)}{\\delta \\overline{z}}$$\n",
    "\n",
    "This is shown by the cyan line below.\n",
    "\n",
    "The $\\beta$ simplification we made above is consistent with neglecting all the $g\\overline{\\kappa}$ terms, in which case we get:\n",
    "\n",
    "$$\\lambda_2 \\approx (1+\\frac{\\overline{T}\\delta \\overline{\\kappa}}{\\delta \\overline{z}})\\frac{c_p + L_v\\alpha(x) q^*(x)}{c_p + L_v\\overline{\\alpha} \\overline{q^*}}\\frac{\\delta z(x)}{\\delta \\overline{z}} - \n",
    "\\frac{c_p + L_v\\alpha(x) q^*(x)}{c_p + L_v\\overline{\\alpha} \\overline{q^*}}\\frac{T(x) \\delta \\kappa(x)}{\\delta \\overline{z}}$$\n",
    "\n",
    "This is shown by the blue line below.\n",
    "\n",
    "We can also replace $T(x)$ with $\\overline{T}$:\n",
    "\n",
    "$$\\lambda_2 \\approx (1+\\frac{\\overline{T}\\delta \\overline{\\kappa}}{\\delta \\overline{z}})\\frac{c_p + L_v\\alpha(x) q^*(x)}{c_p + L_v\\overline{\\alpha} \\overline{q^*}}\\frac{\\delta z(x)}{\\delta \\overline{z}} - \n",
    "\\frac{c_p + L_v\\alpha(x) q^*(x)}{c_p + L_v\\overline{\\alpha} \\overline{q^*}}\\frac{\\overline{T} \\delta \\kappa(x)}{\\delta \\overline{z}}$$\n",
    "\n",
    "This is shown by the dashed dark blue line below."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "save_lambda_2_beta_approx_fig = False\n",
    "fig, ax = plt.subplots(1, 1, figsize=(width['one_col'], width['one_col'] / ar))\n",
    "ax.plot(quant_plot, np.average(lambda_2_num['sim'] / lambda_2_denom['sim'][:, np.newaxis], weights=lat_weights, axis=0), \n",
    "        color='k', label=labels_use[0])\n",
    "ax.plot(quant_plot, np.average(lambda_z_prefactor['lapse'] * z_delta['x'] / z_delta['mean'][:, np.newaxis] + \n",
    "                                   lambda_kappa_prefactor['lapse'] * kappa_delta['x']['lapse'] / kappa_delta['mean']['lapse'][:, np.newaxis], \n",
    "                                   weights=lat_weights, axis=0), default_colors[1], label=labels_use[2])\n",
    "\n",
    "labels_beta_approx = ['Taylor in $\\\\beta$ ($\\mu_{\\kappa}(x)\\\\neq\\overline{\\mu_{\\kappa}}$)', \n",
    "                      '$\\\\beta \\\\approx \\\\frac{\\overline{T}\\delta \\overline{\\kappa}}{\\delta \\overline{z}}$', \n",
    "                      '$g\\overline{\\kappa} \\\\approx 0$', '$T(x) \\\\approx \\overline{T}$']    \n",
    "args_beta_approx = [[True, False, True], [True, False, True, 'simple'], \n",
    "                    [True, False, True, 'simple', True], [True, False, True, 'simple', True, True]]\n",
    "\n",
    "for i in range(len(labels_beta_approx)):\n",
    "    z_prefactor_use, kappa_prefactor_use = get_lambda2_prefactors(*args_beta_approx[i])\n",
    "    ax.plot(quant_plot, np.average(z_prefactor_use * z_delta['x'] / z_delta['mean'][:, np.newaxis] + \n",
    "                                   kappa_prefactor_use * kappa_delta['x']['lapse'] / kappa_delta['mean']['lapse'][:, np.newaxis], \n",
    "                                   weights=lat_weights, axis=0), color=colors_approx[2+i], label=labels_beta_approx[i], linestyle='--')\n",
    "\n",
    "ax.axhline(1, color='k', lw=ax_linewidth)\n",
    "ax.legend(fontsize=6)\n",
    "ax.set_xlim(0, 100)\n",
    "ax.set_ylabel('$\\lambda_2 = \\delta h^*_{FT}(x) / \\delta \\overline{h^*_{FT}}$')\n",
    "ax.set_xlabel('Near surface temperature percentile, $x$')\n",
    "if save_fig or save_lambda_2_beta_approx_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/lambda_2_beta_approx.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:44:18.938787Z",
     "start_time": "2024-03-25T15:44:18.835503Z"
    }
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Final Approximation\n",
    "The dashed dark blue line above seems quite a good approximation to the solid orange line (it is actually closer to the solid black line than the solid orange line is, but this is due to a cancellation of errors). So below, I look at the different contributions to it.\n",
    "\n",
    "The dashed lines ignore the prefactors."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "save_lambda_2_final_approx_fig = False\n",
    "fig, ax = plt.subplots(1, 1, figsize=(width['one_col'], width['one_col'] / ar))\n",
    "ax.plot(quant_plot, np.average(lambda_2_num['sim'] / lambda_2_denom['sim'][:, np.newaxis], weights=lat_weights, axis=0), \n",
    "        color='k', label=labels_use[0])\n",
    "z_prefactor_use, kappa_prefactor_use = get_lambda2_prefactors(*args_beta_approx[-1])\n",
    "ax.plot(quant_plot, np.average(z_prefactor_use * z_delta['x'] / z_delta['mean'][:, np.newaxis] + \n",
    "                                   kappa_prefactor_use * kappa_delta['x']['lapse'] / kappa_delta['mean']['lapse'][:, np.newaxis], \n",
    "                                   weights=lat_weights, axis=0), color='k', label='Approximation', linestyle=':')\n",
    "ax.plot(quant_plot, np.average(z_prefactor_use * z_delta['x'] / z_delta['mean'][:, np.newaxis], \n",
    "                                   weights=lat_weights, axis=0), color=default_colors[0], label='$z$ contribution')\n",
    "ax.plot(quant_plot, np.average(z_delta['x'] / z_delta['mean'][:, np.newaxis], weights=lat_weights, axis=0), \n",
    "        color=default_colors[0], linestyle='--')\n",
    "ax.plot(quant_plot, np.average(kappa_prefactor_use * kappa_delta['x']['lapse'] / kappa_delta['mean']['lapse'][:, np.newaxis], \n",
    "                                   weights=lat_weights, axis=0), color=default_colors[1], label='$\\kappa$ contribution')\n",
    "ax.plot(quant_plot, np.average(-temp_mean[0, 0][:, np.newaxis] * kappa_delta['x']['lapse'] / z_delta['mean'][:, np.newaxis], \n",
    "                               weights=lat_weights, axis=0), color=default_colors[1], linestyle='--')\n",
    "ax.plot(quant_plot, np.average((c_p + L_v * alpha_x * q_x) / (c_p + L_v * alpha_mean * q_mean)[:, np.newaxis], weights=lat_weights, axis=0),\n",
    "        color=default_colors[2], label='$\\\\frac{c_p + L_v\\\\alpha(x) q^*(x)}{c_p + L_v\\overline{\\\\alpha} \\overline{q^*}}$')\n",
    "ax.scatter(1, np.average(1+temp_mean[0, 0] * kappa_delta['mean']['lapse'] / z_delta['mean'], weights=lat_weights, axis=0), \n",
    "           color=default_colors[0], marker='x', s=10)\n",
    "\n",
    "ax.axhline(1, color='k', lw=ax_linewidth)\n",
    "ax.legend(fontsize=6, loc='lower right')\n",
    "ax.set_xlim(0, 100)\n",
    "ax.set_ylabel('$\\lambda_2 = \\delta h^*_{FT}(x) / \\delta \\overline{h^*_{FT}}$')\n",
    "ax.set_xlabel('Near surface temperature percentile, $x$')\n",
    "\n",
    "if save_fig or save_lambda_2_final_approx_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/lambda_2_final_approx.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:50:19.054917Z",
     "start_time": "2024-03-25T15:50:18.961257Z"
    }
   },
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## $\\delta z$ and $\\delta \\Gamma$ contributions to $\\delta T(x)$\n",
    "The above is looking at the dynamic ($\\delta z$) and thermodynamic $\\delta \\kappa$ contributions to $\\lambda_2$. However, we want a theory for the change in near-surface temperature, $\\delta T(x)$.\n",
    "\n",
    "Linking the surface and 500hPa level, we can write the exact equation: $T(x) = z_{500}(x)\\Gamma(x) +  T_{500}(x) = z_{500}\\left(\\Gamma(x) + \\frac{1}{\\kappa(x)}\\right)$\n",
    "\n",
    "Doing a binomial expansion, we can approximate $\\kappa(x) \\approx \\overline{\\kappa} + 0.5 \\left(\\frac{\\Gamma(x)}{\\overline{\\Gamma}}-1\\right)\\overline{\\Gamma}\\overline{\\kappa}^2$\n",
    "\n",
    "Then doing a Taylor expansion, we get: $\\frac{1}{\\kappa(x)} \\approx \\frac{1}{\\overline{\\kappa}}\\left(1 - \\frac{\\overline{\\kappa}}{2}(\\Gamma(x)-\\overline{\\Gamma})\\right)$\n",
    "\n",
    "Subbing in and using $\\overline{\\kappa} = \\frac{\\overline{z}}{\\overline{T_{500}}} = \\frac{\\overline{z}}{\\overline{T} - \\overline{\\Gamma}\\overline{z}}$, we get:\n",
    "\n",
    "$T(x) \\approx \\frac{z(x)}{\\overline{z}}\\overline{T} + \\frac{1}{2}z(x)(\\Gamma(x) - \\overline{\\Gamma})$\n",
    "\n",
    "This is shown as the dashed line in the top plot below. It is a pretty good approximation. The dotted line using the $\\kappa$ formula and no taylor expansion is shown by the dotted line.\n",
    "\n",
    "Then from this, we get three terms in the $\\delta T(x)$ equation: a change in the mean climate (dotted), a change in the lapse rate (dashed) and a change in the dynamics (dashed-dotted).\n",
    "\n",
    "$\\delta T(x) = \\frac{z(x)}{\\overline{z}}\\delta \\overline{T} + \\frac{1}{2}\\frac{z(x)}{\\overline{z}}\\delta (\\overline{z}(\\Gamma(x) - \\overline{\\Gamma})) + [\\overline{T} + \\frac{1}{2}\\overline{z}(\\Gamma(x) - \\overline{\\Gamma})] \\delta \\left(\\frac{z(x)}{\\overline{z}}\\right)$\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "save_delta_temp_theory_fig = False\n",
    "temp_delta_theory_cont = {'T': z_quant3[0]/z_mean[0][:, np.newaxis] * (temp_mean[1, 1]-temp_mean[0, 1])[:, np.newaxis],\n",
    "                   'lapse': 0.5 * z_quant3[0]/z_mean[0][:, np.newaxis] * np.diff(z_mean[:, :, np.newaxis] * (\n",
    "                           lapse_quant3-lapse_mean[:, :, np.newaxis]), axis=0)[0], \n",
    "                   'z': (temp_mean[0, 1][:, np.newaxis] + 0.5 * z_mean[0][:, np.newaxis] * (lapse_quant3[0]-lapse_mean[0, :, np.newaxis])\n",
    "                         ) * np.diff(z_quant3/z_mean[:, :, np.newaxis], axis=0)[0]}\n",
    "temp_delta_theory_cont['all'] = temp_delta_theory_cont['T'] + temp_delta_theory_cont['lapse'] + temp_delta_theory_cont['z']\n",
    "fig, ax = plt.subplots(2, 1, figsize=(width['one_col'], 2 * width['one_col'] / ar), sharex=True)\n",
    "for i in range(n_exp):\n",
    "    ax[0].plot(quant_plot, np.average(temp_quant3[i, 1], axis=0, weights=lat_weights), color=default_colors[i], label=f'$\\\\tau={tau_lw[i]}$')\n",
    "    ax[0].plot(quant_plot, np.average(z_quant3[i]*(lapse_quant3[i]+1/kappa_quant3[i]), axis=0, weights=lat_weights), \n",
    "             color=default_colors[i], linestyle=':')\n",
    "    ax[0].plot(quant_plot, np.average(z_quant3[i]*((temp_mean[i, 1]/z_mean[i])[:, np.newaxis] + 0.5*(lapse_quant3[i]+ - lapse_mean[i][:, np.newaxis])),\n",
    "                                    axis=0, weights=lat_weights), color=default_colors[i], linestyle='--')\n",
    "ax[0].legend(fontsize=5)\n",
    "ax[0].set_ylabel('Near-surface Temperature, $T$ [K]')\n",
    "\n",
    "ax[1].plot(quant_plot, np.average(temp_quant3[1, 1]-temp_quant3[0, 1], weights=lat_weights, axis=0), label='Simulated', color='r')\n",
    "ax[1].plot(quant_plot, np.average(temp_delta_theory_cont['all'], weights=lat_weights, axis=0), color='k', label='Theory')\n",
    "ax[1].plot(quant_plot, np.average(temp_delta_theory_cont['T'], weights=lat_weights, axis=0), color='k', linestyle=':', \n",
    "           label='$\\delta \\overline{T}$')\n",
    "ax[1].plot(quant_plot, np.average(temp_delta_theory_cont['lapse'], weights=lat_weights, axis=0), color='k', linestyle='--', \n",
    "           label='$\\delta \\Gamma$')\n",
    "ax[1].plot(quant_plot, np.average(temp_delta_theory_cont['z'], weights=lat_weights, axis=0), color='k', linestyle='-.', \n",
    "           label='$\\delta z$')\n",
    "ax[1].axhline(0, color='k', lw=ax_linewidth)\n",
    "ax[1].legend(fontsize=5)\n",
    "ax[1].set_ylabel('$\\delta T$ [K]')\n",
    "ax[1].set_xlabel('Near surface temperature percentile, $x$')\n",
    "ax[0].set_xlim(0, 100)\n",
    "\n",
    "if save_fig or save_delta_temp_theory_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/delta_temp_theory.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:48:21.718580Z",
     "start_time": "2024-03-25T15:48:21.572074Z"
    }
   },
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Geostrophic Winds\n",
    "Below, I see if the geostrophic winds are a good approximation at the free troposphere level."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "save_v_geo_fig = False\n",
    "fig, ax = plt.subplots(1,1, figsize=(width['one_col'], width['one_col']/ar))\n",
    "for i in range(n_exp):\n",
    "    ax.plot(quant_plot, np.average(v_quant3[i], axis=0, weights=lat_weights), color=default_colors[i], label=f'$\\kappa={tau_lw[i]}$')\n",
    "    ax.plot(quant_plot, np.average(v_geo_quant3[i], axis=0, weights=lat_weights), color=default_colors[i], linestyle=':')\n",
    "    if plot_include_p:\n",
    "        ax.plot(quant_plot, np.average(v_p_quant3[i], axis=0, weights=lat_weights), color=default_colors[i], alpha=0.4, linestyle='--')\n",
    "ax.set_xlim(0, 100)\n",
    "ax.legend()\n",
    "ax.set_ylabel('$|v|$ [m/s]' if take_abs_v else '$v$ [m/s]')\n",
    "ax.set_xlabel('Near surface temperature percentile, $x$')\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_fig or save_v_geo_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/v_geo.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:44:19.224743Z",
     "start_time": "2024-03-25T15:44:19.158597Z"
    }
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "save_u_geo_fig = False\n",
    "fig, ax = plt.subplots(1,1, figsize=(width['one_col'], width['one_col']/ar))\n",
    "for i in range(n_exp):\n",
    "    ax.plot(quant_plot, np.average(u_quant3[i], axis=0, weights=lat_weights), color=default_colors[i], label=f'$\\kappa={tau_lw[i]}$')\n",
    "    ax.plot(quant_plot, np.average(u_geo_quant3[i], axis=0, weights=lat_weights), color=default_colors[i], linestyle=':')\n",
    "    if plot_include_p:\n",
    "        ax.plot(quant_plot, np.average(u_p_quant3[i], axis=0, weights=lat_weights), color=default_colors[i], alpha=0.4, linestyle='--')\n",
    "ax.set_xlim(0, 100)\n",
    "ax.legend()\n",
    "ax.set_ylabel('$|u|$ [m/s]' if take_abs_u else '$u$ [m/s]')\n",
    "ax.set_xlabel('Near surface temperature percentile, $x$')\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_fig or save_u_geo_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/u_geo.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:44:19.292366Z",
     "start_time": "2024-03-25T15:44:19.228207Z"
    }
   },
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Consider a single time, to see if geostrophic approximation is valid"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tau_ind_st = 0\n",
    "time_ind_st = 1150\n",
    "# time_ind_st = 1060\n",
    "# pressure_ft_ind = int(np.abs(ds[0].pfull-300).argmin())\n",
    "pressure_ft_ind_gradient_calc = [pressure_ft_ind-1, pressure_ft_ind, pressure_ft_ind+1]\n",
    "ds_st = {}\n",
    "ds_st['low'] = ds[tau_ind_st].isel(pfull=pressure_ft_ind_gradient_calc\n",
    "                                   ).sel(time=time_ind_st, method='nearest')[['height', 'vcomp', 'ucomp', 'ps']].load()\n",
    "ds_st['high'] = isca_tools.load_dataset('aquaplanet/high_res/').isel(pfull=pressure_ft_ind_gradient_calc\n",
    "                                   ).sel(time=time_ind_st, method='nearest')[['height', 'vcomp', 'ucomp', 'ps']].load()\n",
    "wind_sigma_adjustment = {}\n",
    "for key in ds_st:\n",
    "    wind_sigma_adjustment[key] = np.gradient(ds_st[key].height, sigma_levels[pressure_ft_ind_gradient_calc], axis=0)[1,:,:]\n",
    "    ds_st[key] = ds_st[key].isel(pfull=1)       # only keep the one pressure level after computing gradient with sigma\n",
    "    wind_sigma_adjustment[key] = wind_sigma_adjustment[key] * sigma_level_ft * grad_x(\n",
    "        np.log(ds_st[key].ps), ds_st[key].lat, ds_st[key].lon, -2, -1)\n",
    "wind_plot_spacing = {'low': 1, 'high': 2}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:44:19.513227Z",
     "start_time": "2024-03-25T15:44:19.293029Z"
    }
   },
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for key in ds_st:\n",
    "    u_geo_st, v_geo_st = get_geostrophic_wind(ds_st[key].height, ds_st[key].lat, ds_st[key].lon)\n",
    "    # v_geo_st2 = get_geostrophic_v(ds_st.height.to_numpy()[:, :, np.newaxis], ds_st.lon, ds_st.lat, 'forward').squeeze()\n",
    "    # fig, ax = plt.subplots(1,1, figsize=(width['one_col'], width['one_col']/ar))\n",
    "    fig, ax = plt.subplots(1,1, figsize=(7, 5))\n",
    "    im = ax.pcolormesh(ds_st[key].lon, ds_st[key].lat, ds_st[key].height)\n",
    "    pu, pv = (ds_st[key].ucomp[::wind_plot_spacing[key],::wind_plot_spacing[key]], \n",
    "              ds_st[key].vcomp[::wind_plot_spacing[key],::wind_plot_spacing[key]])\n",
    "    ax.quiver(ds_st[key].lon[::wind_plot_spacing[key]], ds_st[key].lat[::wind_plot_spacing[key]], pu, pv, alpha=0.5, scale=800)\n",
    "    pu, pv = u_geo_st[::wind_plot_spacing[key],::wind_plot_spacing[key]], v_geo_st[::wind_plot_spacing[key],::wind_plot_spacing[key]]\n",
    "    ax.quiver(ds_st[key].lon[::wind_plot_spacing[key]], ds_st[key].lat[::wind_plot_spacing[key]], pu, pv, alpha=0.5, scale=800, color='r')\n",
    "    plt.colorbar(im, ax=ax, label='$z$ [m]')\n",
    "    ax.set_ylim(25, 70)\n",
    "    ax.set_xlim(40, 110)\n",
    "    # ax.set_ylim(10, 50)\n",
    "    # ax.set_xlim(150, 250)\n",
    "    ax.set_xlabel('Lon [deg]')\n",
    "    ax.set_ylabel('Lat [deg]')\n",
    "    ax.set_title(\"{} resolution: $\\kappa={:.1f}$; time={:.0f} days; p={:.0f}hPa\".format(key, tau_lw[tau_ind_st], \n",
    "                                                                                        ds_st[key].time-0.5, ds_st[key].pfull))\n",
    "    plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:44:19.514031Z",
     "start_time": "2024-03-25T15:44:19.513979Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Is there a relationship between $z(x) - [\\overline{z}]$ and $v(x)$?\n",
    "If the wind where in geostrophic balance, then at a single latitude: $v_g(x) \\propto \\partial z / \\partial x$. If we also have $\\partial z / \\partial x \\propto z(x) - [\\overline{z}]$, then we have $v_g(x) \\propto z(x) - [\\overline{z}]$, where the overline is an average over longitude, anmd the square brackets indicate an average over time.\n",
    "\n",
    "Below, I consider a single latitude to test this.\n",
    "\n",
    "There doesn't seem to be that clear a relationship between $v_g(x)$ and $z(x) - [\\overline{z}]$, except that hotter days appear to have a smaller standard deviation in $v_g$.\n",
    "\n",
    "So I don't think we can use $z(x) - [\\overline{z}]$ to predict $v_g$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tau_ind_scatter = 0\n",
    "lat_ind_scatter = -4\n",
    "z_grad_x_use = grad_x(ds_z_ft[tau_ind_scatter], ds_z_ft[tau_ind_scatter].lat,\n",
    "                      ds_z_ft[tau_ind_scatter].lon, lat_axis=0, lon_axis=1)[lat_keep_ind[lat_ind_scatter]].flatten()\n",
    "z_diff_zonal_mean = (ds_z_ft[tau_ind_scatter][lat_keep_ind] - ds_z_ft[tau_ind_scatter][lat_keep_ind].mean(dim='lon'))\n",
    "if season == 'summer':\n",
    "    z_diff_zonal_mean = get_summer_ds(z_diff_zonal_mean)\n",
    "z_diff_zonal_mean = z_diff_zonal_mean[lat_ind_scatter].to_numpy().flatten()\n",
    "u_geo_scatter, v_geo_scatter = get_geostrophic_wind(ds_z_ft[tau_ind_scatter], ds_z_ft[tau_ind_scatter].lat,\n",
    "                                                    ds_z_ft[tau_ind_scatter].lon, lat_axis=0, lon_axis=1)\n",
    "if season == 'summer':\n",
    "    ds_use = ds_z_ft[0].copy(deep=True)\n",
    "    ds_use.values = u_geo_scatter\n",
    "    u_geo_scatter = get_summer_ds(ds_use).to_numpy()\n",
    "    ds_use.values = v_geo_scatter\n",
    "    v_geo_scatter = get_summer_ds(ds_use).to_numpy()\n",
    "u_geo_scatter = u_geo_scatter[lat_keep_ind[lat_ind_scatter]].flatten()\n",
    "v_geo_scatter = v_geo_scatter[lat_keep_ind[lat_ind_scatter]].flatten()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T15:44:19.514522Z",
     "start_time": "2024-03-25T15:44:19.514475Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ds_use = ds_all[tau_ind_scatter].isel(lat = lat_ind_scatter)\n",
    "\n",
    "# fig, ax = plt.subplots(2,1, figsize=(width['one_col'], 2*width['one_col']/ar))\n",
    "fig, ax = plt.subplots(2,1, figsize=(7, 8), sharey=True, sharex=True)\n",
    "ax[0].scatter(v_geo_scatter, (ds_use.height[0] - ds_use.height[0].mean()).to_numpy().flatten(), c=ds_use.temp[1], alpha=0.1)\n",
    "im = ax[1].scatter(ds_use.vcomp[0], (ds_use.height[0] - ds_use.height[0].mean()).to_numpy().flatten(), c=ds_use.temp[1], alpha=0.1)\n",
    "ax[0].set_xlabel('$v_g$ [m/s]')\n",
    "ax[1].set_xlabel('$v$ [m/s]')\n",
    "fig.supylabel('$z - [\\\\bar{z}]$ [m]', fontsize=7)\n",
    "ax[0].set_title(f'$\\kappa = {tau_lw[tau_ind_scatter]}$; Lat={round(float(ds_use.lat),1)}$\\degree$')\n",
    "plt.tight_layout()\n",
    "cbar_ax = fig.add_axes([0.99, 0.12, 0.01, 0.7])     # add axes for colorbar\n",
    "fig.colorbar(im, cax=cbar_ax, label='$T$ [K]', aspect=100, pad=0.01, fraction=0.01);"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Geostrophic Approximation\n",
    "Below I check whether the geostrophic approximation is reasonable at this latitude i.e. whether $v \\approx v_{g}$.\n",
    "\n",
    "There is a clear trend, so if we can predict $v_g$, we can say a lot about $v$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# fig, ax = plt.subplots(2,1, figsize=(width['one_col'], 2*width['one_col']/ar))\n",
    "fig, ax = plt.subplots(2,1, figsize=(7, 8))\n",
    "ax[0].scatter(ds_use.ucomp[0], u_geo_scatter, c=ds_use.temp[1], alpha=0.1)\n",
    "im = ax[1].scatter(ds_use.vcomp[0], v_geo_scatter, c=ds_use.temp[1], alpha=0.1)\n",
    "ax[0].set_xlabel('$u$ [m/s]')\n",
    "ax[0].set_ylabel('$u_g$ [m/s]')\n",
    "ax[1].set_xlabel('$v$ [m/s]')\n",
    "ax[1].set_ylabel('$v_g$ [m/s]')\n",
    "ax[0].set_title(f'$\\kappa = {tau_lw[tau_ind_scatter]}$; Lat={round(float(ds_use.lat),1)}$\\degree$')\n",
    "for i in range(2):\n",
    "    ax[i].plot(np.arange(-100, 100), np.arange(-100, 100), color='r')\n",
    "    ax[i].hlines(0, -100, 100, color='k', lw=ax_linewidth)\n",
    "    ax[i].vlines(0, -100, 100, color='k', lw=ax_linewidth)\n",
    "ax[0].set_xlim(-np.abs(ds_use.ucomp[0]).max(), np.abs(ds_use.ucomp[0]).max())\n",
    "ax[0].set_ylim(-np.abs(ds_use.ucomp[0]).max(), np.abs(ds_use.ucomp[0]).max())\n",
    "ax[1].set_xlim(-np.abs(ds_use.vcomp[0]).max(), np.abs(ds_use.vcomp[0]).max())\n",
    "ax[1].set_ylim(-np.abs(ds_use.vcomp[0]).max(), np.abs(ds_use.vcomp[0]).max())\n",
    "plt.tight_layout()\n",
    "cbar_ax = fig.add_axes([0.99, 0.12, 0.01, 0.7])     # add axes for colorbar\n",
    "fig.colorbar(im, cax=cbar_ax, label='$T$ [K]', aspect=100, pad=0.01, fraction=0.01);"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using just zonal mean, $\\overline{z}$\n",
    "\n",
    "Here I see if there is a relationship between $z-\\overline{z}$ and $v_g$ and $v$. There seems to be a clear circular relationship here: $v_g^2 + (z-\\overline{z})^2 = C(T)$, with the constant $C$ increasing as near-surface temperature, $T$, decreases.\n",
    "\n",
    "This makes sense because on a given day, when $z$ is a maxima or minima, $v_g \\propto \\partial z / \\partial x = 0$. I.e. large $|z-\\overline{z}|$ must go with a small $|v_g|$.\n",
    " \n",
    "Equally, when $z=\\overline{z}$, $\\partial z / \\partial x$ is going to be large because at longitudes either side, $z$ will not equal the mean value. I.e. small $|z-\\overline{z}|$ must go with a large $|v_g|$.\n",
    "\n",
    "$C(T)$ increases with decreasing near-surface temperature because there are stronger weather systems on the cold days, so a larger range in $z-\\overline{z}$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# fig, ax = plt.subplots(2,1, figsize=(width['one_col'], 2*width['one_col']/ar))\n",
    "fig, ax = plt.subplots(2,1, figsize=(7, 8), sharey=True, sharex=True)\n",
    "ax[0].scatter(v_geo_scatter, z_diff_zonal_mean, c=ds_use.temp[1], alpha=0.1)\n",
    "im = ax[1].scatter(ds_use.vcomp[0], z_diff_zonal_mean, c=ds_use.temp[1], alpha=0.1)\n",
    "ax[0].set_xlabel('$v_g$ [m/s]')\n",
    "ax[1].set_xlabel('$v$ [m/s]')\n",
    "fig.supylabel('$z - \\overline{z}$ [m]', fontsize=7)\n",
    "ax[0].set_title(f'$\\kappa = {tau_lw[tau_ind_scatter]}$; Lat={round(float(ds_use.lat),1)}$\\degree$')\n",
    "for i in range(2):\n",
    "    ax_lim = [ax[i].get_xlim(), ax[i].get_ylim()]\n",
    "    ax[i].hlines(0, ax_lim[0][0], ax_lim[0][1], color='k', lw=ax_linewidth)\n",
    "    ax[i].vlines(0, ax_lim[1][0], ax_lim[1][1], color='k', lw=ax_linewidth)\n",
    "    ax[i].set_xlim(ax_lim[0])\n",
    "    ax[i].set_ylim(ax_lim[1])\n",
    "plt.tight_layout()\n",
    "cbar_ax = fig.add_axes([0.99, 0.12, 0.01, 0.7])     # add axes for colorbar\n",
    "fig.colorbar(im, cax=cbar_ax, label='$T$ [K]', aspect=100, pad=0.01, fraction=0.01);"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Relationship between $z(x) - [\\overline{z}]$ and $z(x) - \\overline{z}$\n",
    "Below, I see if we can somehow relate $z(x) - [\\overline{z}]$ and $z(x) - \\overline{z}$. It doesn't seem particularly obvious."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(7, 5))\n",
    "im = ax.scatter(z_diff_zonal_mean, (ds_use.height[0] - ds_use.height[0].mean()).to_numpy().flatten(), c=ds_use.temp[1], alpha=0.1)\n",
    "ax.set_ylabel('$z - [\\\\bar{z}]$ [m]')\n",
    "ax.set_xlabel('$z - \\overline{z}$ [m]')\n",
    "ax.set_title(f'$\\kappa = {tau_lw[tau_ind_scatter]}$; Lat={round(float(ds_use.lat),1)}$\\degree$')\n",
    "plt.tight_layout()\n",
    "cbar_ax = fig.add_axes([0.99, 0.12, 0.01, 0.7])     # add axes for colorbar\n",
    "fig.colorbar(im, cax=cbar_ax, label='$T$ [K]', aspect=100, pad=0.01, fraction=0.01);"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
