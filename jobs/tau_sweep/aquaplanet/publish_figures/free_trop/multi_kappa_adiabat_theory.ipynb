{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Publishing Figures - Multi Kappa\n",
    "This notebook is for generating extratropic specific plots, combining all $\\kappa$ simulations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "# REMOTE - So can access functions in isca_tools which is in home/Isca directory\n",
    "# sys.path.append(os.path.join(os.environ['HOME'], 'Isca'))\n",
    "# LOCAL - So can access functions in isca_tools which is in StAndrews/Isca\n",
    "sys.path.append(os.environ['PWD'])\n",
    "import isca_tools\n",
    "from isca_tools.utils.moist_physics import clausius_clapeyron_factor, sphum_sat, moist_static_energy\n",
    "from isca_tools.convection.base import convection_neutral_profile, lcl_temp_bolton, dry_profile_pressure, lapse_moist, lapse_dry\n",
    "from isca_tools.utils.constants import L_v, c_p, g, R\n",
    "from isca_tools.utils.stats import z_score_from_confidence_interval\n",
    "from isca_tools.utils import area_weight_mean_lat, area_weighting\n",
    "from isca_tools.thesis.adiabat_theory import (get_delta_temp_quant_theory, get_temp_adiabat, get_theory_prefactor_terms,\n",
    "                                              get_delta_temp_quant_theory_simple, decompose_temp_adiabat_anomaly, get_delta_temp_quant_theory_simple2)\n",
    "from isca_tools.papers.byrne_2021 import get_quant_ind\n",
    "from isca_tools.plot import label_subplots\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import scipy.optimize\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy_indexed\n",
    "plt.style.use('/Users/joshduffield/Documents/StAndrews/Isca/jobs/tau_sweep/aquaplanet/publish_figures/publish.mplstyle')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:47:08.280077Z",
     "start_time": "2024-05-08T15:47:05.715183Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 16:47:05,724 - isca - WARNING - Environment variable GFDL_SOC not set, but this is only required if using SocratesCodebase. Setting to None\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "# Load dataset\n",
    "var_keep = ['temp', 'sphum', 'height', 'convflag', 'klzbs']\n",
    "# var_keep = ['temp', 'sphum', 'height']\n",
    "exp_dir = 'tau_sweep/aquaplanet/depth=1/'\n",
    "# exp_dir = 'tau_sweep/aquaplanet/'\n",
    "exp_names = [dir for dir in os.listdir(os.path.join(os.environ['GFDL_DATA'],exp_dir)) if dir[0]=='k']\n",
    "exp_names.sort()\n",
    "# exp_names = exp_names[2:-1]     # get rid of coldest 2 and warmest simulation as don't work well\n",
    "n_exp = len(exp_names)\n",
    "ds = []\n",
    "albedo = []\n",
    "tau_sw = []\n",
    "tau_lw = []\n",
    "for i in tqdm(range(n_exp)):\n",
    "    ds_use = isca_tools.load_dataset(exp_dir + exp_names[i])[var_keep]\n",
    "    ds += [ds_use]\n",
    "    namelist = isca_tools.load_namelist(exp_dir + exp_names[i])  # Need this for albedo_value\n",
    "    albedo += [namelist['mixed_layer_nml']['albedo_value']]\n",
    "    tau_sw += [namelist['two_stream_gray_rad_nml']['atm_abs']]\n",
    "    tau_lw += [namelist['two_stream_gray_rad_nml']['odp']]\n",
    "tau_lw = np.asarray(tau_lw)\n",
    "p_surface = float(ds[0].pfull[-1]) * 100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T15:47:16.116908Z",
     "start_time": "2024-05-08T15:47:08.281239Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [00:07<00:22,  3.80s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Sigma levels\n",
    "np.convolve(namelist['vert_coordinate_nml']['bk'], np.ones(2)/2, 'valid')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get datasets\n",
    "Get one dataset for each $\\kappa$, combining the desired latitudes: `ds_all`. This combines all or just the summer months in each hemisphere, e.g. negative latitudes will only correspond to times in December, January or February."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# If true, will save all figures to desktop - option to save specific figures later on.\n",
    "save_fig = False\n",
    "# if publishing figure, use high dpi\n",
    "publish_fig = True\n",
    "\n",
    "ar = 4/3        # aspect ratio (width/height)\n",
    "# Details required for Journal of Climate Figures\n",
    "low_dpi = 100\n",
    "dpi = {'monochrome': 1100, 'combination': 800, 'halftone': 300}\n",
    "width = {'one_col': 3.2, 'two_col': 5.5}        # width in inches \n",
    "save_pad_inches = 0.05\n",
    "\n",
    "# Default parameters\n",
    "default_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "ax_linewidth = plt.rcParams['axes.linewidth']\n",
    "\n",
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Compute Global Average Surface Temperature and get near surface temperature data\n",
    "# Use all data after 2 years, as clearly converged from the above spin up plot\n",
    "use_time_start = 360*2\n",
    "pressure_ft = 500           # Desired approximate pressure of free troposphere (hPa)\n",
    "\n",
    "# Tropics\n",
    "# region = 'tropics'\n",
    "# lat_min = 0\n",
    "# lat_max = 20\n",
    "# Extratropics\n",
    "region = 'extratropics'\n",
    "lat_min = 40\n",
    "lat_max = 65\n",
    "# Poles\n",
    "# region = 'High Latitudes'\n",
    "# lat_min = 70\n",
    "# lat_max = 90\n",
    "# region = 'Global'\n",
    "# lat_min = 0\n",
    "# lat_max = 90\n",
    "\n",
    "# Chose whether to only consider summer days or consider all days\n",
    "# season = 'all'\n",
    "season = 'summer'\n",
    "# season = 'winter'\n",
    "if season == 'summer':\n",
    "    if region == 'tropics':\n",
    "        season_months = {'nh': [5, 6, 7, 8, 9, 10], 'sh': [11, 12, 1, 2, 3, 4]}   \n",
    "    else:\n",
    "        season_months = {'nh': [6, 7, 8], 'sh': [12, 1, 2]}   # JJA for NH and DJF for SH\n",
    "elif season == 'winter':\n",
    "    if region == 'tropics':\n",
    "        season_months = {'sh': [5, 6, 7, 8, 9, 10], 'nh': [11, 12, 1, 2, 3, 4]}\n",
    "    else:\n",
    "        season_months = {'sh': [6, 7, 8], 'nh': [12, 1, 2]} \n",
    "\n",
    "ds_all = []\n",
    "with tqdm(total=n_exp, position=0, leave=True) as pbar:\n",
    "    for i in range(n_exp):\n",
    "        ds_use = ds[i].sel(time=slice(use_time_start, np.inf))\n",
    "        ds_use = ds_use.sel(pfull=[np.inf, pressure_ft], method='nearest')      # only keep the surface values - get rid of pfull coordinate\n",
    "        ds_use = ds_use.where((np.abs(ds_use.lat) <= lat_max) & (np.abs(ds_use.lat) >= lat_min), drop=True)\n",
    "\n",
    "        if season == 'summer' or season == 'winter':\n",
    "            # Only consider summer as has expected circulation\n",
    "            ds_nh_summer = isca_tools.utils.annual_time_slice(ds_use, season_months['nh']).sel(lat=slice(lat_min, lat_max)) \n",
    "            ds_sh_summer = isca_tools.utils.annual_time_slice(ds_use, season_months['sh']).sel(lat=slice(-lat_max, -lat_min))  \n",
    "            # Combine hemispheres and average over longitude, time and latitude.\n",
    "            # Note that April, May, June, October, November and December will not be included in this dataset\n",
    "            ds_use = xr.concat([ds_sh_summer, ds_nh_summer], dim='lat')\n",
    "        ds_use = ds_use.stack(lon_time=(\"lon\",\"time\"), create_index=False).chunk(dict(lon_time=-1))\n",
    "        ds_all += [ds_use.load()]\n",
    "        pbar.update(1)\n",
    "\n",
    "ind_surf = 0\n",
    "ind_ft = 1\n",
    "p_surface = float(ds_all[0].pfull[ind_surf]) * 100\n",
    "pressure_ft_actual = float(ds_all[0].pfull[ind_ft]) * 100       # Actual pressure of free troposphere (Pa)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Near Surface Temperature Quantile\n",
    "Get variables as a function of near-surface temperature quantile"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "quantiles_all = np.arange(1, 100)\n",
    "percentile_label = 'Temperature percentile, $x$'\n",
    "n_quant_all = len(quantiles_all)\n",
    "n_lat = len(ds_all[0].lat)\n",
    "n_pressure = ds_all[0].pfull.shape[0]\n",
    "lat_weights = np.cos(np.deg2rad(ds_all[0].lat))     # latitude area weighting is just the cosine\n",
    "lnp_const = R * np.log(p_surface/pressure_ft_actual)/2      # for modified MSE calculation\n",
    "\n",
    "# Days must have klzb < thresh and convflag > thresh to be considered convecting.\n",
    "klzb_thresh = 13\n",
    "convflag_thresh = 1\n",
    "\n",
    "temp_mean = np.zeros((n_exp, n_pressure, n_lat))         # second index: 0 is surface, 1 is free trop\n",
    "mse_mod_mean = np.zeros((n_exp, n_lat))\n",
    "mse_mean = np.zeros((n_exp, n_lat))\n",
    "# 2 different methods for computing r_mean and sphum_mean - q calculates from sphum, while r calculates from rh.\n",
    "sphum_mean = {'q': np.zeros((n_exp, n_lat)), 'r': np.zeros((n_exp, n_lat))}\n",
    "r_mean = {'q': np.zeros((n_exp, n_lat)), 'r': np.zeros((n_exp, n_lat))}\n",
    "z_mean = np.zeros((n_exp, n_lat))\n",
    "\n",
    "# as function of temperature quantile\n",
    "temp_quant3 = np.zeros((n_exp, n_pressure, n_lat, n_quant_all))\n",
    "mse_mod_quant3 = np.zeros((n_exp, n_lat, n_quant_all))\n",
    "mse_quant3 = np.zeros((n_exp, n_lat, n_quant_all))\n",
    "sphum_quant3 = {'q': np.zeros((n_exp, n_lat, n_quant_all)), 'r': np.zeros((n_exp, n_lat, n_quant_all))}\n",
    "r_quant3 = {'q': np.zeros((n_exp, n_lat, n_quant_all)), 'r': np.zeros((n_exp, n_lat, n_quant_all))}\n",
    "z_quant3 = np.zeros((n_exp, n_lat, n_quant_all))\n",
    "convflag_quant3 = np.zeros((n_exp, n_lat, n_quant_all))\n",
    "klzbs_quant3 = np.zeros((n_exp, n_lat, n_quant_all))\n",
    "convfract_quant3 = np.zeros((n_exp, n_lat, n_quant_all))            # record fraction of days convecting\n",
    "with tqdm(total=n_exp*n_lat*n_quant_all, position=0, leave=True) as pbar:\n",
    "    for i in range(n_exp):\n",
    "        temp_mean[i] = ds_all[i].temp.mean(dim='lon_time')\n",
    "        sphum_mean['q'][i] = ds_all[i].sphum.isel(pfull=ind_surf).mean(dim='lon_time')\n",
    "        z_mean[i] = ds_all[i].height.isel(pfull=ind_ft).mean(dim='lon_time')\n",
    "        mse_mod = moist_static_energy(ds_all[i].temp[ind_surf], ds_all[i].sphum[ind_surf], height=0, c_p_const=c_p - lnp_const)\n",
    "        mse_mod_mean[i] = mse_mod.mean(dim='lon_time')\n",
    "        mse = moist_static_energy(ds_all[i].temp[ind_surf], ds_all[i].sphum[ind_surf], ds_all[i].height[ind_surf])\n",
    "        mse_mean[i] = mse.mean(dim='lon_time')\n",
    "        # For surface temperature, take actual quantile - rather than average over quantile days\n",
    "        temp_quant3[i, ind_surf] = ds_all[i].temp[ind_surf].quantile(quantiles_all/100, dim='lon_time').transpose()\n",
    "        rh_use = ds_all[i].sphum.isel(pfull=ind_surf)/sphum_sat(ds_all[i].temp.isel(pfull=ind_surf), p_surface)\n",
    "        r_mean['r'][i] = rh_use.mean(dim='lon_time')\n",
    "        if 'convflag' in var_keep:\n",
    "            is_convecting = np.logical_and(ds_all[i].klzbs<klzb_thresh, ds_all[i].convflag > convflag_thresh)\n",
    "        for k in range(n_lat):\n",
    "            for j, quant in enumerate(quantiles_all):\n",
    "                use_ind = get_quant_ind(ds_all[i].temp.isel(pfull=ind_surf)[k], quant, 0.5, 0.5)\n",
    "                sphum_quant3['q'][i, k, j] = ds_all[i].sphum.isel(pfull=ind_surf)[k, use_ind].mean()\n",
    "                z_quant3[i, k, j] = ds_all[i].height.isel(pfull=ind_ft)[k, use_ind].mean()\n",
    "                mse_mod_quant3[i, k, j] = mse_mod[k, use_ind].mean(dim='lon_time')\n",
    "                mse_quant3[i, k, j] = mse[k, use_ind].mean(dim='lon_time')\n",
    "                temp_quant3[i, ind_ft, k, j] = ds_all[i].temp[ind_ft, k, use_ind].mean(dim='lon_time')\n",
    "                r_quant3['r'][i, k, j] = rh_use[k, use_ind].mean(dim='lon_time')\n",
    "                if 'convflag' in var_keep:\n",
    "                    convflag_quant3[i, k, j] = ds_all[i].convflag[k, use_ind].mean(dim='lon_time')\n",
    "                    klzbs_quant3[i, k, j] = ds_all[i].klzbs[k, use_ind].mean(dim='lon_time')\n",
    "                    convfract_quant3[i, k, j] = np.sum(is_convecting[k, use_ind])/is_convecting[k, use_ind].size\n",
    "                pbar.update(1)\n",
    "\n",
    "r_quant3['q'] = sphum_quant3['q'] / sphum_sat(temp_quant3[:, ind_surf], p_surface)\n",
    "r_mean['q'] = sphum_mean['q'] / sphum_sat(temp_mean[:, ind_surf], p_surface)\n",
    "sphum_quant3['r'] = sphum_sat(temp_quant3[:, ind_surf], p_surface) * r_quant3['r']\n",
    "sphum_mean['r'] = sphum_sat(temp_mean[:, ind_surf], p_surface) * r_mean['r']\n",
    "r_anom_quant3 = {key: r_quant3[key] - r_mean[key][:, :, np.newaxis] for key in r_quant3}"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "humid_calc = 'r'            # which method to use in rest of notebook - recommend 'r'\n",
    "\n",
    "# Print mean values\n",
    "print(f'Temp:', np.average(temp_mean[:, ind_surf], weights=lat_weights, axis=1))\n",
    "for key in r_mean:\n",
    "    print(f'RH ({key}):', np.average(r_mean[key], weights=lat_weights, axis=1))\n",
    "np.average(r_mean['r'], weights=lat_weights, axis=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Convective days as function of $x$ for each $\\kappa$\n",
    "We expect the amount of days convecting to increase with surface temperature. Below, we see that this assumption breaks down for the hottest simulations.\n",
    "\n",
    "A day is convecting if `convflag>1` (at least shallow convection) and $LNB<486hPa$. The percentage of days that satisfy this is shown in the second plot below."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pressure_from_level_func = scipy.interpolate.interp1d(np.arange(len(ds[0].pfull)), ds[0].pfull)\n",
    "def lzb(k, interp_func=pressure_from_level_func):\n",
    "    # Offset by -1 because fortran starts with 1, but python starts with 0\n",
    "    # ds.t_ref will match exactly ds.temp if -2 used as offset, but this is not the LNB.\n",
    "    if np.size(k) == 1:\n",
    "        return float(interp_func(k-1))\n",
    "    else:\n",
    "        return interp_func(k-1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "colors_exp = plt.cm.jet(np.linspace(0, 1, n_exp))\n",
    "save_convflag_fig = False\n",
    "fig, ax = plt.subplots(2, 1, figsize=(width['one_col'], 2 * width['one_col'] / ar), sharex=True)\n",
    "for i in range(n_exp):\n",
    "    ax[0].plot(np.average(temp_quant3[i, ind_surf], axis=0, weights=lat_weights),\n",
    "               np.average(convflag_quant3[i], axis=0, weights=lat_weights), color=colors_exp[i], label=f'{tau_lw[i]}')\n",
    "    ax[1].plot(np.average(temp_quant3[i, ind_surf], axis=0, weights=lat_weights),\n",
    "               lzb(np.average(klzbs_quant3[i], axis=0, weights=lat_weights)), color=colors_exp[i])\n",
    "ax[1].axhline(pressure_ft_actual/100, color='k', lw=ax_linewidth)\n",
    "ax[0].legend(title='$\\kappa$')\n",
    "ax[0].set_ylabel('convflag')\n",
    "ax[-1].set_xlabel('Near-surface Temperature [K]')\n",
    "ax[1].invert_yaxis()\n",
    "ax[1].set_ylabel('LNB [hPa]')\n",
    "# ax.set_ylim(1, 2)\n",
    "if save_convflag_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/convflag_{region}_{season}_kappa.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "save_convfract_fig = False\n",
    "fig, ax = plt.subplots(1, 1, figsize=(width['one_col'], width['one_col'] / ar), sharex=True)\n",
    "for i in range(n_exp):\n",
    "    ax.plot(quantiles_all, 100 * np.average(convfract_quant3[i], axis=0, weights=lat_weights),\n",
    "            color=colors_exp[i], label=f'{tau_lw[i]}')\n",
    "ax.set_xlabel(percentile_label)\n",
    "ax.set_xlim(0, 100)\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_ylabel('% of days convecting')\n",
    "if season == 'summer':\n",
    "    ax.legend(fontsize=5.4, title='$\\kappa$', frameon=True, framealpha=1, edgecolor='white',title_fontsize=7, loc='lower right')\n",
    "label_subplots(fig, [ax], ['a)'] if season == 'summer' else ['b)'], box_alpha=0)\n",
    "# ax.legend(title='$\\kappa$')\n",
    "if save_convfract_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/convfract_{region}_{season}_kappa.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def get_gradient(temp_quant, temp_av, ref_ind, confidence = 0.9):\n",
    "    \"\"\"\n",
    "    Gets gradient of temperature of given quantile vs average temperature\n",
    "\n",
    "    Args:\n",
    "        temp_quant: [n_exp]\n",
    "        temp_av: [n_exp]\n",
    "        ref_ind: int\n",
    "        confidence: float\n",
    "            Desired confidence in temperature\n",
    "\n",
    "    Returns:\n",
    "        float\n",
    "            Gradient\n",
    "        [n_exp]\n",
    "            Predicted temperature for each experiment\n",
    "        float\n",
    "            Confidence value for the gradient, such that there is the desired confidence \n",
    "            in ± this value about returned gradient.\n",
    "    \"\"\"\n",
    "    fit_func = lambda x, m: temp_quant[ref_ind] + m*(x-temp_av[ref_ind])     # Straight line through the ref point\n",
    "    param, pcov = scipy.optimize.curve_fit(fit_func,temp_av, temp_quant)[:2]\n",
    "    # param_with_error = uncertainties.correlated_values(param, pcov)[0]\n",
    "    # param_std = param_with_error.std_dev\n",
    "    param_std = np.sqrt(pcov)\n",
    "    z_score = z_score_from_confidence_interval(confidence)\n",
    "    return param, fit_func(temp_av, param), z_score * param_std"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Figure 4 of O'Gorman & Schneider 2009\n",
    "### Tropics\n",
    "In the plot below, all the gradients are below 1, indicating that the hottest days warm less quickly than the average day. If we look at the largest $\\kappa$ values, it is also clear that the gradient here is a lot larger than the gradient at lower $\\kappa$ and thus causes the gradients to be larger than maybe they appear by eye."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "quant_grad_plot = [1, 25, 50, 75, 99]\n",
    "quant_grad_plot_ind = numpy_indexed.indices(quantiles_all, quant_grad_plot)\n",
    "n_quant_grad_plot = len(quant_grad_plot)\n",
    "\n",
    "tau_lw_ref = 1\n",
    "tau_ref_ind = np.where(np.asarray(tau_lw)==tau_lw_ref)[0][0]\n",
    "temp_quant_grad = np.zeros((n_lat, n_quant_grad_plot))\n",
    "temp_quant_grad_fit = np.zeros((n_exp, n_lat, n_quant_grad_plot))\n",
    "for i in range(n_lat):\n",
    "    for j in range(n_quant_grad_plot):\n",
    "        temp_quant_grad[i, j], temp_quant_grad_fit[:, i, j], _ = \\\n",
    "            get_gradient(temp_quant3[:, ind_surf, i, quant_grad_plot_ind[j]], temp_mean[:, ind_surf, i], tau_ref_ind)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trend_line_on = True\n",
    "save_trend_fig = False\n",
    "\n",
    "color_seq_quant = plt.cm.jet(np.linspace(0,1,n_quant_grad_plot))\n",
    "\n",
    "# labels_quant = [f'{qu}$^{st}$', '25$^{th}$', '50$^{th}$', '75$^{th}$', '99$^{th}$']\n",
    "fig, ax = plt.subplots(1,1, figsize=(width['one_col'], width['one_col']/ar))\n",
    "for j in range(n_quant_grad_plot):\n",
    "    ax.plot(np.average(temp_mean[:, ind_surf], weights=lat_weights, axis=1),\n",
    "            np.average(temp_quant3[:, ind_surf, :, quant_grad_plot_ind[j]], weights=lat_weights, axis=1),\n",
    "            marker='o',\n",
    "            label=f'{quant_grad_plot[j]}'+ ('$^{st}$' if quant_grad_plot[j]==1 else '$^{th}$'),\n",
    "            color=color_seq_quant[j], fillstyle='none')\n",
    "    if trend_line_on:\n",
    "        # Filled circle for reference simulation\n",
    "        ax.plot(np.average(temp_mean[:, ind_surf], weights=lat_weights, axis=1)[tau_ref_ind],\n",
    "                np.average(temp_quant3[:, ind_surf, :, quant_grad_plot_ind[j]], weights=lat_weights, axis=1)[tau_ref_ind],\n",
    "                marker='o', color=color_seq_quant[j], fillstyle='full')\n",
    "        if j==n_quant_grad_plot-1:\n",
    "            label = None #'Linear fits'\n",
    "        else:\n",
    "            label = None\n",
    "        ax.plot(np.average(temp_mean[:, ind_surf], weights=lat_weights, axis=1),\n",
    "                np.average(temp_quant_grad_fit[:, :, j], axis=1, weights=lat_weights),\n",
    "                linestyle='--', color=color_seq_quant[j], alpha=0.3, label=label)\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "lim_new = [np.asarray([xlim, ylim]).min(), np.asarray([xlim, ylim]).max()]\n",
    "ax.plot(lim_new, lim_new, 'k:', alpha=0.75)\n",
    "ax.set_ylim(lim_new)\n",
    "ax.set_xlim(lim_new)\n",
    "if trend_line_on:\n",
    "    ax.legend(loc='upper left', title='Percentile')\n",
    "ax.set_xlabel(f'Mean Temperature [K]')\n",
    "ax.set_ylabel(f'Temperature [K]')\n",
    "if save_fig or save_trend_fig:\n",
    "    if trend_line_on:\n",
    "        file_name = f\"{region.lower()}_trend\"\n",
    "    else:\n",
    "        file_name = f\"{region.lower()}_no_trend\"\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/{file_name}.pdf\",dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight',\n",
    "                pad_inches=save_pad_inches)\n",
    "print(f'Gradient of best fit line for {quant_grad_plot} percentiles: {np.round(np.average(temp_quant_grad, weights=lat_weights, axis=0), 2)}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Scaling Factor\n",
    "Below I combine all simulations to get a scaling factor for temperature covering all simulations. I get both the simulated and theoretical scaling factors."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Decomposition of temp_adiabat_anom\n",
    "temp_adiabat_anom_quant3 = np.zeros((n_exp, n_lat, n_quant_all))\n",
    "temp_ce_mean = np.zeros((n_exp, n_lat))\n",
    "temp_ce_quant3 = np.zeros((n_exp, n_lat, n_quant_all))\n",
    "temp_ft_anom_quant3 = np.zeros((n_exp, n_lat, n_quant_all))\n",
    "z_ft_anom_quant3 = z_quant3 - z_mean[:, :, np.newaxis]\n",
    "for j in range(n_lat):\n",
    "    temp_adiabat_anom_quant3[:, j], temp_ce_mean[:, j], temp_ce_quant3[:, j], temp_ft_anom_quant3[:, j] = \\\n",
    "        decompose_temp_adiabat_anomaly(temp_mean[:, ind_surf, j], temp_quant3[:, ind_surf, j], sphum_mean[humid_calc][:, j], \n",
    "                                       sphum_quant3[humid_calc][:, j], temp_mean[:, ind_ft, j], temp_quant3[:, ind_ft, j], \n",
    "                                       p_surface, pressure_ft_actual)\n",
    "temp_ce_anom_quant3 = temp_ce_quant3 - temp_ce_mean[:, :, np.newaxis]\n",
    "temp_adiabat_anom_quant3_z_form = g/lnp_const * z_ft_anom_quant3 - temp_ce_anom_quant3"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# delta_temp_quant_theory[-1] will be all zeros and never used, but helpful to keep this shape\n",
    "delta_temp_quant_theory = {method: np.zeros((n_exp-1, n_lat, n_quant_all)) for method in\n",
    "                           ['wtg', 'z', 'best', 'wtg_new_q', 'wtg_new_r', 'z_new_q', 'z_new_r']}\n",
    "delta_temp_quant_theory_cont = {'wtg': {var: np.zeros((n_exp-1, n_lat, n_quant_all)) for var in \n",
    "                                ['temp_s_mean', 'rh', 'temp_s_mean_temp_a0', 'temp_a', 'temp_s_mean_temp_ft0', 'temp_ft', \n",
    "                                 'temp_s_mean_temp_ce0', 'temp_ce']}}\n",
    "for method in delta_temp_quant_theory:\n",
    "    if 'new' not in method:\n",
    "        continue\n",
    "    delta_temp_quant_theory_cont[method] = {var: np.zeros((n_exp-1, n_lat, n_quant_all)) for var in \n",
    "                                            ['temp_s', 'humidity', 'r_change', 'temp_a_change', 'temp_ft_change', 'temp_ce_change']}\n",
    "with tqdm(total=(n_exp-1)*n_lat*len(delta_temp_quant_theory), position=0, leave=True) as pbar:\n",
    "    for i in range(n_exp-1):\n",
    "        for j in range(n_lat):\n",
    "            for key in delta_temp_quant_theory:\n",
    "                if 'best' in key:\n",
    "                    delta_temp_quant_theory[key][i, j] = \\\n",
    "                        get_delta_temp_quant_theory(temp_mean[i:i+2, ind_surf, j], temp_quant3[i:i+2, ind_surf, j], sphum_mean[humid_calc][i:i+2, j], \n",
    "                                                    sphum_quant3[humid_calc][i:i+2, j], p_surface, pressure_ft_actual, None, None, None, None, \n",
    "                                                    'squared', 'squared', 'full')[0]\n",
    "                else:\n",
    "                    if 'new' in key:\n",
    "                        delta_temp_quant_theory[key][i, j], info_coef, info_change = \\\n",
    "                            get_delta_temp_quant_theory_simple2(temp_mean[i:i+2, ind_surf, j], temp_quant3[i:i+2, ind_surf, j], \n",
    "                                                                sphum_mean[humid_calc][i:i+2, j],\n",
    "                                                                sphum_quant3[humid_calc][i:i+2, j], p_surface, pressure_ft_actual, \n",
    "                                                                temp_mean[i:i+2, ind_ft, j] if 'z' in key else None, \n",
    "                                                                temp_quant3[i:i+2, ind_ft, j] if 'z' in key else None, \n",
    "                                                                z_mean[i:i+2, j] if 'z' in key else None, \n",
    "                                                                z_quant3[i:i+2, j] if 'z' in key else None,\n",
    "                                                                use_sphum_anom0='q' in key)\n",
    "                        for var in ['temp_s', 'humidity', 'r_change', 'temp_a_change']:\n",
    "                            # Add mean change to each of these so centered around 1 not around 0\n",
    "                            delta_temp_quant_theory_cont[key][var][i, j] = info_coef[var] * info_change[var] + info_change['temp_s']\n",
    "                        delta_temp_quant_theory_cont[key]['temp_ce_change'][i, j] = \\\n",
    "                            info_coef['temp_a_change'] * -(temp_ce_anom_quant3[i+1, j] - temp_ce_anom_quant3[i, j]) + info_change['temp_s']\n",
    "                        if 'z' in key:\n",
    "                            var = g/lnp_const * (z_ft_anom_quant3[i+1, j] - z_ft_anom_quant3[i, j])\n",
    "                        else:\n",
    "                            var = temp_ft_anom_quant3[i+1, j] - temp_ft_anom_quant3[i, j]\n",
    "                        delta_temp_quant_theory_cont[key]['temp_ft_change'][i, j] = \\\n",
    "                            info_coef['temp_a_change'] * var + info_change['temp_s']\n",
    "                    else:\n",
    "                        delta_temp_quant_theory[key][i, j], _, info_coef, info_change = \\\n",
    "                            get_delta_temp_quant_theory_simple(temp_mean[i:i+2, ind_surf, j], temp_quant3[i:i+2, ind_surf, j], \n",
    "                                                               sphum_mean[humid_calc][i:i+2, j], sphum_quant3[humid_calc][i:i+2, j], p_surface, \n",
    "                                                               pressure_ft_actual, temp_mean[i:i+2, ind_ft, j] if 'z' in key else None,\n",
    "                                                               temp_quant3[i:i+2, ind_ft, j] if 'z' in key else None, \n",
    "                                                               z_mean[i:i+2, j] if 'z' in key else None, \n",
    "                                                               z_quant3[i:i+2, j] if 'z' in key else None)\n",
    "                        if key == 'wtg':\n",
    "                            for var in ['temp_s_mean', 'temp_s_mean_temp_a0', 'temp_a']:\n",
    "                                delta_temp_quant_theory_cont[key][var][i, j] = info_coef[var] * info_change[var]\n",
    "                            delta_temp_quant_theory_cont[key]['rh'][i, j] = info_coef['r_quant'] * (info_change['r_quant'] - info_change['r_mean'])\n",
    "                            # Breakdown adiabatic anomaly into ft and ce terms\n",
    "                            delta_temp_quant_theory_cont[key]['temp_s_mean_temp_ft0'][i, j] = \\\n",
    "                                delta_temp_quant_theory_cont[key]['temp_s_mean_temp_a0'][i, j]/temp_adiabat_anom_quant3[i, j] * temp_ft_anom_quant3[i, j]\n",
    "                            delta_temp_quant_theory_cont[key]['temp_ft'][i, j] = info_coef['temp_a'] * (temp_ft_anom_quant3[i+1, j] - \n",
    "                                                                                                   temp_ft_anom_quant3[i, j])\n",
    "                            delta_temp_quant_theory_cont[key]['temp_s_mean_temp_ce0'][i, j] = \\\n",
    "                                delta_temp_quant_theory_cont[key]['temp_s_mean_temp_a0'][i, j]/temp_adiabat_anom_quant3[i, j] * -temp_ce_anom_quant3[i, j]\n",
    "                            delta_temp_quant_theory_cont[key]['temp_ce'][i, j] = info_coef['temp_a'] * -(temp_ce_anom_quant3[i+1, j] - \n",
    "                                                                                                   temp_ce_anom_quant3[i, j])\n",
    "                            for var in delta_temp_quant_theory_cont[key]:\n",
    "                                if var == 'temp_s_mean':\n",
    "                                    continue\n",
    "                                # Add mean change to each of these so centered around 1 not around 0\n",
    "                                # As interested in scaling factor of each term relative to change in mean.\n",
    "                                delta_temp_quant_theory_cont[key][var][i, j] = delta_temp_quant_theory_cont[key][var][i, j] + info_change['temp_s_mean']\n",
    "                pbar.update(1)\n",
    "\n",
    "# theory3 adds the same theoretical delta_temp to theory prediction of previous kappa so errors accumulate\n",
    "temp_quant_theory3 = {method: temp_quant3[:, ind_surf].copy() for method in delta_temp_quant_theory}\n",
    "for method in delta_temp_quant_theory:\n",
    "    for j in range(n_exp-1):\n",
    "        temp_quant_theory3[method][1+j] = temp_quant_theory3[method][j] + delta_temp_quant_theory[method][j]\n",
    "        \n",
    "temp_quant_theory_cont = {var: temp_quant3[:, ind_surf].copy() for var in delta_temp_quant_theory_cont}\n",
    "for method in delta_temp_quant_theory_cont:\n",
    "    temp_quant_theory_cont[method] = {var: temp_quant3[:, ind_surf].copy() for var in delta_temp_quant_theory_cont[method]}\n",
    "    for var in delta_temp_quant_theory_cont[method]:\n",
    "        for j in range(n_exp-1):\n",
    "            temp_quant_theory_cont[method][var][1+j] = temp_quant_theory_cont[method][var][j] + delta_temp_quant_theory_cont[method][var][j]"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "confidence = 0.9        # desired confidence for shading in plots\n",
    "sf_tau_use = [np.where(tau_lw<=np.inf)[0], np.where(tau_lw<=1)[0], np.where(tau_lw>=1)[0]]\n",
    "sf_tau_ref = [tau_lw_ref, tau_lw_ref, tau_lw_ref]\n",
    "n_sf = len(sf_tau_use)\n",
    "sf_tau_ref_ind = [np.where(tau_lw[sf_tau_use[i]]==sf_tau_ref[i])[0] for i in range(n_sf)]\n",
    "sf_labels = ['All $\\kappa$', f'$\\kappa \\leq {tau_lw[sf_tau_use[1]].max()}$', f'$\\kappa \\geq {tau_lw[sf_tau_use[2]].min()}$']\n",
    "# all temperatures averaged above x=0 - same as temp_av except for no area averaging\n",
    "scaling_factor = np.zeros((n_sf, n_lat, n_quant_all))\n",
    "scaling_factor_error = np.zeros((n_sf, n_lat, n_quant_all))\n",
    "\n",
    "scaling_factor_theory = {method: np.zeros((n_sf, n_lat, n_quant_all)) for method in delta_temp_quant_theory}\n",
    "scaling_factor_theory_cont = {method: {var: np.zeros((n_sf, n_lat, n_quant_all)) for var in delta_temp_quant_theory_cont[method]} \n",
    "                              for method in delta_temp_quant_theory_cont}\n",
    "# scaling_factor_theory_cont_new = {var: np.zeros((n_sf, n_lat, n_quant_all)) for var in delta_temp_quant_theory_cont_new}\n",
    "\n",
    "sf_av = temp_mean[:, ind_surf]\n",
    "\n",
    "for i in range(n_sf):\n",
    "    for j in range(n_quant_all):\n",
    "        # The theory predicts median change but not mean hence I use median rather than mean.\n",
    "        # This means can get theoretical scale factor rather than using simulated mean.\n",
    "        # This means x=50 will correspond to y=1 in all plots below.\n",
    "        # Straight line through the ref point\n",
    "        for k in range(n_lat):\n",
    "            scaling_factor[i, k, j], _, scaling_factor_error[i, k, j] = get_gradient(temp_quant3[sf_tau_use[i], ind_surf, k, j],\n",
    "                                                                                     sf_av[sf_tau_use[i], k], sf_tau_ref_ind[i],\n",
    "                                                                                     confidence)\n",
    "            for method in scaling_factor_theory:\n",
    "                # Use theory2 version for theoretical scaling factor as errors compounded - makes most sense to me\n",
    "                scaling_factor_theory[method][i, k, j] = get_gradient(temp_quant_theory3[method][sf_tau_use[i], k, j],\n",
    "                                                           sf_av[sf_tau_use[i], k],\n",
    "                                                           sf_tau_ref_ind[i], confidence)[0]\n",
    "            for method in scaling_factor_theory_cont:\n",
    "                for var in scaling_factor_theory_cont[method]:\n",
    "                    scaling_factor_theory_cont[method][var][i, k, j] = get_gradient(temp_quant_theory_cont[method][var][sf_tau_use[i], k, j], \n",
    "                                                                                    sf_av[sf_tau_use[i], k], sf_tau_ref_ind[i], confidence)[0]     "
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Simulated Scaling Factor\n",
    "Combine simulations to plot the simulated warming of a given percentile as a function of the mean warming."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "save_sf_fig = False\n",
    "# if publishing figure, use high dpi\n",
    "fig, ax = plt.subplots(1,1, figsize=(width['one_col'], width['one_col']/ar))\n",
    "ax.spines[['right', 'top']].set_visible(False)\n",
    "ax.plot(quantiles_all, np.average(scaling_factor[0], axis=0, weights=lat_weights), color='k', label=sf_labels[0])\n",
    "ax.plot(quantiles_all, np.average(scaling_factor[1], axis=0, weights=lat_weights), color='k', linestyle=':',\n",
    "        label = sf_labels[1])\n",
    "ax.plot(quantiles_all, np.average(scaling_factor[2], axis=0, weights=lat_weights), color='k', linestyle='--',\n",
    "        label = sf_labels[2])\n",
    "ax.hlines(1, 0, 100, lw=ax_linewidth, color='k')\n",
    "# # Remove some of the lines but keep ylims the same\n",
    "# ax.lines.pop(1)\n",
    "# ax.lines.pop(1)\n",
    "ax.legend()\n",
    "ax.set_xlim(0,100)\n",
    "# if quant_type_use == 'x':\n",
    "#     ax.set_ylim(0.5,1.5)\n",
    "# else:\n",
    "#     ax.set_ylim(0.5,2.5)\n",
    "ax.set_xlabel(percentile_label)\n",
    "ax.set_ylabel('Scaling factor, $\\delta T(x)/\\delta \\overline{T}$')\n",
    "if save_fig or save_sf_fig:\n",
    "    file_name = f\"scaling_factor_multi_kappa_{region.lower()}_{season}\"\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/{file_name}.pdf\", dpi=dpi['monochrome'] if publish_fig else low_dpi, \n",
    "                bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tropical Theory\n",
    "Below I apply the theory developed for the tropics to the extratropics. It predicts the amplified warming of cold days, but is not quantitatively accurate.\n",
    "\n",
    "Thermodynamic theory assumes $\\delta \\Delta T_A = \\delta \\Delta T_{CE}$, while the dynamic theory assumes $\\delta \\Delta T_A = \\delta \\Delta T_{FT}$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "scaling_factor_theory['wtg_thermo'] = scaling_factor_theory_cont['wtg']['temp_s_mean'] + scaling_factor_theory_cont['wtg']['rh']-1 + scaling_factor_theory_cont['wtg']['temp_s_mean_temp_a0']-1 + scaling_factor_theory_cont['wtg']['temp_ce']-1\n",
    "scaling_factor_theory['wtg_dynamic'] = scaling_factor_theory_cont['wtg']['temp_s_mean'] + scaling_factor_theory_cont['wtg']['rh']-1 + scaling_factor_theory_cont['wtg']['temp_s_mean_temp_a0']-1 + scaling_factor_theory_cont['wtg']['temp_ft']-1\n",
    "\n",
    "for method in delta_temp_quant_theory:\n",
    "    if 'new' not in method:\n",
    "        continue\n",
    "    scaling_factor_theory[method+'_thermo'] = \\\n",
    "        scaling_factor_theory_cont[method]['temp_s']-1 + scaling_factor_theory_cont[method]['humidity']-1 + \\\n",
    "        scaling_factor_theory_cont[method]['r_change']-1 + scaling_factor_theory_cont[method]['temp_ce_change']-1 + 1\n",
    "    scaling_factor_theory[method+'_dynamic'] = \\\n",
    "        scaling_factor_theory_cont[method]['temp_s']-1 + scaling_factor_theory_cont[method]['humidity']-1 + \\\n",
    "        scaling_factor_theory_cont[method]['r_change']-1 + scaling_factor_theory_cont[method]['temp_ft_change']-1 + 1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Do a single plot combining all simulations\n",
    "sf_ind_use = 0  # 0, 1 or 2\n",
    "method = 'z'\n",
    "save_sf_theory_fig = False\n",
    "# if publishing figure, use high dpi\n",
    "fig, ax = plt.subplots(1,1, figsize=(width['one_col'], width['one_col']/ar))\n",
    "ax.plot(quantiles_all, np.average(scaling_factor[sf_ind_use], axis=0, weights=lat_weights), color='b', label='Simulated')\n",
    "# ax.plot(quantiles_all, np.average(scaling_factor_theory['wtg'][sf_ind_use], axis=0, weights=lat_weights), color='k', \n",
    "#         label='Theory')\n",
    "# ax.plot(quantiles_all, np.average(scaling_factor_theory['wtg_thermo'][sf_ind_use], axis=0, weights=lat_weights), color='k',\n",
    "#         linestyle=':', label='Theory [thermodynamic]')\n",
    "# ax.plot(quantiles_all, np.average(scaling_factor_theory['wtg_dynamic'][sf_ind_use], axis=0, weights=lat_weights), color='k',\n",
    "#         linestyle='--', label='Theory [dynamic]')\n",
    "# ax.plot(quantiles_all, np.average(scaling_factor_theory['new_q'][sf_ind_use], axis=0, weights=lat_weights), color='r')\n",
    "# ax.plot(quantiles_all, np.average(scaling_factor_theory['new_q_thermo'][sf_ind_use], axis=0, weights=lat_weights), color='r',\n",
    "#         linestyle=':')\n",
    "# ax.plot(quantiles_all, np.average(scaling_factor_theory['new_q_dynamic'][sf_ind_use], axis=0, weights=lat_weights), color='r',\n",
    "#         linestyle='--')\n",
    "ax.plot(quantiles_all, np.average(scaling_factor_theory[method+'_new_r'][sf_ind_use], axis=0, weights=lat_weights), color='k', label='Theory')\n",
    "ax.plot(quantiles_all, np.average(scaling_factor_theory[method+'_new_r_thermo'][sf_ind_use], axis=0, weights=lat_weights), color='k',\n",
    "        linestyle=':', label='Theory [thermodynamic]')\n",
    "ax.plot(quantiles_all, np.average(scaling_factor_theory[method+'_new_r_dynamic'][sf_ind_use], axis=0, weights=lat_weights), color='k',\n",
    "        linestyle='--', label='Theory [dynamic]')\n",
    "# Add error\n",
    "ax.fill_between(quantiles_all, np.average(scaling_factor[sf_ind_use]-scaling_factor_error[sf_ind_use], axis=0, weights=lat_weights), \n",
    "                np.average(scaling_factor[sf_ind_use]+scaling_factor_error[sf_ind_use], axis=0, weights=lat_weights), fc='b', alpha=0.1)\n",
    "ax.hlines(1, 0, 100, linewidth=ax_linewidth, color='k')\n",
    "if season == 'summer':\n",
    "    ax.legend()\n",
    "ax.set_xlim(0,100)\n",
    "if region == 'tropics':\n",
    "    ax.set_ylim(0.87, 1.15)\n",
    "elif region == 'extratropics':\n",
    "    ax.set_ylim(0.8, 1.25)\n",
    "ax.set_xlabel(percentile_label)\n",
    "label_subplots(fig, ax, ['a)'] if season == 'summer' else ['b)'], box_alpha=0)\n",
    "ax.set_ylabel('Scaling factor, $\\delta T(x)/\\delta \\overline{T}$')\n",
    "if save_fig or save_sf_theory_fig:\n",
    "    file_name = f\"scaling_factor_theory_{region.lower()}_{season}\"\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/{file_name}.pdf\",dpi=dpi['combination'] if publish_fig else low_dpi, \n",
    "                bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ind_min_sf = np.average(scaling_factor[sf_ind_use], axis=0, weights=lat_weights).argmin()\n",
    "print(quantiles_all[ind_min_sf])\n",
    "print(np.average(scaling_factor[sf_ind_use], axis=0, weights=lat_weights)[ind_min_sf])\n",
    "print(np.average(scaling_factor_error[sf_ind_use], axis=0, weights=lat_weights)[ind_min_sf])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Breakdown contribution to Theory\n",
    "Below, in the top plot, I show the scaling factor contribution of each term in the most simple version of the theory.\n",
    "\n",
    "In the second plot, I show how the adiabatic temperature anomaly contribution is split up into convective and free tropospheric parts."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "colors_breakdown = {'temp_s_mean': default_colors[0], 'rh': default_colors[1], 'temp_s_mean_temp_a0': default_colors[2], 'temp_a': default_colors[2], \n",
    "                    'temp_s_mean_temp_ft0': default_colors[4], 'temp_ft': default_colors[4], \n",
    "                    'temp_s_mean_temp_ce0': default_colors[3], 'temp_ce': default_colors[3]}\n",
    "sf_cont_use = scaling_factor_theory_cont['wtg']\n",
    "linestyles_breakdown = {key: '--' if '0' in key else ':' for key in sf_cont_use}\n",
    "linestyles_breakdown['temp_s_mean'] = '-'\n",
    "linestyles_breakdown['rh'] = '-'\n",
    "labels_breakdown = {'temp_s_mean': '$q_{s}$', 'rh': '$\\delta \\Delta r_s$',\n",
    "                    'temp_s_mean_temp_a0': '$\\Delta T_A$', 'temp_a': '$\\delta \\Delta T_A$', \n",
    "                    'temp_s_mean_temp_ft0': '$\\Delta T_{FT}$', 'temp_ft': None, 'temp_s_mean_temp_ce0': '$\\Delta T_{CE}$', 'temp_ce': None}\n",
    "\n",
    "save_sf_theory_breakdown_fig = False\n",
    "fig, ax = plt.subplots(2,1, figsize=(width['one_col'], 2*width['one_col']/ar), sharex=True, sharey=True)\n",
    "ax[0].plot(quantiles_all, np.average(scaling_factor_theory['wtg'][sf_ind_use], axis=0, weights=lat_weights), color='k')\n",
    "for i, key in enumerate(sf_cont_use):\n",
    "    if ('ft' in key) or ('ce' in key):\n",
    "        ax[1].plot(quantiles_all, np.average(sf_cont_use[key][sf_ind_use], axis=0, weights=lat_weights), color=colors_breakdown[key],\n",
    "            linestyle=linestyles_breakdown[key], label=labels_breakdown[key])\n",
    "        if 'temp_a' not in key:\n",
    "            continue\n",
    "    ax[0].plot(quantiles_all, np.average(sf_cont_use[key][sf_ind_use], axis=0, weights=lat_weights), color=colors_breakdown[key],\n",
    "            linestyle=linestyles_breakdown[key], label=labels_breakdown[key])\n",
    "for i in range(2):\n",
    "    ax[i].plot(quantiles_all, np.average(sf_cont_use['temp_a'][sf_ind_use] + \n",
    "                                         sf_cont_use['temp_s_mean_temp_a0'][sf_ind_use] - 1, axis=0, weights=lat_weights),\n",
    "               color=colors_breakdown['temp_a'], label='$\\Delta T_A + \\delta \\Delta T_A$' if i==1 else None)\n",
    "    ax[i].axhline(1, color='k', lw=ax_linewidth)\n",
    "    ax[i].set_ylabel('Scaling factor, $\\delta T(x)/\\delta \\overline{T}$')\n",
    "for var in ['ft', 'ce']:\n",
    "    ax[1].plot(quantiles_all, np.average(sf_cont_use['temp_'+var][sf_ind_use] + \n",
    "                                         sf_cont_use['temp_s_mean_temp_'+var+'0'][sf_ind_use] - 1, axis=0, weights=lat_weights),\n",
    "               color=colors_breakdown['temp_'+var])\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "ax[0].set_xlim(0,100)\n",
    "ax[1].set_xlabel(percentile_label)\n",
    "label_subplots(fig, ax)\n",
    "# ax[0].set_ylim(0.85, 1.15)\n",
    "\n",
    "if save_fig or save_sf_theory_breakdown_fig:\n",
    "    file_name = f\"scaling_factor_theory_breakdown_{region.lower()}_{season}\"\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/{file_name}.pdf\",dpi=dpi['combination'] if publish_fig else low_dpi, \n",
    "                bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### New Theory\n",
    "Below, I do a split for the new theory - no $\\Delta T_A$ term."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "colors_breakdown = {'temp_s': default_colors[3], 'humidity': default_colors[0],  \n",
    "                    'r_change': default_colors[1], 'temp_a_change': default_colors[2], \n",
    "                    'temp_ce_change': default_colors[2], 'temp_ft_change': default_colors[2]}\n",
    "method = 'z'\n",
    "# humidity_use = 'q'\n",
    "humidity_use = 'r'\n",
    "sf_cont_use = scaling_factor_theory_cont[method+'_new_'+humidity_use]\n",
    "linestyles_breakdown = {key: '-' for key in sf_cont_use}\n",
    "linestyles_breakdown['temp_ce_change'] = ':'\n",
    "linestyles_breakdown['temp_ft_change'] = '--'\n",
    "labels_breakdown = {'temp_s': '$T_s$', 'humidity': f'${humidity_use}_s$', 'r_change': '$\\delta \\Delta r_s$',\n",
    "                    'temp_a_change': \"$\\delta \\Delta T_A$'\" if 'z' in method else \"$\\delta \\Delta T_A$\",\n",
    "                    'temp_ce_change': None, 'temp_ft_change': None}\n",
    "\n",
    "save_sf_theory_breakdown_new_fig = False\n",
    "fig, ax = plt.subplots(1,1, figsize=(width['one_col'], width['one_col']/ar), sharex=True, sharey=True)\n",
    "ax = [ax]\n",
    "ax[0].plot(quantiles_all, np.average(scaling_factor_theory[method+'_new_'+humidity_use][sf_ind_use], axis=0, weights=lat_weights), color='k')\n",
    "for i, key in enumerate(sf_cont_use):\n",
    "    # if ('ft' in key) or ('ce' in key):\n",
    "    #     ax[0].plot(quantiles_all, np.average(scaling_factor_theory_cont_new[key][sf_ind_use], axis=0, weights=lat_weights), \n",
    "    #                color=colors_breakdown[key], linestyle=linestyles_breakdown[key], label=None)\n",
    "    #     if 'temp_a' not in key:\n",
    "    #         continue\n",
    "    ax[0].plot(quantiles_all, np.average(sf_cont_use[key][sf_ind_use], axis=0, weights=lat_weights), color=colors_breakdown[key],\n",
    "            linestyle=linestyles_breakdown[key], label=labels_breakdown[key])\n",
    "for i in range(len(ax)):\n",
    "    ax[i].axhline(1, color='k', lw=ax_linewidth)\n",
    "    ax[i].set_ylabel('Scaling factor, $\\delta T(x)/\\delta \\overline{T}$')\n",
    "    if season == 'summer':\n",
    "        ax[i].legend()\n",
    "ax[0].set_xlim(0,100)\n",
    "ax[-1].set_xlabel(percentile_label)\n",
    "if len(ax)>1:\n",
    "    label_subplots(fig, ax)\n",
    "if region == 'tropics':\n",
    "    ax[0].set_ylim(0.8, 1.15)\n",
    "elif region == 'extratropics':\n",
    "    ax[0].set_ylim(0.8, 1.25)\n",
    "label_subplots(fig, ax, ['a)'] if season == 'summer' else ['b)'], box_alpha=0)\n",
    "\n",
    "if save_fig or save_sf_theory_breakdown_new_fig:\n",
    "    file_name = f\"scaling_factor_theory_breakdown_new_{humidity_use}_{region.lower()}_{season}\"\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/{file_name}.pdf\",dpi=dpi['combination'] if publish_fig else low_dpi, \n",
    "                bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### $\\Delta T_A$ for each simulation\n",
    "To help understand the bottom plot above, I see how $T_{CE}(x)$ and $\\Delta T_{FT}(x)$ vary with warming below."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "save_temp_adiabat_fig = False\n",
    "use_temp_adiabat_z_form = True\n",
    "color_seq_exp = plt.cm.jet(np.linspace(0,1,n_exp))\n",
    "\n",
    "fig, ax = plt.subplots(4,1, figsize=(width['one_col'], 4*width['one_col']/ar), sharex=True)\n",
    "ax[0].sharey(ax[2])\n",
    "ax[2].sharey(ax[3])\n",
    "for i in range(n_exp):\n",
    "    if use_temp_adiabat_z_form:\n",
    "        ax[0].plot(quantiles_all, np.average(temp_adiabat_anom_quant3_z_form[i], axis=0, weights=lat_weights), color=color_seq_exp[i],\n",
    "                   label=f'{tau_lw[i]}')\n",
    "        ax[3].plot(quantiles_all, g/lnp_const * np.average(z_ft_anom_quant3[i], axis=0, weights=lat_weights), color=color_seq_exp[i])\n",
    "    else:\n",
    "        ax[0].plot(quantiles_all, np.average(temp_adiabat_anom_quant3[i], axis=0, weights=lat_weights), color=color_seq_exp[i], \n",
    "                   label=f'{tau_lw[i]}')\n",
    "        ax[3].plot(quantiles_all, np.average(temp_ft_anom_quant3[i], axis=0, weights=lat_weights), color=color_seq_exp[i])\n",
    "    ax[1].plot(quantiles_all, np.average(temp_ce_quant3[i], axis=0, weights=lat_weights), color=color_seq_exp[i], label=f'{tau_lw[i]}')\n",
    "    ax[1].scatter(-1, np.average(temp_ce_mean[i], axis=0, weights=lat_weights), marker='o', alpha=0.7, edgecolors=None,\n",
    "                  facecolors=color_seq_exp[i], lw=0)\n",
    "    ax[2].plot(quantiles_all, np.average((temp_ce_quant3[i]-temp_ce_mean[i, :, np.newaxis]), axis=0, weights=lat_weights), color=color_seq_exp[i])\n",
    "for i in range(len(ax)):\n",
    "    ax[i].axhline(0, color='k', lw=ax_linewidth)\n",
    "ax[0].set_xlim(-2, 100)\n",
    "ax[1].set_ylabel('$T_{CE}$ [K]')\n",
    "ax[2].set_ylabel('$\\Delta T_{CE}$ [K]')\n",
    "if use_temp_adiabat_z_form:\n",
    "    ax[0].set_ylabel(\"$\\Delta T_A'$ [K]\")\n",
    "    ax[3].set_ylabel('$\\\\frac{g}{R^{\\dagger}}\\Delta z_{FT}$ [K]')\n",
    "else:\n",
    "    ax[0].set_ylabel('$\\Delta T_A$ [K]')\n",
    "    ax[3].set_ylabel('$\\Delta T_{FT}$ [K]')\n",
    "ax[-1].set_xlabel(percentile_label)\n",
    "label_subplots(fig, ax, ['a)', 'c)', 'e)', 'g)'] if season == 'summer' else ['b)', 'd)', 'f)', 'h)'], box_alpha=0)\n",
    "# ax[0].set_ylim(-13, 13)\n",
    "# ax[1].set_ylim(-2, 19)\n",
    "if season == 'summer':\n",
    "    ax[1].legend(fontsize=5.4, title='$\\kappa$', frameon=True, framealpha=1, edgecolor='white',title_fontsize=7, loc='upper right')\n",
    "# ax[0].legend(title='$\\kappa$', fontsize=4.5, loc='lower right')\n",
    "if save_fig or save_temp_adiabat_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/temp_adiabat_{region.lower()}_{season}.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "save_near_surf_anom_fig = False\n",
    "fig, ax = plt.subplots(2,1, figsize=(width['one_col'], 2*width['one_col']/ar), sharex=True)\n",
    "for i in range(n_exp):\n",
    "    ax[0].plot(quantiles_all, 100*np.average((temp_quant3[i, ind_surf]-temp_mean[i, ind_surf, :, np.newaxis])/temp_mean[i, ind_surf, :, np.newaxis], axis=0, weights=lat_weights),\n",
    "               color=color_seq_exp[i], label=f'{tau_lw[i]}')\n",
    "    ax[1].plot(quantiles_all, 100*np.average(r_anom_quant3[humid_calc][i]/r_mean[humid_calc][i, :, np.newaxis], axis=0, weights=lat_weights),\n",
    "               color=color_seq_exp[i], label=f'{tau_lw[i]}')\n",
    "for i in range(len(ax)):\n",
    "    ax[i].axhline(0, color='k', lw=ax_linewidth)\n",
    "ax[-1].set_xlabel(percentile_label)\n",
    "ax[0].set_ylabel(\"$\\Delta T_s/\\overline{T_s}$ [%]\")\n",
    "ax[1].set_ylabel(\"$\\Delta r_s/\\overline{r_s}$ [%]\")\n",
    "if ((season == 'summer') and (region == 'tropics')) or ((season == 'winter') and (region == 'extratropics')):\n",
    "    ax[0].legend(fontsize=5.4, title='$\\kappa$', frameon=True, framealpha=1, edgecolor='white',title_fontsize=7, loc='lower right')\n",
    "ax[1].set_ylim([ax[1].get_ylim()[0], ax[1].get_ylim()[1]+0.5])\n",
    "ax[0].set_xlim(0, 100)\n",
    "label_subplots(fig, ax, ['a)', 'c)'] if season == 'summer' else ['b)', 'd)'], box_alpha=0)\n",
    "if region == 'tropics':\n",
    "    ax[0].set_ylim(-3.5, 2.5)\n",
    "    ax[1].set_ylim(-12, 6)\n",
    "elif region == 'extratropics':\n",
    "    ax[0].set_ylim(-8, 8)\n",
    "    ax[1].set_ylim(-24, 17)\n",
    "if save_fig or save_near_surf_anom_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/surface_anomalies_{region.lower()}_{season}.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Testing CQE assumption\n",
    "### Decompose $T_{CE}$ into CQE and non-CQE terms.\n",
    "The definition of CQE is that $\\delta h_s(x) = \\delta h_{FT}^*(x)$. Here I split $\\delta T_{CE} = \\delta T_{CQE} + \\delta T_{nonCQE}$ where $\\delta T_{CQE}$ is always non-zero but $\\delta T_{nonCQE}$ is only non-zero if $\\delta h_s(x) \\neq \\delta h_{FT}^*(x)$.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mse_mod_ft_quant3 = moist_static_energy(temp_quant3[:, ind_ft], sphum_sat(temp_quant3[:, ind_ft], pressure_ft_actual), \n",
    "                                        height=0, c_p_const=c_p + lnp_const)\n",
    "mse_mod_ft_mean = moist_static_energy(temp_mean[:, ind_ft], sphum_sat(temp_mean[:, ind_ft], pressure_ft_actual), \n",
    "                                      height=0, c_p_const=c_p + lnp_const)\n",
    "mse_sat_ft_quant3 = moist_static_energy(temp_quant3[:, ind_ft], sphum_sat(temp_quant3[:, ind_ft], pressure_ft_actual), \n",
    "                                        height=z_quant3)\n",
    "mse_sat_ft_mean = moist_static_energy(temp_mean[:, ind_ft], sphum_sat(temp_mean[:, ind_ft], pressure_ft_actual), \n",
    "                                      height=z_mean)\n",
    "temp_adiabat_quant3 = np.zeros((n_exp, n_lat, n_quant_all))\n",
    "temp_adiabat_mean = np.zeros((n_exp, n_lat))\n",
    "for i in range(n_exp):\n",
    "    for j in range(n_lat):\n",
    "        temp_adiabat_mean[i, j] = get_temp_adiabat(temp_mean[i, ind_surf, j], sphum_mean[humid_calc][i, j], p_surface, pressure_ft_actual)\n",
    "        for k in range(n_quant_all):\n",
    "            temp_adiabat_quant3[i, j, k] = get_temp_adiabat(temp_quant3[i, ind_surf, j, k], sphum_quant3[humid_calc][i, j, k], p_surface, pressure_ft_actual)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "_, _, _, beta_a1_x, beta_a2_x, _ = get_theory_prefactor_terms(temp_adiabat_quant3, p_surface, pressure_ft_actual)\n",
    "_, _, _, beta_a1_mean, beta_a2_mean, _ = get_theory_prefactor_terms(temp_adiabat_mean, p_surface, pressure_ft_actual)\n",
    "delta_temp_cqe_quant3 = (-beta_a2_x/beta_a1_x**2 * temp_ce_quant3 / temp_adiabat_quant3)[:-1] * np.diff(mse_mod_quant3, axis=0) * 1000\n",
    "delta_temp_non_cqe_quant3 = 1/beta_a1_x[:-1] * (np.diff(mse_mod_ft_quant3, axis=0) - np.diff(mse_mod_quant3, axis=0)) * 1000\n",
    "delta_temp_cqe_mean = (-beta_a2_mean/beta_a1_mean**2 * temp_ce_mean / temp_adiabat_mean)[:-1] * np.diff(mse_mod_mean, axis=0) * 1000\n",
    "delta_temp_non_cqe_mean = 1/beta_a1_mean[:-1] * (np.diff(mse_mod_ft_mean, axis=0) - np.diff(mse_mod_mean, axis=0)) * 1000"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "save_temp_cqe_fig = False\n",
    "fig, ax = plt.subplots(1,1, figsize=(width['one_col'], width['one_col']/ar), sharex=True, sharey=True)\n",
    "for i in range(n_exp-1):\n",
    "    ax.plot(quantiles_all, np.average(np.diff(temp_ce_quant3, axis=0)[i], axis=0, weights=lat_weights), color=color_seq_exp[i], label=f'{tau_lw[i]}')\n",
    "    ax.plot(quantiles_all, np.average(delta_temp_cqe_quant3[i], axis=0, weights=lat_weights), color=color_seq_exp[i], linestyle='--')\n",
    "    ax.plot(quantiles_all, np.average(delta_temp_non_cqe_quant3[i], axis=0, weights=lat_weights), color=color_seq_exp[i], linestyle=':')\n",
    "    ax.scatter(-1, np.average(np.diff(temp_ce_mean, axis=0)[i], axis=0, weights=lat_weights), marker='o', alpha=0.7, edgecolors=None,\n",
    "                  facecolors=color_seq_exp[i], lw=0)\n",
    "    ax.scatter(-1, np.average(delta_temp_cqe_mean[i], axis=0, weights=lat_weights), marker='s', alpha=0.5, edgecolors=None,\n",
    "                  facecolors=color_seq_exp[i], lw=0)\n",
    "    ax.scatter(-1, np.average(delta_temp_non_cqe_mean[i], axis=0, weights=lat_weights), marker='*', alpha=0.5, edgecolors=None,\n",
    "                  facecolors=color_seq_exp[i], lw=0)\n",
    "ax.set_xlim(-2, 100)\n",
    "ax.set_xlabel(percentile_label)\n",
    "ax.set_ylabel('$\\delta T_{CE}$ [K]')\n",
    "ax.axhline(0, color='k', lw=ax_linewidth)\n",
    "\n",
    "if save_fig or save_temp_cqe_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/delta_temp_cqe_{region.lower()}_{season}.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Are we in CQE?\n",
    "Below, I explictly plot $\\delta h_{FT}^*(x) - \\delta h_s(x)$ to test if we are in CQE. It should be zero if we are. I also compare plot $\\delta T_{CE}$ to show that there is a good correlation between the deviation from CQE and the value of $\\delta T_{CE}$."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "save_cqe_mse_fig = False\n",
    "fig, ax = plt.subplots(2,1, figsize=(width['one_col'], 2*width['one_col']/ar), sharex=True)\n",
    "for i in range(n_exp-1):\n",
    "    ax[0].plot(quantiles_all, -np.average(np.diff(mse_quant3, axis=0)[i]-np.diff(mse_sat_ft_quant3, axis=0)[i], weights=lat_weights, axis=0),\n",
    "            color=color_seq_exp[i])\n",
    "    ax[0].scatter(-1, -np.average(np.diff(mse_mean, axis=0)[i]-np.diff(mse_sat_ft_mean, axis=0)[i], weights=lat_weights, axis=0), \n",
    "                  marker='o', alpha=0.7, edgecolors=None, facecolors=color_seq_exp[i], lw=0)\n",
    "    ax[1].plot(quantiles_all, np.average(np.diff(temp_ce_quant3, axis=0)[i], axis=0, weights=lat_weights), color=color_seq_exp[i])\n",
    "    ax[1].scatter(-1, np.average(np.diff(temp_ce_mean, axis=0)[i], axis=0, weights=lat_weights), marker='o', alpha=0.7, edgecolors=None,\n",
    "                  facecolors=color_seq_exp[i], lw=0)\n",
    "ax[0].axhline(0, color='k', lw=ax_linewidth)\n",
    "ax[1].axhline(0, color='k', lw=ax_linewidth)\n",
    "ax[0].set_xlim(-2, 100)\n",
    "ax[-1].set_xlabel(percentile_label)\n",
    "ax[0].set_ylabel('$\\delta h_{FT}^* - \\delta h_s$ [kJ/kg]')\n",
    "ax[1].set_ylabel('$\\delta T_{CE}$ [K]')\n",
    "\n",
    "if save_fig or save_cqe_mse_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/mse_cqe_{region.lower()}_{season}.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
