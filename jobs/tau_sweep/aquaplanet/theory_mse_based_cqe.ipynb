{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Theory for $\\delta T(x)$ accounting for changes in WTG and CE\n",
    "This starts from  $\\delta h(x) = \\delta h_{FT}(x) + \\delta \\epsilon(x)$ where $\\delta \\epsilon(x) = 0$ in CQE, to obtain an equation for $\\delta T_s(x)$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import copy\n",
    "import sys\n",
    "import os\n",
    "# REMOTE - So can access functions in isca_tools which is in home/Isca directory\n",
    "# sys.path.append(os.path.join(os.environ['HOME'], 'Isca'))\n",
    "# LOCAL - So can access functions in isca_tools which is in StAndrews/Isca\n",
    "sys.path.append(os.environ['PWD'])\n",
    "import isca_tools\n",
    "from isca_tools.utils.moist_physics import moist_static_energy, clausius_clapeyron_factor, sphum_sat\n",
    "from isca_tools.utils.constants import kappa, L_v, c_p, g, R\n",
    "from isca_tools.utils import area_weighting, annual_mean\n",
    "from isca_tools.papers.byrne_2021 import get_quant_ind\n",
    "from isca_tools.thesis.adiabat_theory import (get_temp_adiabat, get_delta_mse_mod_anom_theory, get_theory_prefactor_terms,\n",
    "                                              decompose_temp_adiabat_anomaly, get_delta_temp_quant_theory, get_delta_temp_quant_theory_simple, \n",
    "                                              get_delta_temp_quant_theory_simple2)\n",
    "from isca_tools.utils.stats import z_score_from_confidence_interval\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import scipy.optimize\n",
    "from tqdm import tqdm\n",
    "from scipy import integrate\n",
    "import numpy_indexed\n",
    "from scipy.stats import percentileofscore\n",
    "import copy\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "# Use custom matplotlib style for publishing\n",
    "plt.style.use('/Users/joshduffield/Documents/StAndrews/Isca/jobs/tau_sweep/aquaplanet/publish_figures/publish.mplstyle')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T11:27:43.039966Z",
     "start_time": "2024-05-16T11:27:43.026126Z"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load dataset - one at surface and one in free troposphere\n",
    "var_keep = ['temp', 'sphum', 'height', 'klzbs', 'convflag']        # only keep variables required to compute relative humidity and MSE\n",
    "# var_keep = ['temp', 'sphum', 'height', 'ucomp', 'vcomp']\n",
    "# Load dataset\n",
    "tau_lw_ref = 1\n",
    "tau_lw_warm = 1.5\n",
    "exp_dir = 'tau_sweep/aquaplanet/depth=1/'\n",
    "# exp_dir = 'tau_sweep/aquaplanet/'\n",
    "exp_names = [f\"k={str(tau_lw_ref).replace('.','_')}\", f\"k={str(tau_lw_warm).replace('.','_')}\"]\n",
    "n_exp = len(exp_names)\n",
    "ds = []\n",
    "albedo = []\n",
    "tau_sw = []\n",
    "tau_lw = []\n",
    "for i in range(n_exp):\n",
    "    ds_use = isca_tools.load_dataset(exp_dir + exp_names[i])[var_keep]\n",
    "    ds += [ds_use]      # only keep the surface values\n",
    "    namelist = isca_tools.load_namelist(exp_dir + exp_names[i])  # Need this for albedo_value\n",
    "    albedo += [namelist['mixed_layer_nml']['albedo_value']]\n",
    "    tau_sw += [namelist['two_stream_gray_rad_nml']['atm_abs']]\n",
    "    tau_lw += [namelist['two_stream_gray_rad_nml']['odp']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T11:27:48.958384Z",
     "start_time": "2024-05-16T11:27:45.012656Z"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get datasets\n",
    "Get one surface dataset for summer for each $\\kappa$, combining all latitudes: `ds_all`. This combines the summer months in each hemisphere, e.g. negative latitudes will only correspond to times in December, January or February.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# If true, will save all figures to desktop - option to save specific figures later on.\n",
    "save_fig = False\n",
    "# if publishing figure, use high dpi\n",
    "publish_fig = True\n",
    "\n",
    "ar = 4/3        # aspect ratio (width/height)\n",
    "# Details required for Journal of Climate Figures\n",
    "low_dpi = 100\n",
    "dpi = {'monochrome': 1100, 'combination': 800, 'halftone': 300}\n",
    "width = {'one_col': 3.2, 'two_col': 5.5}        # width in inches \n",
    "save_pad_inches = 0.05\n",
    "\n",
    "# Default parameters\n",
    "default_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "ax_linewidth = plt.rcParams['axes.linewidth']\n",
    "\n",
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-16T11:27:51.221635Z",
     "start_time": "2024-05-16T11:27:51.218883Z"
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Compute Global Average Surface Temperature and get near surface temperature data\n",
    "# Use all data after 2 years, as clearly converged from the above spin up plot\n",
    "use_time_start = 360*2\n",
    "pressure_ft = 500           # Desired approximate pressure of free troposphere (hPa)\n",
    "\n",
    "# Tropics\n",
    "# region = 'tropics'\n",
    "# lat_min = 0\n",
    "# lat_max = 20\n",
    "# Extratropics\n",
    "region = 'extratropics'\n",
    "lat_min = 40\n",
    "lat_max = 65\n",
    "# Poles\n",
    "# region = 'High Latitudes'\n",
    "# lat_min = 70\n",
    "# lat_max = 90\n",
    "# region = 'Global'\n",
    "# lat_min = 0\n",
    "# lat_max = 90\n",
    "\n",
    "# Chose whether to only consider summer days or consider all days\n",
    "# season = 'all'\n",
    "season = 'summer'\n",
    "# season = 'winter'\n",
    "if season == 'summer':\n",
    "    if region == 'tropics':\n",
    "        season_months = {'nh': [5, 6, 7, 8, 9, 10], 'sh': [11, 12, 1, 2, 3, 4]}   \n",
    "    else:\n",
    "        season_months = {'nh': [6, 7, 8], 'sh': [12, 1, 2]}   # JJA for NH and DJF for SH\n",
    "elif season == 'winter':\n",
    "    if region == 'tropics':\n",
    "        season_months = {'sh': [5, 6, 7, 8, 9, 10], 'nh': [11, 12, 1, 2, 3, 4]}\n",
    "    else:\n",
    "        season_months = {'sh': [6, 7, 8], 'nh': [12, 1, 2]} \n",
    "\n",
    "ds_all = []\n",
    "with tqdm(total=n_exp, position=0, leave=True) as pbar:\n",
    "    for i in range(n_exp):\n",
    "        ds_use = ds[i].sel(time=slice(use_time_start, np.inf))\n",
    "        ds_use = ds_use.sel(pfull=[np.inf, pressure_ft], method='nearest')      # only keep the surface values - get rid of pfull coordinate\n",
    "        ds_use = ds_use.where((np.abs(ds_use.lat) <= lat_max) & (np.abs(ds_use.lat) >= lat_min), drop=True)\n",
    "\n",
    "        if season == 'summer' or season == 'winter':\n",
    "            # Only consider summer as has expected circulation\n",
    "            ds_nh_summer = isca_tools.utils.annual_time_slice(ds_use, season_months['nh']).sel(lat=slice(lat_min, lat_max)) \n",
    "            ds_sh_summer = isca_tools.utils.annual_time_slice(ds_use, season_months['sh']).sel(lat=slice(-lat_max, -lat_min))  \n",
    "            # Combine hemispheres and average over longitude, time and latitude.\n",
    "            # Note that April, May, June, October, November and December will not be included in this dataset\n",
    "            ds_use = xr.concat([ds_sh_summer, ds_nh_summer], dim='lat')\n",
    "        ds_use = ds_use.stack(lon_time=(\"lon\",\"time\"), create_index=False).chunk(dict(lon_time=-1))\n",
    "        ds_all += [ds_use.load()]\n",
    "        pbar.update(1)\n",
    "\n",
    "ind_surf = 0\n",
    "ind_ft = 1\n",
    "p_surface = float(ds_all[0].pfull[ind_surf]) * 100\n",
    "pressure_ft_actual = float(ds_all[0].pfull[ind_ft]) * 100       # Actual pressure of free troposphere (Pa)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T11:56:52.057223Z",
     "start_time": "2024-05-17T11:56:36.911016Z"
    }
   },
   "execution_count": 131,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Definition of Summer\n",
    "Below I look at the months that are convecting, to deduce a good definition of summer."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T11:57:08.537167Z",
     "start_time": "2024-05-17T11:56:52.061113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# annual_mean_lat_plot = 64\n",
    "annual_mean_lat_plot = 18\n",
    "annual_mean_tau_ind = 0\n",
    "ds_annual_mean = annual_mean(ds[annual_mean_tau_ind].sel(time=slice(use_time_start, np.inf)\n",
    "                                                         ).sel(lat=[annual_mean_lat_plot, -annual_mean_lat_plot],\n",
    "                                                               method='nearest').mean(dim='lon').isel(pfull=-1)).load()\n",
    "month_ticks = (np.arange(15,12*30+15,30), ['J','F','M','A','M','J','J','A','S','O','N','D'])\n",
    "\n",
    "pressure_from_level_func = scipy.interpolate.interp1d(np.arange(len(ds[0].pfull)), ds[0].pfull)\n",
    "def lzb(k, interp_func=pressure_from_level_func):\n",
    "    # Offset by -1 because fortran starts with 1, but python starts with 0\n",
    "    # ds.t_ref will match exactly ds.temp if -2 used as offset, but this is not the LNB.\n",
    "    if np.size(k) == 1:\n",
    "        return float(interp_func(k-1))\n",
    "    else:\n",
    "        return interp_func(k-1)"
   ],
   "execution_count": 132,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T11:57:08.728396Z",
     "start_time": "2024-05-17T11:57:08.538833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_summer_def_fig = False\n",
    "\n",
    "fig, ax = plt.subplots(2,1, figsize=(width['one_col'], 2*width['one_col']/ar), sharex=True)\n",
    "ax2 = ax[1].twinx()\n",
    "for i in range(ds_annual_mean.lat.size):\n",
    "    ax[0].plot(ds_annual_mean.time-0.5, ds_annual_mean.temp[:, i], alpha=0.2 if ds_annual_mean.lat[i]<0 else 1, color='k')\n",
    "    ax[1].plot(ds_annual_mean.time-0.5, ds_annual_mean.convflag[:, i], color=default_colors[0], alpha=0.2 if ds_annual_mean.lat[i]<0 else 1)\n",
    "    ax2.plot(ds_annual_mean.time-0.5, lzb(ds_annual_mean.klzbs[:, i]), color=default_colors[1], alpha=0.2 if ds_annual_mean.lat[i]<0 else 1)\n",
    "for i in range(len(ax)):\n",
    "    if np.abs(ds_annual_mean.lat[0])>22:\n",
    "        ax[i].axvline(5*30-1, color='k', lw=ax_linewidth)\n",
    "        ax[i].axvline(8*30-1, color='k', lw=ax_linewidth)\n",
    "        ax[i].axvline(11*30-1, color='k', lw=ax_linewidth, alpha=0.2)\n",
    "        ax[i].axvline(2*30-1, color='k', lw=ax_linewidth, alpha=0.2)\n",
    "    else:\n",
    "        ax[i].axvline(4*30-1, color='k', lw=ax_linewidth)\n",
    "        ax[i].axvline(10*30-1, color='k', lw=ax_linewidth)\n",
    "ax2.axhline(pressure_ft_actual/100, color=default_colors[1], lw=ax_linewidth)\n",
    "ax2.invert_yaxis()\n",
    "ax2.spines[['left', 'bottom']].set_visible(False)\n",
    "ax2.spines[['right']].set_visible(True)\n",
    "ax2.spines[['right']].set_color(default_colors[1])\n",
    "ax[1].spines[['left']].set_color(default_colors[0])\n",
    "ax[1].set_ylabel('convflag', color=default_colors[0])\n",
    "ax2.set_ylabel('LNB [hPa]', color=default_colors[1])\n",
    "ax[0].set_ylabel('Near-surface temperature [K]')\n",
    "ax[0].set_xlim(-1,360)\n",
    "ax[0].set_xticks(*month_ticks)\n",
    "ax[0].set_title(f'$\\kappa= {tau_lw[annual_mean_tau_ind]}$; Lat = {round(float(ds_annual_mean.lat[0]))}$\\degree$')\n",
    "\n",
    "if save_fig or save_summer_def_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/summer_definition_lat={annual_mean_lat_plot}.pdf\", \n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "execution_count": 133,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Near Surface Temperature Quantile\n",
    "Get variables as a function of near-surface temperature quantile"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "quantiles_all = np.arange(1, 100)\n",
    "percentile_label = 'Temperature percentile, $x$'\n",
    "n_quant_all = len(quantiles_all)\n",
    "n_lat = len(ds_all[0].lat)\n",
    "n_pressure = ds_all[0].pfull.shape[0]\n",
    "lat_weights = np.cos(np.deg2rad(ds_all[0].lat))     # latitude area weighting is just the cosine\n",
    "\n",
    "# Days must have klzb < thresh and convflag > thresh to be considered convecting.\n",
    "klzb_thresh = 13\n",
    "convflag_thresh = 1\n",
    "\n",
    "temp_mean = np.zeros((n_exp, n_pressure, n_lat))         # second index: 0 is surface, 1 is free trop\n",
    "mse_mean = np.zeros((n_exp, n_pressure, n_lat))\n",
    "# 2 different methods for computing r_mean and sphum_mean - q calculates from sphum, while r calculates from rh.\n",
    "r_mean = np.zeros((n_exp, n_lat))\n",
    "z_mean = np.zeros((n_exp, n_pressure, n_lat))\n",
    "\n",
    "lnp_const = R * np.log(p_surface/pressure_ft_actual)/2      # for modified MSE calculation\n",
    "# as function of temperature quantile\n",
    "temp_quant3 = np.zeros((n_exp, n_pressure, n_lat, n_quant_all))\n",
    "mse_quant3 = np.zeros((n_exp, n_pressure, n_lat, n_quant_all))\n",
    "r_quant3 = np.zeros((n_exp, n_lat, n_quant_all))\n",
    "z_quant3 = np.zeros((n_exp, n_pressure, n_lat, n_quant_all))\n",
    "convflag_quant3 = np.zeros((n_exp, n_lat, n_quant_all))\n",
    "klzbs_quant3 = np.zeros((n_exp, n_lat, n_quant_all))\n",
    "convfract_quant3 = np.zeros((n_exp, n_lat, n_quant_all))            # record fraction of days convecting\n",
    "\n",
    "with tqdm(total=n_exp*n_lat*n_quant_all, position=0, leave=True) as pbar:\n",
    "    for i in range(n_exp):\n",
    "        temp_mean[i] = ds_all[i].temp.mean(dim='lon_time')\n",
    "        z_mean[i] = ds_all[i].height.mean(dim='lon_time')\n",
    "        rh_use = ds_all[i].sphum.isel(pfull=ind_surf)/sphum_sat(ds_all[i].temp.isel(pfull=ind_surf), p_surface)\n",
    "        r_mean[i] = rh_use.mean(dim='lon_time')\n",
    "        if 'convflag' in var_keep:\n",
    "            is_convecting = np.logical_and(ds_all[i].klzbs<klzb_thresh, ds_all[i].convflag > convflag_thresh)\n",
    "        for k in range(n_lat):\n",
    "            for j, quant in enumerate(quantiles_all):\n",
    "                use_ind = get_quant_ind(ds_all[i].temp.isel(pfull=ind_surf)[k], quant, 0.5, 0.5)\n",
    "                z_quant3[i, :, k, j] = ds_all[i].height[:, k, use_ind].mean(dim='lon_time')\n",
    "                temp_quant3[i, :, k, j] = ds_all[i].temp[:, k, use_ind].mean(dim='lon_time')\n",
    "                r_quant3[i, k, j] = rh_use[k, use_ind].mean(dim='lon_time')\n",
    "                if 'convflag' in var_keep:\n",
    "                    convflag_quant3[i, k, j] = ds_all[i].convflag[k, use_ind].mean(dim='lon_time')\n",
    "                    klzbs_quant3[i, k, j] = ds_all[i].klzbs[k, use_ind].mean(dim='lon_time')\n",
    "                    convfract_quant3[i, k, j] = np.sum(is_convecting[k, use_ind])/is_convecting[k, use_ind].size\n",
    "                pbar.update(1)\n",
    "# Compute sphum from rh values\n",
    "sphum_quant3 = sphum_sat(temp_quant3[:, ind_surf], p_surface) * r_quant3\n",
    "sphum_mean = sphum_sat(temp_mean[:, ind_surf], p_surface) * r_mean\n",
    "mse_quant3[:, ind_surf] = moist_static_energy(temp_quant3[:, ind_surf], sphum_quant3, z_quant3[:, ind_surf])\n",
    "mse_quant3[:, ind_ft] = moist_static_energy(temp_quant3[:, ind_ft], sphum_sat(temp_quant3[:, ind_ft], pressure_ft_actual), z_quant3[:, ind_ft])\n",
    "mse_mean[:, ind_surf] = moist_static_energy(temp_mean[:, ind_surf], sphum_mean, z_mean[:, ind_surf])\n",
    "mse_mean[:, ind_ft] = moist_static_energy(temp_mean[:, ind_ft], sphum_sat(temp_mean[:, ind_ft], pressure_ft_actual), z_mean[:, ind_ft])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T11:57:25.030747Z",
     "start_time": "2024-05-17T11:57:08.730634Z"
    }
   },
   "execution_count": 134,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T11:57:25.036261Z",
     "start_time": "2024-05-17T11:57:25.032213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Max % Deviations From Mean')\n",
    "print('Temp:', 100*np.abs(np.average((temp_quant3[0, ind_surf]-temp_mean[0, ind_surf, :, np.newaxis])/temp_mean[0, ind_surf, :, np.newaxis], \n",
    "                                     axis=0, weights=lat_weights)).max())\n",
    "\n",
    "print(f'RH:', 100*np.abs(np.average((r_quant3[0]-r_mean[0, :, np.newaxis])/r_mean[0, :, np.newaxis], \n",
    "                                            axis=0, weights=lat_weights)).max())"
   ],
   "execution_count": 135,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Relating $z_{FT}$ to $T_{500}$ and $T_s$\n",
    "A crucial aspect to this theory is relating the geopotential height $z_{FT}$ to near-surface temperature $T$ and free troposphere temperature $T_{FT}$.\n",
    "\n",
    "We start with two equations, from Zhang 2023. The first combines hydrostatic balance and the ideal gas law. The second assumes a constant lapse rate, $\\Gamma$, for integration processes.\n",
    "\n",
    "$d\\ln p = -\\frac{g}{RT(p)}dz$;      $z(p) - z_s = \\frac{T_s - T(p)}{\\Gamma}$\n",
    "\n",
    "Combining the two, we get $d\\ln p = \\frac{g}{R\\Gamma}d\\ln T$.\n",
    "\n",
    "Integrating between the free troposphere at 500hPa and surface at 1000hPa, we get:\n",
    "$\\ln(\\frac{1000}{500}) = \\ln 2 = \\frac{g}{R\\Gamma}\\ln(\\frac{T_s}{T_{500}})$ or $\\frac{1}{\\Gamma} = \\frac{R\\ln 2}{g\\ln(\\frac{T_s}{T_{500}})}$\n",
    "\n",
    "We also have the $z$ equation applied at 500hPa: $z_{500} - z_s = \\frac{T_s - T_{500}}{\\Gamma}$. Combining the two, we get:\n",
    "$z_{500} - z_s \\approx \\frac{R\\ln 2(T_s - T_{500})}{g\\ln(\\frac{T_s}{T_{500}})}$\n",
    "\n",
    "We can re-write the denominator in $\\ln(1+x)$ form as $\\ln(1+\\frac{T_s-T_{500}}{T_{500}})$. Here $x=\\frac{T_s-T_{500}}{T_{500}}$ and is small. Max value in tropics is about 0.15. \n",
    "\n",
    "The taylor series is $\\frac{1}{\\ln(1+x)} \\approx \\frac{1}{x} + \\frac{1}{2} - \\frac{x}{12} + ...$. Because $x$ is small, I propose keeping just the first two terms. In which case, we get:\n",
    "\n",
    "$z_{500} - z_s \\approx \\frac{R\\ln 2(T_s - T_{500})}{g}(\\frac{T_{500}}{T_s-T_{500}} + \\frac{1}{2}) = \\frac{R\\ln 2}{2g}(T_s + T_{500})$\n",
    "\n",
    "The plots below shows that the taylor approximation is pretty accurate, and they are both decent approximations for the actual geopotential height."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_z_theory(temp_surf, temp_ft, taylor=True, pressure_surf=p_surface, pressure_ft=pressure_ft_actual):\n",
    "    lnp_prefactor = R * np.log(pressure_surf/pressure_ft) / g\n",
    "    if taylor:\n",
    "        return lnp_prefactor/2 * (temp_surf + temp_ft)\n",
    "    else:\n",
    "        return lnp_prefactor * (temp_surf - temp_ft) / np.log(temp_surf/temp_ft)\n",
    "\n",
    "z_theory_quant3 = {key: np.zeros((n_exp, n_lat, n_quant_all)) for key in ['full', 'taylor']}\n",
    "z_theory_mean = {key: np.zeros((n_exp, n_lat)) for key in ['full', 'taylor']}\n",
    "for i in range(n_exp):\n",
    "    for key in z_theory_quant3:\n",
    "        z_theory_quant3[key][i] = get_z_theory(temp_quant3[i, ind_surf], temp_quant3[i, ind_ft], True if key=='taylor' else False)\n",
    "        z_theory_mean[key][i] = get_z_theory(temp_mean[i, ind_surf], temp_mean[i, ind_ft], True if key=='taylor' else False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T11:57:25.064371Z",
     "start_time": "2024-05-17T11:57:25.036995Z"
    }
   },
   "execution_count": 136,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "save_z_ft_fig = True\n",
    "fig, ax = plt.subplots(2,2, figsize=(2*width['one_col'], 2*width['one_col']/ar), sharex=True)\n",
    "linestyles_use = {'full': '--', 'taylor': ':'}\n",
    "for i in range(n_exp):\n",
    "    ax[0, 0].plot(quantiles_all, \n",
    "               np.average(z_quant3[i, ind_ft] - z_quant3[i, ind_surf], axis=0, weights=lat_weights), color=default_colors[i],\n",
    "               label=f'$\\\\kappa={tau_lw[i]}$')\n",
    "    ax[0, 0].axhline(np.average(z_mean[i, ind_ft]-z_mean[i, ind_surf], axis=0, weights=lat_weights), color=default_colors[i], lw=2, alpha=0.2)\n",
    "    for key in z_theory_quant3:\n",
    "        ax[0, 0].plot(quantiles_all, \n",
    "                   np.average(z_theory_quant3[key][i], axis=0, weights=lat_weights), color=default_colors[i], \n",
    "                   linestyle=linestyles_use[key])\n",
    "        ax[0, 0].axhline(np.average(z_theory_mean[key][i], axis=0, weights=lat_weights), color=default_colors[i], \n",
    "                      linestyle=linestyles_use[key], lw=2, alpha=0.2)\n",
    "ax[1, 0].plot(quantiles_all, \n",
    "           np.average(np.diff(z_quant3[:, ind_ft] - z_quant3[:, ind_surf], axis=0)[0], axis=0, weights=lat_weights), color='k',\n",
    "           label='Simulated')\n",
    "ax[1, 0].axhline(np.average(np.diff(z_mean[:, ind_ft]-z_mean[:, ind_surf], axis=0)[0], axis=0, weights=lat_weights), \n",
    "              color='k', lw=2, alpha=0.2)\n",
    "for key in z_theory_quant3:\n",
    "    ax[1, 0].plot(quantiles_all, \n",
    "                   np.average(z_theory_quant3[key][1]-z_theory_quant3[key][0], axis=0, weights=lat_weights), \n",
    "               color='k', linestyle=linestyles_use[key], label=f'Theory - {key}')\n",
    "    ax[1, 0].axhline(np.average(z_theory_mean[key][1]-z_theory_mean[key][0], axis=0, weights=lat_weights), color='k', \n",
    "                  linestyle=linestyles_use[key], lw=2, alpha=0.2)\n",
    "\n",
    "for i in range(n_exp):\n",
    "    ax[0, 1].plot(quantiles_all, \n",
    "               np.average(z_quant3[i, ind_ft] - z_quant3[i, ind_surf] - (z_mean[i, ind_ft]-z_mean[i, ind_surf])[:, np.newaxis], \n",
    "                          axis=0, weights=lat_weights), color=default_colors[i], label=f'$\\\\kappa={tau_lw[i]}$')\n",
    "    for key in z_theory_quant3:\n",
    "        ax[0, 1].plot(quantiles_all, np.average(z_theory_quant3[key][i] - z_theory_mean[key][i][:, np.newaxis], axis=0, weights=lat_weights),\n",
    "                      color=default_colors[i], linestyle=linestyles_use[key])\n",
    "ax[1, 1].plot(quantiles_all, \n",
    "           np.average(np.diff(z_quant3[:, ind_ft] - z_quant3[:, ind_surf] - (z_mean[:, ind_ft]-z_mean[:, ind_surf])[:, :, np.newaxis], axis=0)[0], \n",
    "                      axis=0, weights=lat_weights), color='k')\n",
    "for key in z_theory_quant3:\n",
    "    ax[1, 1].plot(quantiles_all, \n",
    "                   np.average(z_theory_quant3[key][1]-z_theory_quant3[key][0] - (z_theory_mean[key][1]-z_theory_mean[key][0])[:, np.newaxis], \n",
    "                              axis=0, weights=lat_weights), color='k', linestyle=linestyles_use[key], label=f'Theory - {key}') \n",
    "\n",
    "ax[0, 0].legend()\n",
    "ax[1, 0].legend()\n",
    "ax[0, 0].set_ylabel('$z-z_s$ [m]')\n",
    "ax[0, 1].set_ylabel('$\\Delta (z-z_s)$ [m]')\n",
    "ax[1, 0].set_ylabel('$\\delta (z-z_s)$ [m]')\n",
    "ax[1, 1].set_ylabel('$\\delta \\Delta (z-z_s)$ [m]')\n",
    "ax[1, 0].set_xlabel(percentile_label)\n",
    "ax[0, 0].set_xlim(0, 100)\n",
    "ax[0, 1].axhline(0, color='k', lw=ax_linewidth)\n",
    "ax[1, 1].axhline(0, color='k', lw=ax_linewidth)\n",
    "plt.tight_layout()\n",
    "if save_fig or save_z_ft_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/z_ft_approx_{region}_{season}.pdf\",\n",
    "                                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-18T07:15:32.761011Z",
     "start_time": "2024-05-18T07:15:31.943756Z"
    }
   },
   "execution_count": 145,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Theory - Only $z$ approximation\n",
    "I start the theory with the exact equation $h_s(x) = h_{FT}(x) + \\epsilon(x)$ where $\\epsilon$ indicates the deviation from convective equilibrium (CE). \n",
    "\n",
    "If I take changes with warming and then only make the approximation:\n",
    "$\\delta (z_{500} - z_s) \\approx \\frac{R\\ln 2}{2g} \\delta (T_s + T_{FT})$, I can obtain an estimate for $\\delta T_s(x)$ through solving:\n",
    "\n",
    "$$\\delta \\left((c_p - R^{\\dagger})T_s(x) + L_v q_s(x)\\right) \\approx \\delta \\left((c_p + R^{\\dagger})T_{FT}(x) + L_v q^*_{FT}(x)\\right) + \\delta \\epsilon(x)$$\n",
    "\n",
    "I do this numerically below (without any taylor approximations).\n",
    "\n",
    "We see that wherever the approximation for $\\delta (z_{500} - z_s)$ is overestimated by the taylor series above, $\\delta T_s(x)$ is also over-estimated.\n",
    "\n",
    "Above we see that the theory does a better job at approximating the change in geopotential height anomaly ($\\delta \\Delta z$) rather than change in geopotential height ($\\delta z$). As such, when we divide the theoretical $\\delta T_s(x)$ by the theoretical $\\delta \\overline{T_s}$, the theory looks better below."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T11:57:25.610874Z",
     "start_time": "2024-05-17T11:57:25.603521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def delta_temp_fit_func(temp_surf_change: float, temp_surf0: float, r_surf: np.ndarray, temp_ft: np.ndarray, epsilon: np.ndarray,\n",
    "                        pressure_surf: float = p_surface, pressure_ft: float = pressure_ft_actual) -> float:\n",
    "    \"\"\"\n",
    "    This finds $\\delta T_s(x)$ such that $\\delta h(x) = \\delta h_{FT}^*(x) + \\delta \\epsilon(x)$\n",
    "\n",
    "    Args:\n",
    "        temp_surf_change: float\n",
    "            Change in temperature at `pressure_surf` in Kelvin.\n",
    "        temp_surf0:\n",
    "            Actual temperature at `pressure_surf` in reference climate in Kelvin.\n",
    "        r_surf: float [n_exp]\n",
    "            Actual relative humidity at `pressure_surf`.\n",
    "        temp_ft: float [n_exp]\n",
    "            Temperature at `pressure_ft` in Kelvin for each experiment.\n",
    "        epsilon: float [n_exp]\n",
    "            $\\epsilon = h_s(x) - h_{FT}^*(x)$ in *kJ/kg*. It quantifies the deviation from CE and CQE.\n",
    "        pressure_surf:\n",
    "            Pressure at near-surface in *Pa*.\n",
    "        pressure_ft:\n",
    "            Pressure at free troposphere level in *Pa*.\n",
    "    Returns:\n",
    "        MSE discrepancy: difference between surface and free troposphere saturated MSE in *kJ/kg*.\n",
    "    \"\"\"\n",
    "    n_exp = len(r_surf)\n",
    "    R_mod = R * np.log(pressure_surf / pressure_ft) / 2\n",
    "    mse_mod_surf_cold = moist_static_energy(temp_surf0, r_surf[0] * sphum_sat(temp_surf0, pressure_surf), height=0, c_p_const=c_p - R_mod)\n",
    "    mse_mod_surf_hot = moist_static_energy(temp_surf0 + temp_surf_change, r_surf[1] * sphum_sat(temp_surf0 + temp_surf_change, pressure_surf), \n",
    "                                           height=0, c_p_const=c_p - R_mod)\n",
    "    mse_mod_ft = [moist_static_energy(temp_ft[i], sphum_sat(temp_ft[i], pressure_ft), height=0, c_p_const=c_p + R_mod) for i in range(n_exp)]\n",
    "    mse_mod_surf_change = mse_mod_surf_hot - mse_mod_surf_cold\n",
    "    mse_mod_ft_change = mse_mod_ft[1] - mse_mod_ft[0]\n",
    "    epsilon_change = epsilon[1] - epsilon[0]\n",
    "    return mse_mod_surf_change - mse_mod_ft_change - epsilon_change\n",
    "\n",
    "def get_temp_change_theory(temp_surf0, r_surf, temp_ft, epsilon, pressure_surf = p_surface, pressure_ft = pressure_ft_actual, taylor_level='linear'):\n",
    "    R_mod, q_sat_surf, alpha_surf, beta_s1, beta_s2, _ = get_theory_prefactor_terms(temp_surf0, pressure_surf, pressure_ft, r_surf[0] * \n",
    "                                                                                    sphum_sat(temp_surf0, pressure_surf))\n",
    "    _, q_sat_ft, alpha_ft, beta_ft1, beta_ft2, _ = get_theory_prefactor_terms(temp_ft[0], pressure_surf, pressure_ft)\n",
    "    r_change = r_surf[1] - r_surf[0]\n",
    "    temp_ft_change = temp_ft[1] - temp_ft[0]\n",
    "    epsilon_change = (epsilon[1] - epsilon[0]) * 1000\n",
    "    \n",
    "    coef_surf_linear = beta_s1\n",
    "    if 'nl' in taylor_level:\n",
    "        coef_surf_linear = coef_surf_linear + L_v * alpha_surf * q_sat_surf * r_change\n",
    "        \n",
    "    if 'squared' in taylor_level:\n",
    "        coef_surf_squared = 0.5 * beta_s2 / temp_surf0\n",
    "        coef_ft_squared = 0.5 * beta_ft2 / temp_ft[0]\n",
    "    else:\n",
    "        coef_surf_squared = 0\n",
    "        coef_ft_squared = 0\n",
    "    coef_ft_linear = beta_ft1\n",
    "    mse_ft_change_approx = coef_ft_squared * temp_ft_change**2 + coef_ft_linear * temp_ft_change\n",
    "    \n",
    "    quadratic_constant = L_v * q_sat_surf * r_change - mse_ft_change_approx - epsilon_change\n",
    "    return np.roots([coef_surf_squared, coef_surf_linear, quadratic_constant])[-1]"
   ],
   "execution_count": 138,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T11:57:26.133719Z",
     "start_time": "2024-05-17T11:57:25.611910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epsilon_mean = np.asarray([mse_mean[i, ind_surf] - mse_mean[i, ind_ft] for i in range(n_exp)])\n",
    "epsilon_quant3 = np.asarray([mse_quant3[i, ind_surf] - mse_quant3[i, ind_ft] for i in range(n_exp)])\n",
    "\n",
    "temp_mean_change = temp_mean[1, ind_surf] - temp_mean[0, ind_surf]\n",
    "temp_quant_change = temp_quant3[1, ind_surf] - temp_quant3[0, ind_surf]\n",
    "temp_mean_change_theory = {key: np.zeros(n_lat) for key in ['just_z', 'taylor', 'taylor_nl']}\n",
    "temp_quant_change_theory = {key: np.zeros((n_lat, n_quant_all)) for key in ['just_z', 'taylor', 'taylor_nl']}\n",
    "for i in range(n_lat):\n",
    "    temp_mean_change_theory['just_z'][i] = scipy.optimize.fsolve(delta_temp_fit_func, 5, args=(temp_mean[0, ind_surf, i], r_mean[:, i], \n",
    "                                                                                        temp_mean[:, ind_ft, i], epsilon_mean[:, i]))\n",
    "    temp_mean_change_theory['taylor'][i] = get_temp_change_theory(temp_mean[0, ind_surf, i], r_mean[:, i], temp_mean[:, ind_ft, i], \n",
    "                                                                  epsilon_mean[:, i])\n",
    "    temp_mean_change_theory['taylor_nl'][i] = get_temp_change_theory(temp_mean[0, ind_surf, i], r_mean[:, i], temp_mean[:, ind_ft, i],  \n",
    "                                                                     epsilon_mean[:, i], taylor_level='nl')\n",
    "    for j in range(n_quant_all):\n",
    "        temp_quant_change_theory['just_z'][i, j] = scipy.optimize.fsolve(\n",
    "            delta_temp_fit_func, 5, args=(temp_quant3[0, ind_surf, i, j], r_quant3[:, i, j], temp_quant3[:, ind_ft, i, j], epsilon_quant3[:, i, j]))\n",
    "        temp_quant_change_theory['taylor'][i, j] = get_temp_change_theory(temp_quant3[0, ind_surf, i, j], r_quant3[:, i, j], \n",
    "                                                                          temp_quant3[:, ind_ft, i, j], epsilon_quant3[:, i, j])\n",
    "        temp_quant_change_theory['taylor_nl'][i, j] = get_temp_change_theory(temp_quant3[0, ind_surf, i, j], r_quant3[:, i, j], \n",
    "                                                                          temp_quant3[:, ind_ft, i, j], epsilon_quant3[:, i, j], taylor_level='nl')\n",
    "# scipy.optimize.fsolve(delta_temp_fit_func, 273, args=(temp_surf, sphum_surf, pressure_surf, pressure_ft))"
   ],
   "execution_count": 139,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T11:57:26.369845Z",
     "start_time": "2024-05-17T11:57:26.143197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_theory1_fig = True\n",
    "linestyles_use = ['-', '--', ':']\n",
    "fig, ax = plt.subplots(2,1, figsize=(width['one_col'], 2*width['one_col']/ar), sharex=True)\n",
    "ax[0].plot(quantiles_all, np.average(temp_quant_change, axis=0, weights=lat_weights), color='k', label='Simulated')\n",
    "ax[0].axhline(np.average(temp_mean_change, axis=0, weights=lat_weights), color='k')\n",
    "ax[1].plot(quantiles_all, np.average(temp_quant_change/temp_mean_change[:, np.newaxis], axis=0, weights=lat_weights), color='k', label='Theory')\n",
    "for i, key in enumerate(temp_quant_change_theory):\n",
    "    ax[0].plot(quantiles_all, np.average(temp_quant_change_theory[key], axis=0, weights=lat_weights), color=default_colors[0], \n",
    "               label=f'Theory ({key})', linestyle=linestyles_use[i])\n",
    "    ax[0].axhline(np.average(temp_mean_change_theory[key], axis=0, weights=lat_weights), color=default_colors[0], linestyle=linestyles_use[i])\n",
    "    ax[1].plot(quantiles_all, np.average(temp_quant_change_theory[key]/temp_mean_change_theory[key][:, np.newaxis], axis=0,\n",
    "                                         weights=lat_weights), color=default_colors[0], linestyle=linestyles_use[i])\n",
    "ax[1].axhline(1, color='k', lw=ax_linewidth)\n",
    "ax[0].legend()\n",
    "ax[0].set_ylabel('$\\delta T_s$ [K]')\n",
    "ax[1].set_ylabel('Scaling factor, $\\delta T_s(x)/\\delta \\overline{T_s}$')\n",
    "\n",
    "if save_fig or save_theory1_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/theory1_{region}_{season}.pdf\",\n",
    "                                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "execution_count": 140,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Theory relating change in $T_s(x)$ to change in $\\overline{T_s}$\n",
    "If I make the assumption of $\\Delta (z_{500} - z_s) \\approx \\frac{R\\ln 2}{2g}(\\Delta T_s + \\Delta T_{FT})$ and nothing more in a given climate, I can obtain the equation:\n",
    "\n",
    "$$(c_p - R^{\\dagger})\\Delta T_s(x) + L_v \\Delta q_s(x) \\approx (c_p + R^{\\dagger})\\Delta T_{FT}(x) + L_v \\Delta q^*_{FT}(x) + \\Delta \\epsilon(x)$$\n",
    "\n",
    "If I also take a linear taylor series, I obtain:\n",
    "\n",
    "$$\\beta_{s1}\\Delta T_s(x) + L_v \\overline{q_s^*} \\Delta r_s(x) \\approx \\beta_{FT1}\\Delta T_{FT}(x) + \\Delta \\epsilon(x)$$\n",
    "\n",
    "Below I see how good an approximation this is for $\\Delta T_s$. Both these equations do very well for summer, so it makes sense to use the latter going foreward as it is more simple."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T11:57:26.375029Z",
     "start_time": "2024-05-17T11:57:26.370721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def temp_s_anom_fit_func(temp_surf_anom, temp_surf_mean, r_surf_mean, r_surf_quant, temp_ft_mean, temp_ft_quant, epsilon_mean, epsilon_quant,\n",
    "                        pressure_surf = p_surface, pressure_ft = pressure_ft_actual):\n",
    "    R_mod = R * np.log(pressure_surf / pressure_ft) / 2\n",
    "    sphum_anom = r_surf_quant * sphum_sat(temp_surf_mean+temp_surf_anom, pressure_surf) - r_surf_mean * sphum_sat(temp_surf_mean, pressure_surf)\n",
    "    mse_mod_anom_surf = (c_p - R_mod) * temp_surf_anom + L_v * sphum_anom\n",
    "    mse_mod_anom_ft = (c_p + R_mod) * (temp_ft_quant - temp_ft_mean) + L_v * (sphum_sat(temp_ft_quant, pressure_ft) - \n",
    "                                                                              sphum_sat(temp_ft_mean, pressure_ft))\n",
    "    epsilon_anom = (epsilon_quant - epsilon_mean) * 1000\n",
    "    return mse_mod_anom_surf - mse_mod_anom_ft - epsilon_anom\n",
    "\n",
    "def get_temp_s_anom_theory(temp_surf_mean, r_surf_mean, r_surf_quant, temp_ft_mean, temp_ft_quant, epsilon_mean, epsilon_quant, \n",
    "                           pressure_surf = p_surface, pressure_ft = pressure_ft_actual, use_taylor=False):\n",
    "    if not use_taylor:\n",
    "        return scipy.optimize.fsolve(temp_s_anom_fit_func, 5, args=(temp_surf_mean, r_surf_mean, r_surf_quant, temp_ft_mean, \n",
    "                                                                    temp_ft_quant, epsilon_mean, epsilon_quant, pressure_surf, pressure_ft))\n",
    "    else:\n",
    "        epsilon_anom = (epsilon_quant - epsilon_mean) * 1000\n",
    "        r_anom = r_surf_quant - r_surf_mean\n",
    "        temp_ft_anom = temp_ft_quant - temp_ft_mean\n",
    "        \n",
    "        _, q_sat_surf, _, beta_s1, _, _ = get_theory_prefactor_terms(temp_surf_mean, pressure_surf, pressure_ft, r_surf_mean * \n",
    "                                                                                    sphum_sat(temp_surf_mean, pressure_surf))\n",
    "        _, _, _, beta_ft1, _, _ = get_theory_prefactor_terms(temp_ft_mean, pressure_surf, pressure_ft)\n",
    "        return (beta_ft1 * temp_ft_anom + epsilon_anom - L_v * q_sat_surf * r_anom) / beta_s1"
   ],
   "execution_count": 141,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T11:57:27.021945Z",
     "start_time": "2024-05-17T11:57:26.376067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "temp_s_anom_theory = {key: np.zeros((n_exp, n_lat, n_quant_all)) for key in ['just_z', 'taylor']}\n",
    "for key in temp_s_anom_theory:\n",
    "    for i in range(n_exp):\n",
    "        for j in range(n_lat):\n",
    "            for k in range(n_quant_all):\n",
    "                temp_s_anom_theory[key][i, j, k] = get_temp_s_anom_theory(temp_mean[i, ind_surf, j], r_mean[i, j], r_quant3[i, j, k], \n",
    "                                                                          temp_mean[i, ind_ft, j], temp_quant3[i, ind_ft, j, k], \n",
    "                                                                          epsilon_mean[i, j], epsilon_quant3[i, j, k], use_taylor='taylor' in key)"
   ],
   "execution_count": 142,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T11:57:27.137911Z",
     "start_time": "2024-05-17T11:57:27.023076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_temp_s_anom_fig = True\n",
    "fig, ax = plt.subplots(1,1, figsize=(width['one_col'], width['one_col']/ar), sharex=True)\n",
    "linestyles_use = ['-', ':']\n",
    "for i in range(n_exp):\n",
    "    ax.plot(quantiles_all, np.average(temp_quant3[i, ind_surf] - temp_mean[i, ind_surf][:, np.newaxis], axis=0,weights=lat_weights), \n",
    "            color='k', label='Simulated' if i==0 else None, linestyle=linestyles_use[i], lw=2, alpha=0.2)\n",
    "    for j, key in enumerate(temp_s_anom_theory):\n",
    "        ax.plot(quantiles_all, np.average(temp_s_anom_theory[key][i], axis=0,weights=lat_weights), \n",
    "                color=default_colors[j], label=f'Theory ({key})' if i==0 else None, linestyle=linestyles_use[i], lw=ax_linewidth)\n",
    "ax.legend()\n",
    "\n",
    "if save_fig or save_temp_s_anom_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/temp_s_anom_{region}_{season}.pdf\",\n",
    "                                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "execution_count": 143,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T12:08:20.845715Z",
     "start_time": "2024-05-17T12:08:20.842428Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "execution_count": 144,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
