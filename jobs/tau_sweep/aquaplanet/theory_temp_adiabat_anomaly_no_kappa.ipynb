{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Theory for $\\delta T(x)$ accounting for changes in WTG and CE\n",
    "This extends the $\\delta h(x) = \\delta \\overline{h}$ theory for the tropics with an additional term accounting for the fact that the current climate differs from convective equilibrium (CE) and constant free troposphere temperature gradient (WTG). \n",
    "\n",
    "It also quantifies the effect of changes to these two terms with warming."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import copy\n",
    "import sys\n",
    "import os\n",
    "# REMOTE - So can access functions in isca_tools which is in home/Isca directory\n",
    "# sys.path.append(os.path.join(os.environ['HOME'], 'Isca'))\n",
    "# LOCAL - So can access functions in isca_tools which is in StAndrews/Isca\n",
    "sys.path.append(os.environ['PWD'])\n",
    "import isca_tools\n",
    "from isca_tools.utils.moist_physics import moist_static_energy, clausius_clapeyron_factor, sphum_sat\n",
    "from isca_tools.utils.constants import kappa, L_v, c_p, g, R\n",
    "from isca_tools.utils import area_weighting, annual_mean\n",
    "from isca_tools.papers.byrne_2021 import get_quant_ind\n",
    "from isca_tools.thesis.adiabat_theory import (get_temp_adiabat, get_delta_mse_mod_anom_theory, get_theory_prefactor_terms,\n",
    "                                              decompose_temp_adiabat_anomaly, get_delta_temp_quant_theory, get_delta_temp_quant_theory_simple, \n",
    "                                              get_delta_temp_quant_theory_simple2)\n",
    "from isca_tools.utils.stats import z_score_from_confidence_interval\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import scipy.optimize\n",
    "from tqdm import tqdm\n",
    "from scipy import integrate\n",
    "import numpy_indexed\n",
    "from scipy.stats import percentileofscore\n",
    "import copy\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "# Use custom matplotlib style for publishing\n",
    "plt.style.use('/Users/joshduffield/Documents/StAndrews/Isca/jobs/tau_sweep/aquaplanet/publish_figures/publish.mplstyle')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:49:19.994431Z",
     "start_time": "2024-05-17T15:49:17.105796Z"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load dataset - one at surface and one in free troposphere\n",
    "var_keep = ['temp', 'sphum', 'height', 'klzbs', 'convflag']        # only keep variables required to compute relative humidity and MSE\n",
    "# var_keep = ['temp', 'sphum', 'height', 'ucomp', 'vcomp']\n",
    "# Load dataset\n",
    "tau_lw_ref = 1\n",
    "tau_lw_warm = 1.5\n",
    "exp_dir = 'tau_sweep/aquaplanet/depth=1/'\n",
    "# exp_dir = 'tau_sweep/aquaplanet/'\n",
    "exp_names = [f\"k={str(tau_lw_ref).replace('.','_')}\", f\"k={str(tau_lw_warm).replace('.','_')}\"]\n",
    "n_exp = len(exp_names)\n",
    "ds = []\n",
    "albedo = []\n",
    "tau_sw = []\n",
    "tau_lw = []\n",
    "for i in range(n_exp):\n",
    "    ds_use = isca_tools.load_dataset(exp_dir + exp_names[i])[var_keep]\n",
    "    ds += [ds_use]      # only keep the surface values\n",
    "    namelist = isca_tools.load_namelist(exp_dir + exp_names[i])  # Need this for albedo_value\n",
    "    albedo += [namelist['mixed_layer_nml']['albedo_value']]\n",
    "    tau_sw += [namelist['two_stream_gray_rad_nml']['atm_abs']]\n",
    "    tau_lw += [namelist['two_stream_gray_rad_nml']['odp']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:49:25.953980Z",
     "start_time": "2024-05-17T15:49:21.188707Z"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get datasets\n",
    "Get one surface dataset for summer for each $\\kappa$, combining all latitudes: `ds_all`. This combines the summer months in each hemisphere, e.g. negative latitudes will only correspond to times in December, January or February.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# If true, will save all figures to desktop - option to save specific figures later on.\n",
    "save_fig = False\n",
    "# if publishing figure, use high dpi\n",
    "publish_fig = True\n",
    "\n",
    "ar = 4/3        # aspect ratio (width/height)\n",
    "# Details required for Journal of Climate Figures\n",
    "low_dpi = 100\n",
    "dpi = {'monochrome': 1100, 'combination': 800, 'halftone': 300}\n",
    "width = {'one_col': 3.2, 'two_col': 5.5}        # width in inches \n",
    "save_pad_inches = 0.05\n",
    "\n",
    "# Default parameters\n",
    "default_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "ax_linewidth = plt.rcParams['axes.linewidth']\n",
    "\n",
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-17T15:49:27.189289Z",
     "start_time": "2024-05-17T15:49:27.186707Z"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Compute Global Average Surface Temperature and get near surface temperature data\n",
    "# Use all data after 2 years, as clearly converged from the above spin up plot\n",
    "use_time_start = 360*2\n",
    "pressure_ft = 500           # Desired approximate pressure of free troposphere (hPa)\n",
    "\n",
    "# Tropics\n",
    "region = 'tropics'\n",
    "lat_min = 0\n",
    "lat_max = 20\n",
    "# Extratropics\n",
    "# region = 'extratropics'\n",
    "# lat_min = 40\n",
    "# lat_max = 65\n",
    "# Poles\n",
    "# region = 'High Latitudes'\n",
    "# lat_min = 70\n",
    "# lat_max = 90\n",
    "# region = 'Global'\n",
    "# lat_min = 0\n",
    "# lat_max = 90\n",
    "\n",
    "# Chose whether to only consider summer days or consider all days\n",
    "# season = 'all'\n",
    "season = 'summer'\n",
    "# season = 'winter'\n",
    "if season == 'summer':\n",
    "    if region == 'tropics':\n",
    "        season_months = {'nh': [5, 6, 7, 8, 9, 10], 'sh': [11, 12, 1, 2, 3, 4]}   \n",
    "    else:\n",
    "        season_months = {'nh': [6, 7, 8], 'sh': [12, 1, 2]}   # JJA for NH and DJF for SH\n",
    "elif season == 'winter':\n",
    "    if region == 'tropics':\n",
    "        season_months = {'sh': [5, 6, 7, 8, 9, 10], 'nh': [11, 12, 1, 2, 3, 4]}\n",
    "    else:\n",
    "        season_months = {'sh': [6, 7, 8], 'nh': [12, 1, 2]} \n",
    "\n",
    "ds_all = []\n",
    "with tqdm(total=n_exp, position=0, leave=True) as pbar:\n",
    "    for i in range(n_exp):\n",
    "        ds_use = ds[i].sel(time=slice(use_time_start, np.inf))\n",
    "        ds_use = ds_use.sel(pfull=[np.inf, pressure_ft], method='nearest')      # only keep the surface values - get rid of pfull coordinate\n",
    "        ds_use = ds_use.where((np.abs(ds_use.lat) <= lat_max) & (np.abs(ds_use.lat) >= lat_min), drop=True)\n",
    "\n",
    "        if season == 'summer' or season == 'winter':\n",
    "            # Only consider summer as has expected circulation\n",
    "            ds_nh_summer = isca_tools.utils.annual_time_slice(ds_use, season_months['nh']).sel(lat=slice(lat_min, lat_max)) \n",
    "            ds_sh_summer = isca_tools.utils.annual_time_slice(ds_use, season_months['sh']).sel(lat=slice(-lat_max, -lat_min))  \n",
    "            # Combine hemispheres and average over longitude, time and latitude.\n",
    "            # Note that April, May, June, October, November and December will not be included in this dataset\n",
    "            ds_use = xr.concat([ds_sh_summer, ds_nh_summer], dim='lat')\n",
    "        ds_use = ds_use.stack(lon_time=(\"lon\",\"time\"), create_index=False).chunk(dict(lon_time=-1))\n",
    "        ds_all += [ds_use.load()]\n",
    "        pbar.update(1)\n",
    "\n",
    "ind_surf = 0\n",
    "ind_ft = 1\n",
    "p_surface = float(ds_all[0].pfull[ind_surf]) * 100\n",
    "pressure_ft_actual = float(ds_all[0].pfull[ind_ft]) * 100       # Actual pressure of free troposphere (Pa)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:07.187748Z",
     "start_time": "2024-05-20T09:57:40.180573Z"
    }
   },
   "execution_count": 272,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Definition of Summer\n",
    "Below I look at the months that are convecting, to deduce a good definition of summer."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:22.561562Z",
     "start_time": "2024-05-20T09:58:07.193242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# annual_mean_lat_plot = 64\n",
    "annual_mean_lat_plot = 18\n",
    "annual_mean_tau_ind = 0\n",
    "ds_annual_mean = annual_mean(ds[annual_mean_tau_ind].sel(time=slice(use_time_start, np.inf)\n",
    "                                                         ).sel(lat=[annual_mean_lat_plot, -annual_mean_lat_plot],\n",
    "                                                               method='nearest').mean(dim='lon').isel(pfull=-1)).load()\n",
    "month_ticks = (np.arange(15,12*30+15,30), ['J','F','M','A','M','J','J','A','S','O','N','D'])\n",
    "\n",
    "pressure_from_level_func = scipy.interpolate.interp1d(np.arange(len(ds[0].pfull)), ds[0].pfull)\n",
    "def lzb(k, interp_func=pressure_from_level_func):\n",
    "    # Offset by -1 because fortran starts with 1, but python starts with 0\n",
    "    # ds.t_ref will match exactly ds.temp if -2 used as offset, but this is not the LNB.\n",
    "    if np.size(k) == 1:\n",
    "        return float(interp_func(k-1))\n",
    "    else:\n",
    "        return interp_func(k-1)"
   ],
   "execution_count": 273,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:22.802774Z",
     "start_time": "2024-05-20T09:58:22.564396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_summer_def_fig = False\n",
    "\n",
    "fig, ax = plt.subplots(2,1, figsize=(width['one_col'], 2*width['one_col']/ar), sharex=True)\n",
    "ax2 = ax[1].twinx()\n",
    "for i in range(ds_annual_mean.lat.size):\n",
    "    ax[0].plot(ds_annual_mean.time-0.5, ds_annual_mean.temp[:, i], alpha=0.2 if ds_annual_mean.lat[i]<0 else 1, color='k')\n",
    "    ax[1].plot(ds_annual_mean.time-0.5, ds_annual_mean.convflag[:, i], color=default_colors[0], alpha=0.2 if ds_annual_mean.lat[i]<0 else 1)\n",
    "    ax2.plot(ds_annual_mean.time-0.5, lzb(ds_annual_mean.klzbs[:, i]), color=default_colors[1], alpha=0.2 if ds_annual_mean.lat[i]<0 else 1)\n",
    "for i in range(len(ax)):\n",
    "    if np.abs(ds_annual_mean.lat[0])>22:\n",
    "        ax[i].axvline(5*30-1, color='k', lw=ax_linewidth)\n",
    "        ax[i].axvline(8*30-1, color='k', lw=ax_linewidth)\n",
    "        ax[i].axvline(11*30-1, color='k', lw=ax_linewidth, alpha=0.2)\n",
    "        ax[i].axvline(2*30-1, color='k', lw=ax_linewidth, alpha=0.2)\n",
    "    else:\n",
    "        ax[i].axvline(4*30-1, color='k', lw=ax_linewidth)\n",
    "        ax[i].axvline(10*30-1, color='k', lw=ax_linewidth)\n",
    "ax2.axhline(pressure_ft_actual/100, color=default_colors[1], lw=ax_linewidth)\n",
    "ax2.invert_yaxis()\n",
    "ax2.spines[['left', 'bottom']].set_visible(False)\n",
    "ax2.spines[['right']].set_visible(True)\n",
    "ax2.spines[['right']].set_color(default_colors[1])\n",
    "ax[1].spines[['left']].set_color(default_colors[0])\n",
    "ax[1].set_ylabel('convflag', color=default_colors[0])\n",
    "ax2.set_ylabel('LNB [hPa]', color=default_colors[1])\n",
    "ax[0].set_ylabel('Near-surface temperature [K]')\n",
    "ax[0].set_xlim(-1,360)\n",
    "ax[0].set_xticks(*month_ticks)\n",
    "ax[0].set_title(f'$\\kappa= {tau_lw[annual_mean_tau_ind]}$; Lat = {round(float(ds_annual_mean.lat[0]))}$\\degree$')\n",
    "\n",
    "if save_fig or save_summer_def_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/summer_definition_lat={annual_mean_lat_plot}.pdf\", \n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "execution_count": 274,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Near Surface Temperature Quantile\n",
    "Get variables as a function of near-surface temperature quantile"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "quantiles_all = np.arange(1, 100)\n",
    "percentile_label = 'Temperature percentile, $x$'\n",
    "n_quant_all = len(quantiles_all)\n",
    "n_lat = len(ds_all[0].lat)\n",
    "n_pressure = ds_all[0].pfull.shape[0]\n",
    "lat_weights = np.cos(np.deg2rad(ds_all[0].lat))     # latitude area weighting is just the cosine\n",
    "\n",
    "# Days must have klzb < thresh and convflag > thresh to be considered convecting.\n",
    "klzb_thresh = 13\n",
    "convflag_thresh = 1\n",
    "\n",
    "temp_mean = np.zeros((n_exp, n_pressure, n_lat))         # second index: 0 is surface, 1 is free trop\n",
    "# 2 different methods for computing r_mean and sphum_mean - q calculates from sphum, while r calculates from rh.\n",
    "sphum_mean = {'q': np.zeros((n_exp, n_lat)), 'r': np.zeros((n_exp, n_lat))}\n",
    "r_mean = {'q': np.zeros((n_exp, n_lat)), 'r': np.zeros((n_exp, n_lat))}\n",
    "z_mean = np.zeros((n_exp, n_pressure, n_lat))\n",
    "\n",
    "lnp_const = R * np.log(p_surface/pressure_ft_actual)/2      # for modified MSE calculation\n",
    "# as function of temperature quantile\n",
    "temp_quant3 = np.zeros((n_exp, n_pressure, n_lat, n_quant_all))\n",
    "sphum_quant3 = {'q': np.zeros((n_exp, n_lat, n_quant_all)), 'r': np.zeros((n_exp, n_lat, n_quant_all))}\n",
    "r_quant3 = {'q': np.zeros((n_exp, n_lat, n_quant_all)), 'r': np.zeros((n_exp, n_lat, n_quant_all))}\n",
    "z_quant3 = np.zeros((n_exp, n_pressure, n_lat, n_quant_all))\n",
    "convflag_quant3 = np.zeros((n_exp, n_lat, n_quant_all))\n",
    "klzbs_quant3 = np.zeros((n_exp, n_lat, n_quant_all))\n",
    "convfract_quant3 = np.zeros((n_exp, n_lat, n_quant_all))            # record fraction of days convecting\n",
    "if 'ucomp' in var_keep:\n",
    "    u_mean = np.zeros((n_exp, n_lat))\n",
    "    v_mean = np.zeros((n_exp, n_lat))\n",
    "    u_quant3 = np.zeros((n_exp, n_lat, n_quant_all))\n",
    "    v_quant3 = np.zeros((n_exp, n_lat, n_quant_all))\n",
    "\n",
    "with tqdm(total=n_exp*n_lat*n_quant_all, position=0, leave=True) as pbar:\n",
    "    for i in range(n_exp):\n",
    "        temp_mean[i] = ds_all[i].temp.mean(dim='lon_time')\n",
    "        sphum_mean['q'][i] = ds_all[i].sphum.isel(pfull=ind_surf).mean(dim='lon_time')\n",
    "        z_mean[i] = ds_all[i].height.mean(dim='lon_time')\n",
    "        # Modify MSE so is one used to compute adiabatic temperature\n",
    "        # mse_mod = moist_static_energy(ds_all[i].temp[ind_surf], ds_all[i].sphum[ind_surf], height=0, c_p_const=c_p - lnp_const)\n",
    "        # mse_mod_mean['q'][i] = mse_mod.mean(dim='lon_time')\n",
    "        rh_use = ds_all[i].sphum.isel(pfull=ind_surf)/sphum_sat(ds_all[i].temp.isel(pfull=ind_surf), p_surface)\n",
    "        r_mean['r'][i] = rh_use.mean(dim='lon_time')\n",
    "        if 'ucomp' in var_keep:\n",
    "            u_mean[i] = np.abs(ds_all[i].ucomp.isel(pfull=ind_ft)).mean(dim='lon_time')\n",
    "            v_mean[i] = np.abs(ds_all[i].vcomp.isel(pfull=ind_ft)).mean(dim='lon_time')\n",
    "        if 'convflag' in var_keep:\n",
    "            is_convecting = np.logical_and(ds_all[i].klzbs<klzb_thresh, ds_all[i].convflag > convflag_thresh)\n",
    "        for k in range(n_lat):\n",
    "            for j, quant in enumerate(quantiles_all):\n",
    "                use_ind = get_quant_ind(ds_all[i].temp.isel(pfull=ind_surf)[k], quant, 0.5, 0.5)\n",
    "                sphum_quant3['q'][i, k, j] = ds_all[i].sphum.isel(pfull=ind_surf)[k, use_ind].mean()\n",
    "                z_quant3[i, :, k, j] = ds_all[i].height[:, k, use_ind].mean(dim='lon_time')\n",
    "                # mse_mod_quant3['q'][i, k, j] = mse_mod[k, use_ind].mean(dim='lon_time')\n",
    "                temp_quant3[i, :, k, j] = ds_all[i].temp[:, k, use_ind].mean(dim='lon_time')\n",
    "                r_quant3['r'][i, k, j] = rh_use[k, use_ind].mean(dim='lon_time')\n",
    "                if 'ucomp' in var_keep:\n",
    "                    u_quant3[i, k, j] = np.abs(ds_all[i].ucomp[ind_ft, k, use_ind]).mean(dim='lon_time')\n",
    "                    v_quant3[i, k, j] = np.abs(ds_all[i].vcomp[ind_ft, k, use_ind]).mean(dim='lon_time')\n",
    "                if 'convflag' in var_keep:\n",
    "                    convflag_quant3[i, k, j] = ds_all[i].convflag[k, use_ind].mean(dim='lon_time')\n",
    "                    klzbs_quant3[i, k, j] = ds_all[i].klzbs[k, use_ind].mean(dim='lon_time')\n",
    "                    convfract_quant3[i, k, j] = np.sum(is_convecting[k, use_ind])/is_convecting[k, use_ind].size\n",
    "                pbar.update(1)\n",
    "r_quant3['q'] = sphum_quant3['q'] / sphum_sat(temp_quant3[:, ind_surf], p_surface)\n",
    "r_mean['q'] = sphum_mean['q'] / sphum_sat(temp_mean[:, ind_surf], p_surface)\n",
    "sphum_quant3['r'] = sphum_sat(temp_quant3[:, ind_surf], p_surface) * r_quant3['r']\n",
    "sphum_mean['r'] = sphum_sat(temp_mean[:, ind_surf], p_surface) * r_mean['r']\n",
    "mse_mod_quant3 = {key: moist_static_energy(temp_quant3[:, ind_surf], sphum_quant3[key], height=0, c_p_const=c_p - lnp_const) for key in r_mean}\n",
    "mse_mod_mean = {key: moist_static_energy(temp_mean[:, ind_surf], sphum_mean[key], height=0, c_p_const=c_p - lnp_const) for key in r_mean}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:42.579890Z",
     "start_time": "2024-05-20T09:58:22.805168Z"
    }
   },
   "execution_count": 275,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Different RH and $q$ definitions\n",
    "Below I illustrate the difference between two definitions of specific humidity and relative humidity:\n",
    "* $q$ based: I compute the specific humidity as the mean over all days and then find mean relative humidity through: $\\overline{r_s} = \\overline{q_s}/q^*_s(\\overline{T_s})$.\n",
    "* $r$ based: I compute the relative humidity as the mean over all days (rh on a given day is $q/q^*$ still) and then find the mean specific humidity through: $\\overline{q_s} = \\overline{r_s}q^*_s(\\overline{T_s})$.\n",
    "\n",
    "The latter seems best as doesn't have problem with very large $\\overline{r_s}$."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:42.736673Z",
     "start_time": "2024-05-20T09:58:42.581560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(2,1, figsize=(width['one_col'], 2*width['one_col']/ar), sharex=True)\n",
    "linestyles_use = {'q': '-', 'r': ':'}\n",
    "for key in sphum_quant3:\n",
    "    for i in range(n_exp):\n",
    "        ax[0].plot(quantiles_all, 1000*np.average(sphum_quant3[key][i], weights=lat_weights, axis=0), \n",
    "                   color=default_colors[i], linestyle=linestyles_use[key], label=key + ' based' if i==0 else None)\n",
    "        ax[0].axhline(1000*np.average(sphum_mean[key][i], weights=lat_weights, axis=0), color=default_colors[i], linestyle=linestyles_use[key])\n",
    "        ax[1].plot(quantiles_all, 100*np.average(r_quant3[key][i], weights=lat_weights, axis=0), \n",
    "                   color=default_colors[i], linestyle=linestyles_use[key], label=f'$\\\\kappa={tau_lw[i]}$' if key=='q' else None)\n",
    "        ax[1].axhline(100*np.average(r_mean[key][i], weights=lat_weights, axis=0), color=default_colors[i], linestyle=linestyles_use[key])\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(percentile_label)\n",
    "ax[0].set_ylabel('Specific humidity [g/kg]')\n",
    "ax[1].set_ylabel('Relative humidity [%]')\n",
    "ax[0].set_xlim([0, 100])\n",
    "humid_calc = 'r'            # which method to use in rest of notebook - recommend 'r'"
   ],
   "execution_count": 276,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:42.741168Z",
     "start_time": "2024-05-20T09:58:42.737496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Max % Deviations From Mean')\n",
    "print('Temp:', 100*np.abs(np.average((temp_quant3[0, ind_surf]-temp_mean[0, ind_surf, :, np.newaxis])/temp_mean[0, ind_surf, :, np.newaxis], \n",
    "                                     axis=0, weights=lat_weights)).max())\n",
    "for key in r_quant3:\n",
    "    print(f'RH ({key}):', 100*np.abs(np.average((r_quant3[key][0]-r_mean[key][0, :, np.newaxis])/r_mean[key][0, :, np.newaxis], \n",
    "                                                axis=0, weights=lat_weights)).max())"
   ],
   "execution_count": 277,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Relating $z_{FT}$ to $T_{500}$ and $T_s$\n",
    "A crucial aspect to this theory is relating the geopotential height $z_{FT}$ to near-surface temperature $T$ and free troposphere temperature $T_{FT}$.\n",
    "\n",
    "We start with two equations, from Zhang 2023. The first combines hydrostatic balance and the ideal gas law. The second assumes a constant lapse rate, $\\Gamma$, for integration processes.\n",
    "\n",
    "$d\\ln p = -\\frac{g}{RT(p)}dz$;      $z(p) - z_s = \\frac{T_s - T(p)}{\\Gamma}$\n",
    "\n",
    "Combining the two, we get $d\\ln p = \\frac{g}{R\\Gamma}d\\ln T$.\n",
    "\n",
    "Integrating between the free troposphere at 500hPa and surface at 1000hPa, we get:\n",
    "$\\ln(\\frac{1000}{500}) = \\ln 2 = \\frac{g}{R\\Gamma}\\ln(\\frac{T_s}{T_{500}})$ or $\\frac{1}{\\Gamma} = \\frac{R\\ln 2}{g\\ln(\\frac{T_s}{T_{500}})}$\n",
    "\n",
    "We also have the $z$ equation applied at 500hPa: $z_{500} - z_s = \\frac{T_s - T_{500}}{\\Gamma}$. Combining the two, we get:\n",
    "$z_{500} - z_s \\approx \\frac{R\\ln 2(T_s - T_{500})}{g\\ln(\\frac{T_s}{T_{500}})}$\n",
    "\n",
    "We can re-write the denominator in $\\ln(1+x)$ form as $\\ln(1+\\frac{T_s-T_{500}}{T_{500}})$. Here $x=\\frac{T_s-T_{500}}{T_{500}}$ and is small. Max value in tropics is about 0.15. \n",
    "\n",
    "The taylor series is $\\frac{1}{\\ln(1+x)} \\approx \\frac{1}{x} + \\frac{1}{2} - \\frac{x}{12} + ...$. Because $x$ is small, I propose keeping just the first two terms. In which case, we get:\n",
    "\n",
    "$z_{500} - z_s \\approx \\frac{R\\ln 2(T_s - T_{500})}{g}(\\frac{T_{500}}{T_s-T_{500}} + \\frac{1}{2}) = \\frac{R\\ln 2}{2g}(T_s + T_{500})$\n",
    "\n",
    "The plots below shows that the taylor approximation is pretty accurate, and they are both decent approximations for the actual geopotential height."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_z_theory(temp_surf, temp_ft, taylor=True, pressure_surf=p_surface, pressure_ft=pressure_ft_actual):\n",
    "    lnp_prefactor = R * np.log(pressure_surf/pressure_ft) / g\n",
    "    if taylor:\n",
    "        return lnp_prefactor/2 * (temp_surf + temp_ft)\n",
    "    else:\n",
    "        return lnp_prefactor * (temp_surf - temp_ft) / np.log(temp_surf/temp_ft)\n",
    "\n",
    "z_theory_quant3 = {key: np.zeros((n_exp, n_lat, n_quant_all)) for key in ['full', 'taylor']}\n",
    "z_theory_mean = {key: np.zeros((n_exp, n_lat)) for key in ['full', 'taylor']}\n",
    "for i in range(n_exp):\n",
    "    for key in z_theory_quant3:\n",
    "        z_theory_quant3[key][i] = get_z_theory(temp_quant3[i, ind_surf], temp_quant3[i, ind_ft], True if key=='taylor' else False)\n",
    "        z_theory_mean[key][i] = get_z_theory(temp_mean[i, ind_surf], temp_mean[i, ind_ft], True if key=='taylor' else False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:42.748201Z",
     "start_time": "2024-05-20T09:58:42.741898Z"
    }
   },
   "execution_count": 278,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "save_z_ft_fig = False\n",
    "fig, ax = plt.subplots(2,1, figsize=(width['one_col'], 2*width['one_col']/ar), sharex=True)\n",
    "linestyles_use = {'full': '--', 'taylor': ':'}\n",
    "for i in range(n_exp):\n",
    "    ax[0].plot(quantiles_all, \n",
    "               np.average(z_quant3[i, ind_ft] - z_quant3[i, ind_surf], axis=0, weights=lat_weights), color=default_colors[i],\n",
    "               label=f'$\\\\tau={tau_lw[i]}$')\n",
    "    ax[0].axhline(np.average(z_mean[i, ind_ft]-z_mean[i, ind_surf], axis=0, weights=lat_weights), color=default_colors[i], lw=2, alpha=0.2)\n",
    "    for key in z_theory_quant3:\n",
    "        ax[0].plot(quantiles_all, \n",
    "                   np.average(z_theory_quant3[key][i], axis=0, weights=lat_weights), color=default_colors[i], \n",
    "                   linestyle=linestyles_use[key])\n",
    "        ax[0].axhline(np.average(z_theory_mean[key][i], axis=0, weights=lat_weights), color=default_colors[i], \n",
    "                      linestyle=linestyles_use[key], lw=2, alpha=0.2)\n",
    "ax[1].plot(quantiles_all, \n",
    "           np.average(np.diff(z_quant3[:, ind_ft] - z_quant3[:, ind_surf], axis=0)[0], axis=0, weights=lat_weights), color='k',\n",
    "           label='Simulated')\n",
    "ax[1].axhline(np.average(np.diff(z_mean[:, ind_ft]-z_mean[:, ind_surf], axis=0)[0], axis=0, weights=lat_weights), \n",
    "              color='k', lw=2, alpha=0.2)\n",
    "for key in z_theory_quant3:\n",
    "    ax[1].plot(quantiles_all, \n",
    "                   np.average(z_theory_quant3[key][1]-z_theory_quant3[key][0], axis=0, weights=lat_weights), \n",
    "               color='k', linestyle=linestyles_use[key], label=f'Theory - {key}')\n",
    "    ax[1].axhline(np.average(z_theory_mean[key][1]-z_theory_mean[key][0], axis=0, weights=lat_weights), color='k', \n",
    "                  linestyle=linestyles_use[key], lw=2, alpha=0.2)\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "ax[0].set_ylabel('$z-z_s$ [m]')\n",
    "ax[1].set_ylabel('$\\delta (z-z_s)$ [m]')\n",
    "ax[1].set_xlabel(percentile_label)\n",
    "ax[0].set_xlim(0, 100)\n",
    "if save_fig or save_z_ft_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/z_ft_approx_{region}_{season}.pdf\",\n",
    "                                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:42.904838Z",
     "start_time": "2024-05-20T09:58:42.748937Z"
    }
   },
   "execution_count": 279,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### $z$ Anomaly\n",
    "The plot below is the same as above but for the anomaly i.e. $\\Delta z = z(x) - \\overline{z}$. This is what turns up in the later equations so makes sense to plot it as well."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "save_z_ft_anom_fig = False\n",
    "fig, ax = plt.subplots(2,1, figsize=(width['one_col'], 2*width['one_col']/ar), sharex=True)\n",
    "linestyles_use = {'full': '--', 'taylor': ':'}\n",
    "for i in range(n_exp):\n",
    "    ax[0].plot(quantiles_all, \n",
    "               np.average(z_quant3[i, ind_ft] - z_quant3[i, ind_surf] - (z_mean[i, ind_ft]-z_mean[i, ind_surf])[:, np.newaxis], \n",
    "                          axis=0, weights=lat_weights), color=default_colors[i], label=f'$\\\\tau={tau_lw[i]}$')\n",
    "    for key in z_theory_quant3:\n",
    "        ax[0].plot(quantiles_all, \n",
    "                   np.average(z_theory_quant3[key][i] - z_theory_mean[key][i][:, np.newaxis], axis=0, weights=lat_weights),\n",
    "                   color=default_colors[i], linestyle=linestyles_use[key])\n",
    "ax[1].plot(quantiles_all, \n",
    "           np.average(np.diff(z_quant3[:, ind_ft] - z_quant3[:, ind_surf] - (z_mean[:, ind_ft]-z_mean[:, ind_surf])[:, :, np.newaxis],\n",
    "                              axis=0)[0], axis=0, weights=lat_weights), color='k', label='Simulated')\n",
    "for key in z_theory_quant3:\n",
    "    ax[1].plot(quantiles_all, \n",
    "                   np.average(np.diff(z_theory_quant3[key] - z_theory_mean[key][:, :, np.newaxis], axis=0)[0], \n",
    "                              axis=0, weights=lat_weights), color='k', linestyle=linestyles_use[key], label=f'Theory - {key}')\n",
    "ax[0].axhline(0, color='k', lw=ax_linewidth)\n",
    "ax[1].axhline(0, color='k', lw=ax_linewidth)\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "ax[0].set_ylabel('$\\Delta z- \\Delta z_s$ [m]')\n",
    "ax[1].set_ylabel('$\\delta (\\Delta z- \\Delta z_s)$ [m]')\n",
    "ax[1].set_xlabel(percentile_label)\n",
    "ax[0].set_xlim(0, 100)\n",
    "if save_fig or save_z_ft_anom_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/z_ft_anom_approx_{region}_{season}.pdf\",\n",
    "                                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:43.047294Z",
     "start_time": "2024-05-20T09:58:42.905713Z"
    }
   },
   "execution_count": 280,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:43.054815Z",
     "start_time": "2024-05-20T09:58:43.049708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if 'ucomp' in var_keep:\n",
    "    fig, ax = plt.subplots(2,1, figsize=(width['one_col'], 2*width['one_col']/ar), sharex=True)\n",
    "    for i in range(n_exp):\n",
    "        ax[0].plot(quantiles_all, np.average(u_quant3[i]-u_mean[i][:, np.newaxis], axis=0, weights=lat_weights), \n",
    "                   color=default_colors[i], label=f'$\\\\tau={tau_lw[i]}$')\n",
    "        ax[0].plot(quantiles_all, np.average(v_quant3[i]-v_mean[i][:, np.newaxis], axis=0, weights=lat_weights), color=default_colors[i], linestyle=':')\n",
    "    ax[1].plot(quantiles_all, np.average(np.diff(u_quant3-u_mean[:, :, np.newaxis], axis=0)[0], axis=0, weights=lat_weights), color='k',\n",
    "               label='$u$')\n",
    "    ax[1].plot(quantiles_all, np.average(np.diff(v_quant3-v_mean[:, :, np.newaxis], axis=0)[0], axis=0, weights=lat_weights), \n",
    "               color='k', linestyle=':', label='$v$')\n",
    "    ax[0].axhline(0, color='k', lw=ax_linewidth)\n",
    "    ax[1].axhline(0, color='k', lw=ax_linewidth)\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()\n",
    "    ax[0].set_ylabel('$\\Delta u$ [m]')\n",
    "    ax[1].set_ylabel('$\\delta \\Delta u$ [m]')\n",
    "    ax[1].set_xlabel(percentile_label)\n",
    "    ax[0].set_xlim(0, 100)"
   ],
   "execution_count": 281,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Adiabatic Temperature\n",
    "\n",
    "The starting point for the original theory is the assumption that $\\delta h(x) \\approx \\delta \\overline{h}$.\n",
    "\n",
    "We can define an adiabatic temperature, $T_{A, 500}$, such that the saturated free troposphere MSE is equal to the near-surface MSE:\n",
    "$h(x) = c_pT_s + L_v q + g z_s = c_p T_{A, 500} + L_vq^*(T_{A, 500}) + gz_{A, 500}$.\n",
    "\n",
    "Using the above approximation, we can sub in for $z_{A,500} - z_s \\approx \\frac{R\\ln 2}{2g}(T_s + T_{A, 500})$ to get:\n",
    "$h^{\\dagger} = (c_p - \\frac{R\\ln 2}{2})T_s + L_v q = (c_p + \\frac{R\\ln 2}{2})T_{A, 500} + L_vq^*(T_{A, 500})$ \n",
    "\n",
    "Similarly, in the mean we have $\\overline{h^{\\dagger}} = (c_p + \\frac{R\\ln 2}{2})\\overline{T_{A, 500}} + L_vq^*(\\overline{T_{A, 500}})$\n",
    "\n",
    "Where we have defined the modified moist static energy, $h^{\\dagger} = h - \\frac{R\\ln 2}{2}T - gz$\n",
    "\n",
    "Below, we solve these two equations to get estimates of $T_A(x)$ and $\\overline{T_A}$ (dropping the 500hPa indicator).\n",
    "\n",
    "The figure below is just a sanity check to ensure the equality of the two moist static energy like quantities. It also shows that $T_A$ differs from the actual free troposphere temperature. The different colours refer to the different simulations as usual."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "temp_adiabat_mean = {'q': np.zeros((n_exp, n_lat)), 'r': np.zeros((n_exp, n_lat))}\n",
    "temp_adiabat_quant3 = {'q': np.zeros((n_exp, n_lat, n_quant_all)), 'r': np.zeros((n_exp, n_lat, n_quant_all))}\n",
    "for i in range(n_exp):\n",
    "    for j in range(n_lat):\n",
    "        for key in r_mean:\n",
    "            temp_adiabat_mean[key][i, j] = get_temp_adiabat(temp_mean[i, ind_surf, j], sphum_mean[key][i, j], p_surface, pressure_ft_actual)\n",
    "            for k in range(n_quant_all):\n",
    "                temp_adiabat_quant3[key][i, j, k] = get_temp_adiabat(temp_quant3[i, ind_surf, j, k], sphum_quant3[key][i, j, k], \n",
    "                                                                     p_surface, pressure_ft_actual)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:43.671034Z",
     "start_time": "2024-05-20T09:58:43.055424Z"
    }
   },
   "execution_count": 282,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "save_mse_ft_fig = False\n",
    "fig, ax = plt.subplots(2,1, figsize=(width['one_col'], 2*width['one_col']/ar), sharex=True)\n",
    "for i in range(n_exp):\n",
    "    ax[0].plot(quantiles_all, \n",
    "            np.average(temp_quant3[i, ind_ft], axis=0, weights=lat_weights), color=default_colors[i], label='$T_{FT}$' if i==0 else None)\n",
    "    ax[0].plot(quantiles_all, \n",
    "            np.average(temp_adiabat_quant3[humid_calc][i], axis=0, weights=lat_weights), color=default_colors[i], linestyle='--', \n",
    "               label='$T_A$' if i==0 else None)\n",
    "    ax[0].axhline(np.average(temp_mean[i, ind_ft], axis=0, weights=lat_weights), color=default_colors[i], lw=ax_linewidth, alpha=0.6)\n",
    "    ax[0].axhline(np.average(temp_adiabat_mean[humid_calc][i], axis=0, weights=lat_weights), color=default_colors[i], lw=ax_linewidth, alpha=0.6,\n",
    "                  linestyle='--')\n",
    "    ax[1].plot(quantiles_all, np.average(mse_mod_quant3[humid_calc][i], axis=0, weights=lat_weights), color=default_colors[i], \n",
    "               lw=2, alpha=0.2, label='$h^{\\dagger}$' if i==0 else None)\n",
    "    ax[1].plot(quantiles_all, np.average(moist_static_energy(temp_adiabat_quant3[humid_calc][i], \n",
    "                                                             sphum_sat(temp_adiabat_quant3[humid_calc][i], pressure_ft_actual),\n",
    "                                                             height=0, c_p_const=c_p + lnp_const), axis=0, weights=lat_weights),\n",
    "               color=default_colors[i], linestyle='--', label='$(c_p + \\\\frac{R\\ln 2}{2})T_{A} + L_vq^*(T_{A})$' if i==0 else None)\n",
    "    ax[1].axhline(np.average(mse_mod_mean[humid_calc][i], axis=0, weights=lat_weights), color=default_colors[i], \n",
    "               lw=1, alpha=0.2)\n",
    "    ax[1].axhline(np.average(moist_static_energy(temp_adiabat_mean[humid_calc][i], sphum_sat(temp_adiabat_mean[humid_calc][i], pressure_ft_actual),\n",
    "                                                 height=0, c_p_const=c_p + lnp_const), axis=0, weights=lat_weights), \n",
    "                  color=default_colors[i], linestyle='--', lw=ax_linewidth)\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "ax[0].set_ylabel('Temperature [K]')\n",
    "ax[1].set_ylabel('Modified MSE [kJ/kg]')\n",
    "ax[1].set_xlabel(percentile_label)\n",
    "ax[0].set_xlim(0, 100)\n",
    "if save_fig or save_mse_ft_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/mse_ft_sat_{region}_{season}.pdf\",\n",
    "                                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:43.854727Z",
     "start_time": "2024-05-20T09:58:43.675249Z"
    }
   },
   "execution_count": 283,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extended Theory\n",
    "Doing a taylor expansion of $h^{\\dagger}(x)$ for a given simulation about $\\overline{T_A}$ we get:\n",
    "$h^{\\dagger}(x) \\approx (c_p+\\frac{R\\ln 2}{2}) \\overline{T_A} + L_v q^*(\\overline{T_A}) + (c_p + \\frac{R\\ln 2}{2} + L_v \\alpha(\\overline{T_A}) q^*(\\overline{T_A}))\\Delta T_A$\n",
    "\n",
    "Using the definition of $\\overline{h^{\\dagger}}$, this becomes:\n",
    "$h^{\\dagger}(x)-\\overline{h^{\\dagger}} \\approx (c_p + \\frac{R\\ln 2}{2} + L_v \\alpha q^*)\\Delta T_A$\n",
    "\n",
    "This is shown by the dashed lines in the top plot of the second figure below. The dotted lines include the squared term in the expansion.\n",
    "\n",
    "Taking the difference between simulations:\n",
    "$\\delta (h^{\\dagger}(x)-\\overline{h^{\\dagger}}) \\approx \\beta_1 \\delta \\Delta T_A + \\beta_2\\frac{\\Delta T_A}{\\overline{T_A}}\\delta \\overline{T_A}$\n",
    "where $\\beta_1 = \\frac{d\\overline{h^{\\dagger}}}{d\\overline{T_A}} = c_p + \\frac{R\\ln 2}{2} + L_v \\alpha q^*$ and $\\beta_2 = \\overline{T_A}\\frac{d\\beta_1}{d\\overline{T_A}} = L_v \\alpha q^*(\\alpha \\overline{T_A} - 2)$\n",
    "\n",
    "From the equation for $\\overline{h^{\\dagger}}$, we have $\\delta \\overline{T_A} \\approx \\frac{\\delta \\overline{h^{\\dagger}}}{\\beta_1}$. This is shown in the first plot below with the exact $\\delta \\overline{h^{\\dagger}}$.\n",
    "\n",
    "Combining everything, we have:\n",
    "$$\\delta (h^{\\dagger}(x)-\\overline{h^{\\dagger}}) \\approx \\beta_1 \\delta \\Delta T_A + \\frac{\\beta_2}{\\beta_1}\\frac{\\Delta T_A}{\\overline{T_A}}\\delta \\overline{h^{\\dagger}}$$\n",
    "\n",
    "This is shown by the thick red line in the bottom plot of the second figure below. The dotted red line includes squared terms in this equation. The black lines show just take the difference of the respective coloured lines in the plot above. The red dashed line should be the same as the red thick line - same equation used by different functions, really just a sanity check."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_h_anom_theory(temp_adiabat_mean, temp_adiabat_quant, p_ft = pressure_ft_actual,\n",
    "                      include_squared_term=False):\n",
    "    \"\"\"\n",
    "        Get h - h_mean theory using taylor expansion and free troposphere adiabatic temperatures.\n",
    "    Args:\n",
    "        temp_adiabat_mean: float\n",
    "        temp_adiabat_quant: [n_quant]\n",
    "        p_ft: float\n",
    "        include_squared_term: bool\n",
    "\n",
    "    Returns:\n",
    "        [n_quant]\n",
    "            MSE anomaly in kJ/kg\n",
    "    \"\"\"\n",
    "    temp_adiabat_anom = temp_adiabat_quant - temp_adiabat_mean\n",
    "    alpha_mean = clausius_clapeyron_factor(temp_adiabat_mean, p_ft)\n",
    "    q_sat_mean = sphum_sat(temp_adiabat_mean, p_ft)\n",
    "    if include_squared_term:\n",
    "        squared_term = 0.5 * L_v * alpha_mean * q_sat_mean / temp_adiabat_mean * (alpha_mean * temp_adiabat_mean - 2) * temp_adiabat_anom**2\n",
    "    else:\n",
    "        squared_term = 0\n",
    "    return ((c_p + lnp_const) * temp_adiabat_anom + L_v * q_sat_mean * alpha_mean * temp_adiabat_anom + squared_term)/1000\n",
    "\n",
    "def get_delta_temp_adiabat_mean_theory(temp_adiabat_mean, mse_surf_mean, \n",
    "                                       temp_surf_mean = None, sphum_surf_mean = None, p_ft=pressure_ft_actual, p_surface=p_surface, \n",
    "                                       include_squared_term=False):\n",
    "    \"\"\"\n",
    "    Assumes n_exp=2\n",
    "    Args:\n",
    "        temp_adiabat_mean: [n_exp]\n",
    "        kappa_mean: [n_exp]\n",
    "        mse_surf_mean: [n_exp]\n",
    "            In units of kJ/kg\n",
    "            If given, computes the exact difference in MSE surface. Otherwise, does linear expansion with temp_surf and sphum_surf.\n",
    "        temp_surf_mean: [n_exp]\n",
    "        sphum_surf_mean: [n_exp]\n",
    "        p_ft: float (Pa)\n",
    "        p_surface: float (Pa)\n",
    "        include_squared_term: bool\n",
    "            If `True`, will include squared terms in taylor expansion\n",
    "\n",
    "    Returns:\n",
    "        float\n",
    "    \"\"\"\n",
    "    if mse_surf_mean is not None:\n",
    "        delta_mse = (mse_surf_mean[1] - mse_surf_mean[0]) * 1000        # convert into units of J/kg\n",
    "    else:\n",
    "        # Do linear taylor expansion to compute delta_mse if actual value not given\n",
    "        delta_rh = float(np.diff(sphum_surf_mean / sphum_sat(temp_surf_mean, p_surface)))\n",
    "        delta_temp_surf = temp_surf_mean[1] - temp_surf_mean[0]\n",
    "        alpha_surf = clausius_clapeyron_factor(temp_surf_mean[0], p_surface)\n",
    "        q_sat_surf = sphum_sat(temp_surf_mean[0], p_surface)\n",
    "        delta_mse = (c_p + L_v * sphum_surf_mean[0] * alpha_surf) * delta_temp_surf + L_v * q_sat_surf * delta_rh\n",
    "    alpha = clausius_clapeyron_factor(temp_adiabat_mean[0], p_ft)\n",
    "    q_sat = sphum_sat(temp_adiabat_mean[0], p_ft)\n",
    "    \n",
    "    beta_1 = c_p + lnp_const + L_v * alpha * q_sat                        # this is a float\n",
    "    beta_2 = L_v * alpha * q_sat * (alpha * temp_adiabat_mean[0] - 2)   # this is a float, same units as beta\n",
    "    final_answer = delta_mse/beta_1\n",
    "    if include_squared_term:\n",
    "        final_answer = final_answer - 0.5 * beta_2/(beta_1**3 * temp_adiabat_mean[0]) * delta_mse**2\n",
    "    return final_answer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:43.860718Z",
     "start_time": "2024-05-20T09:58:43.855585Z"
    }
   },
   "execution_count": 284,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "delta_temp_adiabat_mean = {'simulated': temp_adiabat_mean[humid_calc][1]-temp_adiabat_mean[humid_calc][0], \n",
    "                           'linear': np.zeros(n_lat), 'squared': np.zeros(n_lat)}\n",
    "h_anom_theory = {'linear': np.zeros((n_exp, n_lat, n_quant_all)), 'squared': np.zeros((n_exp, n_lat, n_quant_all))}\n",
    "delta_h_anom = {'simulated': np.diff(mse_mod_quant3[humid_calc] - mse_mod_mean[humid_calc][:, :, np.newaxis], axis=0)[0], \n",
    "                'linear': np.zeros((n_lat, n_quant_all)), 'squared': np.zeros((n_lat, n_quant_all))}\n",
    "delta_h_anom_theory_prefactors = {key: np.zeros((n_lat, n_quant_all)) for key in \n",
    "                           ['temp_adiabat_anom', 'mse_mod_mean', 'mse_mod_mean_squared', 'non_linear']}\n",
    "delta_h_anom_theory_prefactors = {key: copy.deepcopy(delta_h_anom_theory_prefactors) for key in ['linear', 'squared', 'simple']}\n",
    "delta_h_anom_theory_diff = copy.deepcopy(delta_h_anom_theory_prefactors)\n",
    "delta_h_anom_theory_cont = copy.deepcopy(delta_h_anom_theory_prefactors)\n",
    "\n",
    "for j in range(n_lat):\n",
    "    for key in ['linear', 'squared']:\n",
    "        delta_temp_adiabat_mean[key][j] = \\\n",
    "            get_delta_temp_adiabat_mean_theory(temp_adiabat_mean[humid_calc][:, j], mse_mod_mean[humid_calc][:, j], \n",
    "                                               temp_mean[:, ind_surf, j], sphum_mean[humid_calc][:, j], \n",
    "                                               include_squared_term=True if key=='squared' else False)\n",
    "        delta_h_anom[key][j], info = get_delta_mse_mod_anom_theory(temp_mean[:, ind_surf, j], temp_quant3[:, ind_surf, j], sphum_mean[humid_calc][:, j],\n",
    "                                                                   sphum_quant3[humid_calc][:, j], p_surface, pressure_ft_actual, \n",
    "                                                                   taylor_terms=key)[:2]\n",
    "        for info_key in delta_h_anom_theory_prefactors['squared']:\n",
    "            delta_h_anom_theory_prefactors[key][info_key][j] = info[info_key][0]\n",
    "            delta_h_anom_theory_diff[key][info_key][j] = info[info_key][1]\n",
    "            delta_h_anom_theory_cont[key][info_key][j] = delta_h_anom_theory_prefactors[key][info_key][j] * \\\n",
    "                                                         delta_h_anom_theory_diff[key][info_key][j]\n",
    "    for i in range(n_exp):\n",
    "        for key in h_anom_theory:\n",
    "            h_anom_theory[key][i, j] = get_h_anom_theory(temp_adiabat_mean[humid_calc][i, j], temp_adiabat_quant3[humid_calc][i, j], \n",
    "                                                         include_squared_term=True if key=='squared' else False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:44.484745Z",
     "start_time": "2024-05-20T09:58:43.861778Z"
    }
   },
   "execution_count": 285,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(width['one_col'], width['one_col']/ar))\n",
    "linestyles_use = ['-', '--', ':']\n",
    "for i, key in enumerate(delta_temp_adiabat_mean):\n",
    "    ax.plot(ds_all[0].lat, delta_temp_adiabat_mean[key], color='k', label=key, linestyle=linestyles_use[i])\n",
    "    ax.axhline(np.average(delta_temp_adiabat_mean[key], weights=lat_weights, axis=0), color='k', \n",
    "               linestyle=linestyles_use[i], lw=2, alpha=0.1)\n",
    "ax.set_xlim(-lat_max, lat_max)\n",
    "ax.set_ylabel('$\\delta \\overline{T^A}$ [K]')\n",
    "ax.set_xlabel('Lat [deg]')\n",
    "ax.legend()\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:44.576602Z",
     "start_time": "2024-05-20T09:58:44.489307Z"
    }
   },
   "execution_count": 286,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below, the linear red line captures the broad trend we are after."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "save_mse_anom_fig = False\n",
    "fig, ax = plt.subplots(2,1, figsize=(width['one_col'], 2*width['one_col']/ar), sharex=True)\n",
    "for i in range(n_exp):\n",
    "    ax[0].plot(quantiles_all, \n",
    "               np.average(mse_mod_quant3[humid_calc][i] - mse_mod_mean[humid_calc][i][:, np.newaxis], axis=0, weights=lat_weights),\n",
    "               color=default_colors[i], label=f'$\\\\tau={tau_lw[i]}$')\n",
    "    ax[0].plot(quantiles_all, \n",
    "               np.average(h_anom_theory['linear'][i], axis=0, weights=lat_weights),\n",
    "               color=default_colors[i], linestyle='--')\n",
    "    ax[0].plot(quantiles_all, \n",
    "               np.average(h_anom_theory['squared'][i], axis=0, weights=lat_weights),\n",
    "               color=default_colors[i], linestyle=':')\n",
    "ax[1].plot(quantiles_all, np.average(delta_h_anom['simulated'], \n",
    "                                     axis=0, weights=lat_weights), color='k', label='Simulated')\n",
    "ax[1].plot(quantiles_all, np.average(np.diff(h_anom_theory['linear'], axis=0)[0], axis=0, weights=lat_weights), \n",
    "           color='k', linestyle='--', label='$h$ Theory: linear')\n",
    "ax[1].plot(quantiles_all, np.average(np.diff(h_anom_theory['squared'], axis=0)[0], axis=0, weights=lat_weights), \n",
    "           color='k', linestyle=':', label='$h$ Theory: squared')\n",
    "ax[1].plot(quantiles_all, np.average(delta_h_anom['linear'], axis=0, weights=lat_weights), \n",
    "           color='r', linestyle='--', label='$\\delta h$ Theory: linear')\n",
    "ax[1].plot(quantiles_all, np.average(delta_h_anom['squared'], axis=0, weights=lat_weights), \n",
    "           color='r', linestyle=':', label='$\\delta h$ Theory: squared')\n",
    "ax[0].axhline(0, color='k', lw=ax_linewidth)\n",
    "ax[1].axhline(0, color='k', lw=ax_linewidth)\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "ax[0].set_ylabel('$h^{\\dagger}-\\overline{h^{\\dagger}}$ [kJ/kg]')\n",
    "ax[1].set_ylabel('$\\delta (h^{\\dagger}-\\overline{h^{\\dagger}})$ [kJ/kg]')\n",
    "ax[1].set_xlabel(percentile_label)\n",
    "ax[0].set_xlim(0, 100)\n",
    "\n",
    "if save_fig or save_mse_anom_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/mse_anom_{region}_{season}.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:44.753947Z",
     "start_time": "2024-05-20T09:58:44.577482Z"
    }
   },
   "execution_count": 287,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Breakdown of $\\delta (h^{\\dagger}(x) - \\overline{h^{\\dagger}})$ contributions\n",
    "Below I show which terms are most important in explaining why $\\lambda \\neq 1$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "save_mse_anom_theory_decomp_fig = False\n",
    "fig, ax = plt.subplots(1,1, figsize=(width['one_col'], width['one_col']/ar), sharex=True)\n",
    "ax.plot(quantiles_all, np.average(delta_h_anom['simulated'], \n",
    "                                     axis=0, weights=lat_weights), color='k')\n",
    "ax.plot(quantiles_all, np.average(delta_h_anom['linear'], axis=0, weights=lat_weights), \n",
    "           color='k', linestyle='--')\n",
    "ax.plot(quantiles_all, np.average(delta_h_anom['squared'], axis=0, weights=lat_weights), \n",
    "           color='k', linestyle=':', alpha=0.5)\n",
    "for i, key in enumerate(delta_h_anom_theory_cont['linear']):\n",
    "    ax.plot(quantiles_all, np.average(delta_h_anom_theory_cont['linear'][key], axis=0, weights=lat_weights), \n",
    "            color=default_colors[i], label=key, linestyle='--')\n",
    "    ax.plot(quantiles_all, np.average(delta_h_anom_theory_cont['squared'][key], axis=0, weights=lat_weights), \n",
    "            color=default_colors[i], linestyle=':', alpha=0.5)\n",
    "ax.legend()\n",
    "ax.axhline(0, color='k', lw=ax_linewidth)\n",
    "ax.set_ylabel('$\\delta (h^{\\dagger}-\\overline{h^{\\dagger}})$ [kJ/kg]')\n",
    "ax.set_xlabel(percentile_label)\n",
    "ax.set_xlim(0, 100)\n",
    "\n",
    "if save_fig or save_mse_anom_theory_decomp_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/mse_anom_theory_decomp_{region}_{season}.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:44.873271Z",
     "start_time": "2024-05-20T09:58:44.754980Z"
    }
   },
   "execution_count": 288,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Climatological $\\Delta T_A$ Breakdown\n",
    "The variation in the $\\delta \\overline{h}$ contribution is caused by the variation of $\\Delta T^A(x)$ with $x$ in the current climate.\n",
    "We can decompose this into a WTG and two Convective Equilibrium (CE) terms:\n",
    "$\\Delta T_{WTG}(x) = T_{FT}(x) - \\overline{T_{FT}}$\n",
    "$\\Delta T_{CE}(x) = T_{FT}(x) - T^A_{FT}(x)$\n",
    "$\\Delta \\overline{T_{CE}} = \\overline{T_{FT}} - \\overline{T^A_{FT}}$\n",
    "\n",
    "Putting everything together, we have:\n",
    "$\\Delta T^A(x) = T^A_{FT}(x) - \\overline{T^A_{FT}} = \\Delta T_{WTG}(x) - \\Delta T_{CE}(x) + \\Delta \\overline{T_{CE}}$\n",
    "\n",
    "If WTG and CE were both valid in the current climate, then clearly $\\Delta T^A(x) = 0$ and the `mse_mean` term in the above plot would be 0.\n",
    "\n",
    "Equally, we can decompose the change in the anomaly with warming, $\\delta \\Delta T^A(x)$:\n",
    "$\\delta (\\Delta T^A(x)) = \\delta (T^A_{FT}(x) - \\overline{T^A_{FT}}) = \\delta (\\Delta T_{WTG}(x)) - \\delta(\\Delta T_{CE}(x)) + \\delta(\\Delta \\overline{T_{CE}})$\n",
    "\n",
    "In convective-quasi equilibrium, we would expect $\\delta(\\Delta T_{CE}(x)) \\approx \\delta(\\Delta \\overline{T_{CE}}) \\approx 0$. If WTG remained valid, we would expect $\\delta (\\Delta T_{WTG}(x)) \\approx 0$. Together, they would give $\\delta (\\Delta T^A(x)) \\approx 0$.\n",
    "\n",
    "It seems that WTG is pretty well satisfied, and the main trend comes from the convection part.\n",
    "If convection becomes more prevalent on all days that are not yet convecting, the climatological $\\Delta T_{CE}$ and the change $\\delta \\Delta T_{CE}$ oppose each other. This happens for small $x$.\n",
    "\n",
    "If a climate is convecting i.e. $\\Delta T_{CE} < 0$ and CAPE increases with warming i.e. $\\delta \\Delta T_{CE} < 0$ then they reinforce each other. This happens at large $x$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "temp_adiabat_anom = np.zeros((n_exp, n_lat, n_quant_all))\n",
    "temp_ce_mean_anom = np.zeros((n_exp, n_lat))\n",
    "temp_ce_quant = np.zeros((n_exp, n_lat, n_quant_all))\n",
    "temp_wtg_anom = np.zeros((n_exp, n_lat, n_quant_all))\n",
    "for j in range(n_lat):\n",
    "    temp_adiabat_anom[:, j], temp_ce_mean_anom[:, j], temp_ce_quant[:, j], temp_wtg_anom[:, j] = \\\n",
    "        decompose_temp_adiabat_anomaly(temp_mean[:, ind_surf, j], temp_quant3[:, ind_surf, j], sphum_mean[humid_calc][:, j], \n",
    "                                       sphum_quant3[humid_calc][:, j], \n",
    "                                       temp_mean[:, ind_ft, j], temp_quant3[:, ind_ft, j], p_surface, pressure_ft_actual)\n",
    "\n",
    "save_temp_adiabat_anom_fig = False\n",
    "fig, ax = plt.subplots(2,1, figsize=(width['one_col'], 2*width['one_col']/ar), sharex=True)\n",
    "linestyles_use = ['-', ':']\n",
    "alpha_use = [1, 0.3]\n",
    "for i in range(n_exp):\n",
    "    ax[0].plot(quantiles_all, np.average(temp_adiabat_anom[i], weights=lat_weights, axis=0), color='k', \n",
    "               label='$\\Delta T^A$' if i==0 else None, linestyle=linestyles_use[i], alpha=alpha_use[i])\n",
    "    ax[0].plot(quantiles_all, -np.average(temp_ce_quant[i], weights=lat_weights, axis=0), color=default_colors[0], \n",
    "               label='-$\\Delta T_{CE}$' if i==0 else None, linestyle=linestyles_use[i], alpha=alpha_use[i])\n",
    "    ax[0].plot(quantiles_all, np.average(temp_wtg_anom[i], weights=lat_weights, axis=0), color=default_colors[1], \n",
    "               label='$\\Delta T_{WTG}$' if i==0 else None, linestyle=linestyles_use[i], alpha=alpha_use[i])\n",
    "    ax[0].axhline(np.average(temp_ce_mean_anom[i], weights=lat_weights, axis=0), color=default_colors[2], \n",
    "                  label='$\\Delta \\overline{T_{CE}}$' if i==0 else None, linestyle=linestyles_use[i], alpha=alpha_use[i])\n",
    "ax[1].plot(quantiles_all, np.average(temp_adiabat_anom[1]-temp_adiabat_anom[0], weights=lat_weights, axis=0), color='k')\n",
    "ax[1].plot(quantiles_all, -np.average(temp_ce_quant[1]-temp_ce_quant[0], weights=lat_weights, axis=0), color=default_colors[0])\n",
    "ax[1].plot(quantiles_all, np.average(temp_wtg_anom[1] - temp_wtg_anom[0], weights=lat_weights, axis=0), color=default_colors[1])\n",
    "ax[1].axhline(np.average(temp_ce_mean_anom[1]-temp_ce_mean_anom[0], weights=lat_weights, axis=0), color=default_colors[2])\n",
    "ax[0].axhline(0, color='k', lw=ax_linewidth)\n",
    "ax[1].axhline(0, color='k', lw=ax_linewidth)\n",
    "ax[0].legend()\n",
    "ax[1].set_xlabel(percentile_label)\n",
    "ax[0].set_xlim(0, 100)\n",
    "ax[0].set_ylabel('Adiabatic temperature anomaly [K]', fontsize=6)\n",
    "ax[1].set_ylabel('$\\delta \\Delta T_A(x)$ [K]', fontsize=6)\n",
    "\n",
    "if save_fig or save_temp_adiabat_anom_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/temp_adiabat_anom_{region}_{season}.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:45.354370Z",
     "start_time": "2024-05-20T09:58:44.874225Z"
    }
   },
   "execution_count": 289,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below is basically a repeat of the above, but I include the prefactors in the linear $\\delta (h^{\\dagger}(x)-\\overline{h^{\\dagger}})$ theory so the actual magnitudes can be compared.\n",
    "\n",
    "In the non-linear case, you get cross terms so it doesn't make much sense."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "save_mse_anom_decomp_fig = False\n",
    "fig, ax = plt.subplots(1,1, figsize=(width['one_col'], width['one_col']/ar), sharex=True)\n",
    "ax.plot(quantiles_all, np.average(delta_h_anom_theory_cont['linear']['mse_mod_mean'], weights=lat_weights, axis=0), \n",
    "        color='k', label='$\\Delta T^A$')\n",
    "prefactor_use = delta_h_anom_theory_cont['linear']['mse_mod_mean'] / temp_adiabat_anom[0]      # [n_lat, n_quant] but same for each quant\n",
    "ax.plot(quantiles_all, -np.average(prefactor_use * temp_ce_quant[0], weights=lat_weights, axis=0), \n",
    "        color=default_colors[0], label='-$\\Delta T_{CE}$')\n",
    "ax.plot(quantiles_all, np.average(prefactor_use * temp_wtg_anom[0], weights=lat_weights, axis=0), \n",
    "        color=default_colors[1], label='$\\Delta T_{WTG}$')\n",
    "ax.axhline(np.average(prefactor_use[:, 0] * temp_ce_mean_anom[0], weights=lat_weights, axis=0), color=default_colors[2], \n",
    "           label='$\\Delta \\overline{T_{CE}}$')\n",
    "prefactor_use = delta_h_anom_theory_prefactors['linear']['temp_adiabat_anom']\n",
    "ax.plot(quantiles_all, np.average(delta_h_anom_theory_cont['linear']['temp_adiabat_anom'], weights=lat_weights, axis=0), \n",
    "        color='k', linestyle='--')\n",
    "ax.plot(quantiles_all, -np.average(prefactor_use * (temp_ce_quant[1]-temp_ce_quant[0]), weights=lat_weights, axis=0), \n",
    "        color=default_colors[0], linestyle='--')\n",
    "ax.plot(quantiles_all, np.average(prefactor_use * (temp_wtg_anom[1]-temp_wtg_anom[0]), weights=lat_weights, axis=0), \n",
    "        color=default_colors[1], linestyle='--')\n",
    "ax.axhline(np.average(prefactor_use[:, 0] * (temp_ce_mean_anom[1]-temp_ce_mean_anom[0]), weights=lat_weights, axis=0), \n",
    "           color=default_colors[2], linestyle='--')\n",
    "ax.plot(quantiles_all, np.average(delta_h_anom_theory_cont['linear']['mse_mod_mean'] + delta_h_anom_theory_cont['linear']['temp_adiabat_anom'],\n",
    "                                  weights=lat_weights, axis=0), color='r', lw=2, alpha=0.1)\n",
    "ax.plot(quantiles_all, np.average(delta_h_anom['linear'], weights=lat_weights, axis=0), color='r', alpha=0.1, label='Total')\n",
    "ax.axhline(0, color='k', lw=ax_linewidth)\n",
    "ax.legend(fontsize=5)\n",
    "ax.set_ylabel('$\\delta (h^{\\dagger}-\\overline{h^{\\dagger}})$ [kJ/kg]')\n",
    "ax.set_xlabel(percentile_label)\n",
    "ax.set_xlim(0, 100)\n",
    "\n",
    "if save_fig or save_mse_anom_decomp_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/mse_anom_decomp_{region}_{season}.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:45.473524Z",
     "start_time": "2024-05-20T09:58:45.356021Z"
    }
   },
   "execution_count": 290,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conversion between $\\Delta T_{WTG}$ and $\\Delta z$\n",
    "For the extratropics, we know WTG is not valid, so we want to consider geopotential height instead i.e. $\\Delta z = z(x) - \\overline{z}$. Below, we see how we can convert between the two terms.\n",
    "\n",
    "We can start with our equation for $z$: $z_{FT}(x) - z_s(x) \\approx \\frac{R\\ln 2}{2g}(T_s(x) + T_{FT}(x))$ and $\\overline{z_{FT}} - \\overline{z_s} \\approx \\frac{R\\ln 2}{2g}(\\overline{T_s} + \\overline{T_{FT}})$\n",
    "\n",
    "Subtracting the two, we have:\n",
    "$\\Delta z - (z_s - \\overline{z_s}) \\approx \\frac{R\\ln 2}{2g}(T_s - \\overline{T_s} + \\Delta T_{WTG})$\n",
    "\n",
    "Rearranging, we get an equation for $\\Delta T_{WTG}$:\n",
    "$\\Delta T_{WTG} \\approx \\frac{2g}{R\\ln 2}(\\Delta z - \\Delta z_s) - \\Delta T_s$\n",
    "\n",
    "Taking the difference between simulations, we get:\n",
    "$\\delta \\Delta T_{WTG} \\approx \\frac{2g}{R\\ln 2}(\\delta \\Delta z - \\delta \\Delta z_s) - \\delta \\Delta T_s$\n",
    "\n",
    "In the second plot below, we see that this theory differs quite a lot from the simulated $\\Delta T_{WTG}$. This is because of the intitial $z$ approximate equation. I.e. this plot and the $\\Delta z$ plot earlier look very similar, just shifted by the $\\Delta T_s$ term.\n",
    "\n",
    "It is clear that we can neglect the $\\Delta z_s$ terms though."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "save_wtg_fig = False\n",
    "fig, ax = plt.subplots(2,1, figsize=(width['one_col'], 2*width['one_col']/ar), sharex=True)\n",
    "scale_factor = temp_mean[0, ind_ft] / z_mean[0, ind_ft]         # to put z on same axis as temp\n",
    "for i in range(n_exp):\n",
    "    ax[0].plot(quantiles_all, np.average(temp_quant3[i, ind_ft] - temp_mean[i, ind_ft][:, np.newaxis], weights=lat_weights, axis=0),\n",
    "            color=default_colors[i], label=f'$\\\\tau={tau_lw[i]}$')\n",
    "    ax[0].plot(quantiles_all, \n",
    "            np.average(scale_factor[:, np.newaxis] * (z_quant3[i, ind_ft] - z_mean[i, ind_ft][:, np.newaxis]), \n",
    "                       weights=lat_weights, axis=0), color=default_colors[i], linestyle=':')\n",
    "ax[1].plot(quantiles_all, np.average(np.diff(temp_quant3[:, ind_ft] - temp_mean[:, ind_ft, :, np.newaxis], axis=0)[0],\n",
    "                                     weights=lat_weights, axis=0), color='k', label='$T_{FT}(x) - \\overline{T_{FT}}$')\n",
    "ax[1].plot(quantiles_all, \n",
    "           np.average(scale_factor[:, np.newaxis] * np.diff((z_quant3[:, ind_ft] - z_mean[:, ind_ft, :, np.newaxis]), axis=0)[0], \n",
    "                      weights=lat_weights, axis=0), color='k', linestyle=':', \n",
    "           label='$\\\\frac{1}{\\overline{\\kappa_{ref}}}(z_{FT}(x) - \\overline{z_{FT}})$')\n",
    "# ax[1].plot(quantiles_all, np.average(np.diff(temp_quant3[:, ind_ft] - temp_mean[:, ind_ft, np.newaxis], axis=0)[0],\n",
    "#                                      weights=lat_weights, axis=0), color='k')\n",
    "ax[0].axhline(0, color='k', lw=ax_linewidth)\n",
    "ax[1].axhline(0, color='k', lw=ax_linewidth)\n",
    "ax[0].set_ylabel('$\\Delta T_{WTG}$ [K]')\n",
    "ax[1].set_ylabel('$\\delta \\Delta T_{WTG}$ [K]')\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(percentile_label)\n",
    "ax[0].set_xlim(0, 100)\n",
    "\n",
    "if save_fig or save_wtg_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/wtg_{region}_{season}.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:45.634002Z",
     "start_time": "2024-05-20T09:58:45.474291Z"
    }
   },
   "execution_count": 291,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_temp_wtg(z_ft_mean, z_ft_quant, temp_surf_mean, temp_surf_quant, z_surf_mean, z_surf_quant = None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        z_ft_mean: float\n",
    "        z_ft_quant: [n_quant]\n",
    "        temp_surf_mean: float\n",
    "        temp_surf_quant: [n_quant]\n",
    "        z_surf_mean: float\n",
    "        z_surf_quant: [n_quant]\n",
    "            If not given, will assume no variation of z_surf with temperature percentile i.e. anomaly=0.\n",
    "\n",
    "    Returns:\n",
    "        [n_quant]\n",
    "    \"\"\"\n",
    "    z_ft_anom = z_ft_quant - z_ft_mean\n",
    "    temp_surf_anom = temp_surf_quant - temp_surf_mean\n",
    "    if z_surf_quant is None:\n",
    "        z_surf_anom = np.zeros_like(z_ft_anom)\n",
    "    else:\n",
    "        z_surf_anom = z_surf_quant - z_surf_mean\n",
    "    \n",
    "    return g/lnp_const * (z_ft_anom - z_surf_anom) - temp_surf_anom\n",
    "\n",
    "def get_delta_temp_wtg(z_ft_mean, z_ft_quant, temp_surf_mean, temp_surf_quant, z_surf_mean, z_surf_quant = None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        z_ft_mean: [n_exp]\n",
    "        z_ft_quant: [n_exp, n_quant]\n",
    "        temp_surf_mean: [n_exp]\n",
    "        temp_surf_quant: [n_exp, n_quant]\n",
    "        z_surf_mean: [n_exp]\n",
    "        z_surf_quant: [n_exp, n_quant]\n",
    "            If not given, will assume no variation of z_surf with temperature percentile i.e. anomaly=0.\n",
    "\n",
    "    Returns:\n",
    "        [n_quant]\n",
    "    \"\"\"\n",
    "    z_ft_anom = z_ft_quant - z_ft_mean[:, np.newaxis]\n",
    "    temp_surf_anom = temp_surf_quant - temp_surf_mean[:, np.newaxis]\n",
    "    if z_surf_quant is None:\n",
    "        z_surf_anom = np.zeros_like(z_ft_anom)\n",
    "    else:\n",
    "        z_surf_anom = z_surf_quant - z_surf_mean[:, np.newaxis]\n",
    "        \n",
    "    delta_z_ft_anom = z_ft_anom[1] - z_ft_anom[0]\n",
    "    delta_temp_surf_anom = temp_surf_anom[1] - temp_surf_anom[0]\n",
    "    delta_z_surf_anom = z_surf_anom[1] - z_surf_anom[0]\n",
    "    \n",
    "    return g/lnp_const * (delta_z_ft_anom - delta_z_surf_anom) - delta_temp_surf_anom\n",
    "\n",
    "temp_wtg_anom_from_z = {key: np.zeros((n_exp, n_lat, n_quant_all)) for key in ['no_z_surf', 'with_z_surf']}\n",
    "delta_temp_wtg_anom_from_z = {key: np.zeros((n_lat, n_quant_all)) for key in ['no_z_surf', 'with_z_surf']}\n",
    "\n",
    "for j in range(n_lat):\n",
    "    for key in delta_temp_wtg_anom_from_z:\n",
    "        delta_temp_wtg_anom_from_z[key][j] = get_delta_temp_wtg(z_mean[:, ind_ft, j], z_quant3[:, ind_ft, j], \n",
    "                                                                temp_mean[:, ind_surf, j], temp_quant3[:, ind_surf, j],\n",
    "                                                                z_mean[:, ind_surf, j], \n",
    "                                                                z_quant3[:, ind_surf, j] if 'with' in key else None)\n",
    "        for i in range(n_exp):\n",
    "            temp_wtg_anom_from_z[key][i, j] = get_temp_wtg(z_mean[i, ind_ft, j], z_quant3[i, ind_ft, j], \n",
    "                                                           temp_mean[i, ind_surf, j], temp_quant3[i, ind_surf, j],\n",
    "                                                           z_mean[i, ind_surf, j], z_quant3[i, ind_surf, j] if 'with' in key else None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:45.642196Z",
     "start_time": "2024-05-20T09:58:45.635140Z"
    }
   },
   "execution_count": 292,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "save_wtg_theory_fig = False\n",
    "fig, ax = plt.subplots(2,1, figsize=(width['one_col'], 2*width['one_col']/ar), sharex=True)\n",
    "for i in range(n_exp):\n",
    "    ax[0].plot(quantiles_all, np.average(temp_wtg_anom[i], weights=lat_weights, axis=0), color=default_colors[i], \n",
    "               label=f'$\\\\tau={tau_lw[i]}$', alpha=0.4, lw=2)\n",
    "    ax[0].plot(quantiles_all, np.average(temp_wtg_anom_from_z['with_z_surf'][i], weights=lat_weights, axis=0), color=default_colors[i], \n",
    "               linestyle='--')\n",
    "    ax[0].plot(quantiles_all, np.average(temp_wtg_anom_from_z['no_z_surf'][i], weights=lat_weights, axis=0), color=default_colors[i], \n",
    "               linestyle=':')\n",
    "ax[1].plot(quantiles_all, np.average(np.diff(temp_wtg_anom, axis=0)[0], weights=lat_weights, axis=0), color='k', \n",
    "           alpha=0.4, lw=2, label='Simulated')\n",
    "ax[1].plot(quantiles_all, np.average(delta_temp_wtg_anom_from_z['with_z_surf'], weights=lat_weights, axis=0),\n",
    "           color='k', linestyle='--', label='$\\Delta z_s \\\\neq 0$')\n",
    "ax[1].plot(quantiles_all, np.average(delta_temp_wtg_anom_from_z['no_z_surf'], weights=lat_weights, axis=0),\n",
    "           color='k', linestyle=':', label='$\\Delta z_s = 0$')\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "ax[0].axhline(0, color='k', lw=ax_linewidth)\n",
    "ax[1].axhline(0, color='k', lw=ax_linewidth)\n",
    "ax[1].set_xlabel(percentile_label)\n",
    "ax[0].set_xlim(0, 100)\n",
    "ax[0].set_ylabel('$\\Delta T_{WTG}$ [K]')\n",
    "ax[1].set_ylabel('$\\delta \\Delta T_{WTG}$ [K]')\n",
    "if save_fig or save_wtg_theory_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/wtg_theory_{region}_{season}.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:45.792185Z",
     "start_time": "2024-05-20T09:58:45.642958Z"
    }
   },
   "execution_count": 293,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Theory for $\\delta T_s$\n",
    "\n",
    "Next we want to substitute these two equations into the following, and put all the $\\delta T_s$ terms on the LHS. \n",
    "$\\delta (h^{\\dagger}(x)-\\overline{h^{\\dagger}}) \\approx \\beta_1 \\delta (\\Delta T_{WTG} + \\Delta \\overline{T_{CE}} - \\Delta T_{CE}) + \\frac{\\beta_2}{\\beta_1}\\frac{(\\Delta T_{WTG} + \\Delta \\overline{T_{CE}} - \\Delta T_{CE})}{\\overline{T_A}}\\delta \\overline{h^{\\dagger}}$\n",
    "\n",
    "In $\\Delta T_{WTG}$ form, we get:\n",
    "\n",
    "$\\left(c_p - \\frac{R\\ln 2}{2} + L_v\\alpha_s(x)q(x)\\right)\\delta T_s(x) + L_vq^*_s(x)\\delta r(x) \\approx \\beta_1 \\delta (\\Delta T_{WTG} + \\Delta \\overline{T_{CE}} - \\Delta T_{CE}) + \\\\\n",
    "\\left(1+\\frac{\\beta_2}{\\beta_1}\\frac{(\\Delta T_{WTG} + \\Delta \\overline{T_{CE}} - \\Delta T_{CE})}{\\overline{T_A}}\\right)\\left((c_p - \\frac{R\\ln 2}{2} + L_v\\bar{\\alpha_s}\\overline{q})\\delta \\overline{T_s} + L_v\\overline{q^*_s}\\delta \\overline{r}\\right)$\n",
    "\n",
    "In $\\Delta z$ form, we get:\n",
    "\n",
    "$\\left(c_p - \\frac{R\\ln 2}{2} + \\beta_1 + L_v\\alpha_s(x)q(x)\\right)\\delta T_s(x) + L_vq^*_s(x)\\delta r(x) \\approx \\beta_1 \\delta (\\frac{2g}{R\\ln 2}\\Delta z + \\Delta \\overline{T_{CE}} - \\Delta T_{CE}) + \\\\\n",
    "\\left(1+\\frac{\\beta_2}{\\beta_1}\\frac{(\\frac{2g}{R\\ln 2}\\Delta z - \\Delta T_s + \\Delta \\overline{T_{CE}} - \\Delta T_{CE})}{\\overline{T_A}}\\right)\\left((c_p - \\frac{R\\ln 2}{2} + L_v\\bar{\\alpha_s}\\overline{q})\\delta \\overline{T_s} + L_v\\overline{q^*_s}\\delta \\overline{r}\\right) + \\beta_1 \\delta \\overline{T_s}$\n",
    "\n",
    "We can simplify this by neglecting $\\delta \\overline{r}$ when multiplied by a $\\Delta T$ or $\\Delta z$ term. Then the theory is basically the old theory plus two additional terms. One for $\\delta \\Delta T$ and one for $\\Delta T \\delta \\overline{T}$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "delta_temp_theory = {key: np.zeros((n_lat, n_quant_all)) for key in ['wtg', 'z', 'wtg_no_rh', 'z_no_rh', 'old', 'old_no_rh', 'best', 'best_no_rh',\n",
    "                                                                     'wtg_simple', 'z_simple', 'new_wtg_q', 'new_z_q', 'new_wtg_r', 'new_z_r']}\n",
    "delta_temp_theory_prefactors = {key: np.zeros((n_lat, n_quant_all)) for key in \n",
    "                                ['temp_s_mean', 'r_mean', 'r_quant', 'temp_a','temp_s_mean_squared', 'temp_s_mean_temp_a0', 'r_mean_temp_a0',\n",
    "                                 'temp_s_mean_squared_temp_a0', 'temp_s_mean_cubed_temp_a0', 'r_mean_squared_temp_a0', \n",
    "                                 'nl_temp_s_mean_temp_a', 'nl_r_mean_temp_a', 'nl_temp_s_mean_r_mean']}\n",
    "delta_temp_theory_prefactors =  {key: copy.deepcopy(delta_temp_theory_prefactors) for key in \n",
    "                                 ['wtg', 'z', 'wtg_no_rh', 'z_no_rh', 'old', 'old_no_rh', 'wtg_simple', 'z_simple']}\n",
    "delta_temp_theory_changes = copy.deepcopy(delta_temp_theory_prefactors)\n",
    "delta_temp_theory_cont = copy.deepcopy(delta_temp_theory_prefactors)\n",
    "\n",
    "delta_temp_theory_prefactors_new = {key: np.zeros((n_lat, n_quant_all)) for key in \n",
    "                                    ['temp_s', 'humidity', 'r_change', 'temp_a_change']}\n",
    "delta_temp_theory_prefactors_new = {key: copy.deepcopy(delta_temp_theory_prefactors_new) for key in ['new_wtg_q', 'new_z_q', 'new_wtg_r', 'new_z_r']}\n",
    "delta_temp_theory_changes_new = copy.deepcopy(delta_temp_theory_prefactors_new)\n",
    "delta_temp_theory_cont_new = copy.deepcopy(delta_temp_theory_prefactors_new)\n",
    "\n",
    "for j in range(n_lat):\n",
    "    for key in delta_temp_theory:\n",
    "        if 'old' in key:\n",
    "            continue\n",
    "        if 'best' in key:\n",
    "            delta_temp_theory[key][j], _, info_coef, info_change = \\\n",
    "                get_delta_temp_quant_theory(temp_mean[:, ind_surf, j], temp_quant3[:, ind_surf, j], sphum_mean[humid_calc][:, j],\n",
    "                                            sphum_quant3[humid_calc][:, j], p_surface, pressure_ft_actual, None, None, None, None, \n",
    "                                            'squared', 'squared', 'none' if 'no_rh' in key else 'full')\n",
    "            continue\n",
    "        elif 'simple' in key:\n",
    "            if 'z' in key:\n",
    "                delta_temp_theory[key][j], _, info_coef, info_change = \\\n",
    "                    get_delta_temp_quant_theory_simple(temp_mean[:, ind_surf, j], temp_quant3[:, ind_surf, j], sphum_mean[humid_calc][:, j],\n",
    "                                                       sphum_quant3[humid_calc][:, j], p_surface, pressure_ft_actual, temp_mean[:, ind_ft, j],\n",
    "                                                       temp_quant3[:, ind_ft, j], z_mean[:, ind_ft, j], z_quant3[:, ind_ft, j])\n",
    "            elif 'wtg' in key:\n",
    "                delta_temp_theory[key][j], _, info_coef, info_change = \\\n",
    "                    get_delta_temp_quant_theory_simple(temp_mean[:, ind_surf, j], temp_quant3[:, ind_surf, j], sphum_mean[humid_calc][:, j],\n",
    "                                                       sphum_quant3[humid_calc][:, j], p_surface, pressure_ft_actual)\n",
    "        elif 'new' in key:\n",
    "            if 'z' in key:\n",
    "                delta_temp_theory[key][j], info_coef, info_change = \\\n",
    "                    get_delta_temp_quant_theory_simple2(temp_mean[:, ind_surf, j], temp_quant3[:, ind_surf, j], sphum_mean[humid_calc][:, j], \n",
    "                                                        sphum_quant3[humid_calc][:, j], p_surface, pressure_ft_actual, temp_mean[:, ind_ft, j],\n",
    "                                                        temp_quant3[:, ind_ft, j], z_mean[:, ind_ft, j], z_quant3[:, ind_ft, j], \n",
    "                                                        use_sphum_anom0='q' in key)\n",
    "            elif 'wtg' in key:\n",
    "                delta_temp_theory[key][j], info_coef, info_change = \\\n",
    "                    get_delta_temp_quant_theory_simple2(temp_mean[:, ind_surf, j], temp_quant3[:, ind_surf, j], sphum_mean[humid_calc][:, j], \n",
    "                                                        sphum_quant3[humid_calc][:, j], p_surface, pressure_ft_actual, use_sphum_anom0='q' in key)\n",
    "            for var in info_coef:\n",
    "                delta_temp_theory_prefactors_new[key][var][j] = info_coef[var]\n",
    "                delta_temp_theory_changes_new[key][var][j] = info_change[var]\n",
    "                delta_temp_theory_cont_new[key][var][j] = info_coef[var] * info_change[var]\n",
    "            continue\n",
    "        else:\n",
    "            if 'z' in key:\n",
    "                delta_temp_theory[key][j], _, info_coef, info_change = \\\n",
    "                    get_delta_temp_quant_theory(temp_mean[:, ind_surf, j], temp_quant3[:, ind_surf, j], sphum_mean[humid_calc][:, j], \n",
    "                                                sphum_quant3[humid_calc][:, j], p_surface, pressure_ft_actual, temp_mean[:, ind_ft, j], \n",
    "                                                temp_quant3[:, ind_ft, j], z_mean[:, ind_ft, j], z_quant3[:, ind_ft, j], 'linear', 'linear',\n",
    "                                                'none' if 'no_rh' in key else 'approx_anomaly', 'approx')\n",
    "            elif 'wtg' in key:\n",
    "                delta_temp_theory[key][j], delta_temp_theory[key.replace('wtg', 'old')][j], info_coef, info_change = \\\n",
    "                    get_delta_temp_quant_theory(temp_mean[:, ind_surf, j], temp_quant3[:, ind_surf, j], sphum_mean[humid_calc][:, j], \n",
    "                                                sphum_quant3[humid_calc][:, j], p_surface, pressure_ft_actual, None, None, None, None, 'linear',\n",
    "                                                'linear', 'none' if 'no_rh' in key else 'approx_anomaly', 'approx')\n",
    "        for info_key in info_coef:\n",
    "            delta_temp_theory_prefactors[key][info_key][j] = info_coef[info_key]\n",
    "            delta_temp_theory_changes[key][info_key][j] = info_change[info_key]\n",
    "            delta_temp_theory_cont[key][info_key][j] = info_coef[info_key] * info_change[info_key]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:52.352975Z",
     "start_time": "2024-05-20T09:58:45.792982Z"
    }
   },
   "execution_count": 294,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:52.413112Z",
     "start_time": "2024-05-20T09:58:52.397516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sanity check that sum of change terms is equal to total theory\n",
    "key = 'wtg'\n",
    "theory_sanity_check = 0\n",
    "for info_key in delta_temp_theory_cont[key]:\n",
    "    if 'change' not in info_key:\n",
    "        continue\n",
    "    theory_sanity_check = theory_sanity_check + delta_temp_theory_cont[key][info_key]\n",
    "np.max(np.abs(sum(delta_temp_theory_cont[key].values()) - delta_temp_theory[key]))"
   ],
   "execution_count": 295,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:52.460279Z",
     "start_time": "2024-05-20T09:58:52.414436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sanity check that simple function works same as complete function\n",
    "print('Sanity check that complete and simple functions give same result')\n",
    "for key in ['wtg', 'z']:\n",
    "    print(f\"{key} - total: {np.max(np.abs(delta_temp_theory[key] - delta_temp_theory[key+'_simple']))}\")\n",
    "    for var in ['temp_s_mean', 'r_mean', 'r_quant', 'temp_a', 'temp_s_mean_temp_a0']:\n",
    "        print(f\"{key} - {var}: {np.max(np.abs(delta_temp_theory_cont[key][var] - delta_temp_theory_cont[key+'_simple'][var]))}\")"
   ],
   "execution_count": 296,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "save_delta_temp_theory_fig = False\n",
    "fig, ax = plt.subplots(1,1, figsize=(width['one_col'], width['one_col']/ar), sharex=True)\n",
    "ax = [ax]\n",
    "ax[0].plot(quantiles_all, np.average(temp_quant3[1, ind_surf] - temp_quant3[0, ind_surf], weights=lat_weights, axis=0), \n",
    "           color='k', label='Simulated')\n",
    "# ax[0].plot(quantiles_all, np.average(delta_temp_theory['old'], weights=lat_weights, axis=0), color='r', \n",
    "#            label='Theory - Old')\n",
    "# ax[0].plot(quantiles_all, np.average(delta_temp_theory['old_no_rh'], weights=lat_weights, axis=0), color='r', \n",
    "#            linestyle=':')\n",
    "ax[0].plot(quantiles_all, np.average(delta_temp_theory['wtg'], weights=lat_weights, axis=0), color=default_colors[0], \n",
    "           label='Theory - WTG')\n",
    "ax[0].plot(quantiles_all, np.average(delta_temp_theory['z'], weights=lat_weights, axis=0), color=default_colors[1], \n",
    "           label='Theory - $z$')\n",
    "# ax[0].plot(quantiles_all, np.average(delta_temp_theory['wtg_no_rh'], weights=lat_weights, axis=0), color=default_colors[0], \n",
    "#            linestyle=':')\n",
    "# ax[0].plot(quantiles_all, np.average(delta_temp_theory['z_no_rh'], weights=lat_weights, axis=0), color=default_colors[1], \n",
    "#            linestyle=':')\n",
    "ax[0].plot(quantiles_all, np.average(delta_temp_theory['best'], weights=lat_weights, axis=0), color='green', \n",
    "           label='Theory - Best')\n",
    "# ax[0].plot(quantiles_all, np.average(delta_temp_theory['best_no_rh'], weights=lat_weights, axis=0), color='green', \n",
    "#            linestyle=':')\n",
    "ax[0].plot(quantiles_all, np.average(delta_temp_theory['new_wtg_q'], weights=lat_weights, axis=0), color='purple', \n",
    "           label='Theory - new WTG')\n",
    "ax[0].plot(quantiles_all, np.average(delta_temp_theory['new_z_q'], weights=lat_weights, axis=0), color='purple', \n",
    "           label='Theory - new $z$', linestyle='--')\n",
    "ax[0].plot(quantiles_all, np.average(delta_temp_theory['new_wtg_r'], weights=lat_weights, axis=0), color='brown', \n",
    "           label='Theory - new WTG (rh)')\n",
    "ax[0].plot(quantiles_all, np.average(delta_temp_theory['new_z_r'], weights=lat_weights, axis=0), color='brown', \n",
    "           label='Theory - new $z$ (rh)', linestyle='--')\n",
    "ax[0].set_xlabel(percentile_label)\n",
    "ax[0].set_xlim(0, 100)\n",
    "ax[0].legend()\n",
    "ax[0].set_ylabel('$\\delta T_s$')\n",
    "\n",
    "if save_fig or save_delta_temp_theory_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/delta_temp_theory_{region}_{season}.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:52.634867Z",
     "start_time": "2024-05-20T09:58:52.461468Z"
    }
   },
   "execution_count": 297,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Decompose $\\Delta T_A$ and $\\delta \\Delta T_A$ terms in $\\delta T_s(x)$ Theory\n",
    "Below I plot the contributions of $\\Delta T_A$ and $\\delta \\Delta T_A$ terms to the most simple linear theory.\n",
    "I then decompose these contributions into the more physical convective equilibrium and WTG terms."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:52.640981Z",
     "start_time": "2024-05-20T09:58:52.636565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# multiply z_anom by factor used in formula so same units as temperature\n",
    "z_ft_mod_anom = (z_quant3[:, ind_ft] - z_mean[:, ind_ft][:, :, np.newaxis]) * g / lnp_const \n",
    "delta_z_ft_mod_anom = z_ft_mod_anom[1] - z_ft_mod_anom[0]         \n",
    "delta_temp_ce_mean = temp_ce_mean_anom[1] - temp_ce_mean_anom[0]\n",
    "delta_temp_ce_quant = temp_ce_quant[1] - temp_ce_quant[0]\n",
    "delta_temp_wtg_anom = temp_wtg_anom[1] - temp_wtg_anom[0]"
   ],
   "execution_count": 298,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "save_delta_temp_theory_decomp_fig = False\n",
    "exp_plot = 'wtg'          # Note that these plots are the same for 'no_rh' experiments as rh changes excluded when multiply Delta T_A factors.\n",
    "# Get prefactor for all terms with base climate adiabatic temp anomaly\n",
    "coef_temp_a0 = sum([delta_temp_theory_cont[exp_plot][var] for var in delta_temp_theory_cont[exp_plot] if 'temp_a0' in var])/temp_adiabat_anom[0]\n",
    "fig, ax = plt.subplots(2,1, figsize=(width['one_col'], 2*width['one_col']/ar), sharex=True, sharey=True)\n",
    "ax[0].plot(quantiles_all, np.average(delta_temp_theory_cont[exp_plot]['temp_a'], weights=lat_weights, axis=0),\n",
    "           color='k', label='$\\delta \\Delta T_A$')\n",
    "ax[0].plot(quantiles_all, np.average(coef_temp_a0 * temp_adiabat_anom[0], weights=lat_weights, axis=0),\n",
    "           linestyle=':', color='k', label='$\\Delta T_A$')\n",
    "ax[0].plot(quantiles_all, np.average(delta_temp_theory_cont[exp_plot]['temp_a'] + coef_temp_a0 * temp_adiabat_anom[0], \n",
    "                                     weights=lat_weights, axis=0), lw=2, alpha=0.1, color='k', label='Sum')\n",
    "\n",
    "ax[1].plot(quantiles_all, -np.average(delta_temp_theory_prefactors[exp_plot]['temp_a'] * delta_temp_ce_quant, weights=lat_weights, axis=0),\n",
    "           color=default_colors[0], label='$T_{CE}$')\n",
    "if 'wtg' in exp_plot:\n",
    "    ax[1].plot(quantiles_all, np.average(delta_temp_theory_prefactors[exp_plot]['temp_a'] * delta_temp_wtg_anom, weights=lat_weights, axis=0),\n",
    "               color=default_colors[1], label='$\\Delta T_{FT}$')\n",
    "elif 'z' in exp_plot:\n",
    "    ax[1].plot(quantiles_all, np.average(delta_temp_theory_prefactors[exp_plot]['temp_a'] * delta_z_ft_mod_anom, weights=lat_weights, axis=0),\n",
    "               color=default_colors[1], label='$\\delta \\Delta z_{FT}$')\n",
    "ax[1].plot(quantiles_all, np.average(delta_temp_theory_prefactors[exp_plot]['temp_a'] * delta_temp_ce_mean[:, np.newaxis], \n",
    "                                     weights=lat_weights, axis=0), color=default_colors[2], label='$\\overline{T_{CE}}$')\n",
    "ax[1].plot(quantiles_all, -np.average(coef_temp_a0 * temp_ce_quant[0], weights=lat_weights, axis=0), \n",
    "           color=default_colors[0], linestyle=':')\n",
    "ax[1].plot(quantiles_all, np.average(coef_temp_a0 * temp_wtg_anom[0], weights=lat_weights, axis=0), \n",
    "           color=default_colors[1], linestyle=':', label='$\\Delta T_{FT}$' if 'z' in exp_plot else None)\n",
    "ax[1].plot(quantiles_all, np.average(coef_temp_a0 * temp_ce_mean_anom[0][:, np.newaxis], weights=lat_weights, axis=0), \n",
    "           color=default_colors[2], linestyle=':')\n",
    "ax[0].axhline(0, color='k', lw=ax_linewidth)\n",
    "ax[1].axhline(0, color='k', lw=ax_linewidth)\n",
    "\n",
    "ax[0].set_ylabel('$\\delta T_s$ [K]')\n",
    "ax[1].set_ylabel('$\\delta T_s$ [K]')\n",
    "ax[1].set_xlabel(percentile_label)\n",
    "ax[0].set_xlim(0, 100)\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "if save_fig or save_delta_temp_theory_decomp_fig:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/delta_temp_{exp_plot}_theory_decomp_{region}_{season}.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:52.949342Z",
     "start_time": "2024-05-20T09:58:52.652966Z"
    }
   },
   "execution_count": 299,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Breakdown of New Theory\n",
    "Below I plot the contributions to the scaling factor by the new theory."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:52.954378Z",
     "start_time": "2024-05-20T09:58:52.950748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for key in delta_temp_theory_cont_new:\n",
    "    delta_temp_theory_cont_new[key]['temp_ce_change'] = delta_temp_theory_prefactors_new[key]['temp_a_change'] * \\\n",
    "                                                        (delta_temp_ce_mean[:, np.newaxis] - delta_temp_ce_quant)\n",
    "    if 'z' in key:\n",
    "        delta_temp_theory_cont_new[key]['temp_ft_change'] = delta_temp_theory_prefactors_new[key]['temp_a_change'] * delta_z_ft_mod_anom\n",
    "    else:\n",
    "        delta_temp_theory_cont_new[key]['temp_ft_change'] = delta_temp_theory_prefactors_new[key]['temp_a_change'] * delta_temp_wtg_anom"
   ],
   "execution_count": 300,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:53.061183Z",
     "start_time": "2024-05-20T09:58:52.955233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "exp_new_plot = 'new_wtg_r'\n",
    "humidity_use = exp_new_plot[-1]\n",
    "colors_breakdown = {'temp_s': default_colors[3], 'humidity': default_colors[0],  \n",
    "                    'r_change': default_colors[0], 'temp_a_change': default_colors[2], \n",
    "                    'temp_ce_change': default_colors[1], 'temp_ft_change': default_colors[2]}\n",
    "linestyles_breakdown = {key: '-' for key in colors_breakdown}\n",
    "linestyles_breakdown['humidity'] = '--'\n",
    "linestyles_breakdown['temp_s'] = '--'\n",
    "# linestyles_breakdown['temp_ce_change'] = ':'\n",
    "# linestyles_breakdown['temp_ft_change'] = '--'\n",
    "labels_breakdown = {'temp_s': '$T_s$', 'humidity': f'${humidity_use}_s$', 'r_change': '$\\delta \\Delta r_s$',\n",
    "                    'temp_a_change': '$\\delta \\Delta T_A$',\n",
    "                    'temp_ce_change': '$\\delta \\Delta T_{CE}$', 'temp_ft_change': '$\\delta \\Delta T_{FT}$'}\n",
    "sf_denom = delta_temp_theory_changes_new['new_wtg_q']['temp_s']         # delta_temp_s_mean\n",
    "\n",
    "save_sf_theory_breakdown_new_fig = False\n",
    "fig, ax = plt.subplots(1,1, figsize=(width['one_col'], width['one_col']/ar), sharex=True, sharey=True)\n",
    "ax = [ax]\n",
    "ax[0].plot(quantiles_all, np.average((temp_quant3[1, ind_surf] - temp_quant3[0, ind_surf])/sf_denom, weights=lat_weights, axis=0), \n",
    "           color='k', label='Simulated')\n",
    "ax[0].plot(quantiles_all, np.average(delta_temp_theory[exp_new_plot]/sf_denom, axis=0, weights=lat_weights), color='k', linestyle='--', label='Theory')\n",
    "for key in delta_temp_theory_cont_new[exp_new_plot]:\n",
    "    if 'temp_a' in key:\n",
    "        continue\n",
    "    ax[0].plot(quantiles_all, np.average(delta_temp_theory_cont_new[exp_new_plot][key]/sf_denom, weights=lat_weights, axis=0)+1, color=colors_breakdown[key], linestyle=linestyles_breakdown[key])#, label=labels_breakdown[key])\n",
    "for i in range(len(ax)):\n",
    "    ax[i].axhline(1, color='k', lw=ax_linewidth)\n",
    "    ax[i].set_ylabel('Scaling factor, $\\delta T(x)/\\delta \\overline{T}$')\n",
    "    ax[i].legend()\n",
    "ax[0].set_xlim(0,100)\n",
    "ax[-1].set_xlabel(percentile_label)\n",
    "ax[0].set_ylim(0.8, 1.2)\n",
    "\n",
    "if save_fig or save_sf_theory_breakdown_new_fig:\n",
    "    file_name = f\"sf_breakdown_{exp_new_plot}_{region.lower()}_{season}\"\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/{file_name}.pdf\",dpi=dpi['combination'] if publish_fig else low_dpi, \n",
    "                bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "execution_count": 301,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Does Theory with $\\delta \\Delta T_{CE}(x)=0$ match a CQE theory?\n",
    "The exact scaling factor is obtained by the solution to $\\delta h_s(x) - \\delta \\overline{h_s} = \\delta h^*_{FT}(x) - \\delta \\overline{h^*_{FT}} + \\delta \\Delta \\epsilon(x)$.\n",
    "\n",
    "Here we test what happens if we assume CQE through setting $\\delta \\Delta \\epsilon(x) = 0$. We also compare this to the full theory with $\\delta \\Delta T_{CE}=0$.\n",
    "\n",
    "We see that the full theory with $\\delta \\Delta T_{CE}=0$ gives quite a different result at small $x$ than if use theoretical equation below to relate to $\\delta \\Delta \\epsilon$:\n",
    "\n",
    "$\\delta \\Delta T_{CE}(x) \\approx \\frac{\\overline{\\beta_{s1}}\\beta_{A2}}{\\beta_{A1}^3} \\frac{\\Delta \\epsilon(x)}{\\overline{T_A}}\\delta \\overline{T_s} - \\frac{\\delta \\Delta \\epsilon(x)}{\\beta_{A1}}$\n",
    "\n",
    "Orange line below assumes $\\delta \\Delta T_{CE}(x)=0$ in CQE or equivalently $\\delta \\Delta \\epsilon(x)=-\\beta_{A1}\\delta \\Delta T_{CE}(x)$.\n",
    "\n",
    "Bottom plot of figure indicates the approximation for $\\delta \\Delta \\epsilon(x)$ that is set to zero in the CQE theory. So for orange line it is $\\delta \\Delta \\epsilon(x)=-\\beta_{A1}\\delta \\Delta T_{CE}(x)$, but for green line invert full $\\delta \\Delta T_{CE}(x)$ theory so there is an extra $\\delta \\overline{T_s}$ term. For blue dashed line it is the actual $\\delta \\Delta \\epsilon$."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T09:58:54.231083Z",
     "start_time": "2024-05-20T09:58:53.062174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def scale_factor_theory_fit_func(scale_factor, temp_surf_mean, temp_surf_quant0, r_surf_mean, r_surf_quant, temp_ft_mean, temp_ft_quant, \n",
    "                                 z_surf_mean = None, z_surf_quant = None, z_ft_quant = None, z_ft_mean = None, epsilon_mean = None, \n",
    "                                 epsilon_quant = None, pressure_surf: float = p_surface, pressure_ft: float = pressure_ft_actual) -> float:\n",
    "    # Finds scaling factor such that mse_s_quant - mse_s_mean = mse_ft_quant - mse_ft_mean + epsilon_quant - epsilon_mean\n",
    "    # If z is not given, will assume z relation to temperature\n",
    "    # If epsilon_mean not given, will assume CQE i.e. no change in epsilon anomaly with warming\n",
    "    # Epsilon is in kJ/kg\n",
    "    n_exp = len(r_surf_mean)\n",
    "    temp_mean_change = temp_surf_mean[1] - temp_surf_mean[0]\n",
    "    temp_quant_hot = temp_surf_quant0 + scale_factor * temp_mean_change\n",
    "    \n",
    "    if z_surf_mean is None:\n",
    "        # Assume relation between z and temp\n",
    "        z_surf_mean = np.zeros(n_exp)\n",
    "        z_surf_quant = np.zeros(n_exp)\n",
    "        z_ft_mean = np.zeros(n_exp)\n",
    "        z_ft_quant = np.zeros(n_exp)\n",
    "        c_p_const_surf = c_p - lnp_const\n",
    "        c_p_const_ft = c_p + lnp_const\n",
    "    else:\n",
    "        c_p_const_surf = c_p\n",
    "        c_p_const_ft = c_p\n",
    "    \n",
    "    mse_surf_quant_cold = moist_static_energy(temp_surf_quant0, r_surf_quant[0] * sphum_sat(temp_surf_quant0, pressure_surf), z_surf_quant[0],\n",
    "                                              c_p_const=c_p_const_surf)\n",
    "    mse_surf_quant_hot = moist_static_energy(temp_quant_hot, r_surf_quant[1] * sphum_sat(temp_quant_hot, pressure_surf), z_surf_quant[1], \n",
    "                                             c_p_const=c_p_const_surf)\n",
    "    mse_surf_mean = [moist_static_energy(temp_surf_mean[i], r_surf_mean[i] * sphum_sat(temp_surf_mean[i], pressure_surf), z_surf_mean[i], \n",
    "                                         c_p_const=c_p_const_surf) \n",
    "                     for i in range(n_exp)]\n",
    "    mse_ft_quant = [moist_static_energy(temp_ft_quant[i], sphum_sat(temp_ft_quant[i], pressure_ft), z_ft_quant[i], c_p_const=c_p_const_ft) \n",
    "                     for i in range(n_exp)]\n",
    "    mse_ft_mean = [moist_static_energy(temp_ft_mean[i], sphum_sat(temp_ft_mean[i], pressure_ft), z_ft_mean[i], c_p_const=c_p_const_ft) \n",
    "                     for i in range(n_exp)]\n",
    "    mse_surf_quant_change = mse_surf_quant_hot - mse_surf_quant_cold\n",
    "    mse_surf_mean_change = mse_surf_mean[1] - mse_surf_mean[0]\n",
    "    mse_ft_quant_change = mse_ft_quant[1] - mse_ft_quant[0]\n",
    "    mse_ft_mean_change = mse_ft_mean[1] - mse_ft_mean[0]\n",
    "    if epsilon_mean is not None:\n",
    "        epsilon_quant_change = epsilon_quant[1] - epsilon_quant[0]\n",
    "        epsilon_mean_change = epsilon_mean[1] - epsilon_mean[0]\n",
    "    else:\n",
    "        epsilon_quant_change = 0\n",
    "        epsilon_mean_change = 0\n",
    "    return mse_surf_quant_change - mse_surf_mean_change - (mse_ft_quant_change - mse_ft_mean_change) - (epsilon_quant_change - \n",
    "                                                                                                        epsilon_mean_change)\n",
    "\n",
    "# Compute explicitly from mse_ft_sat_quant3\n",
    "mse_ft_sat_quant3 = moist_static_energy(temp_quant3[:, ind_ft], sphum_sat(temp_quant3[:, ind_ft], pressure_ft_actual), z_quant3[:, ind_ft])\n",
    "mse_ft_sat_mean = moist_static_energy(temp_mean[:, ind_ft], sphum_sat(temp_mean[:, ind_ft], pressure_ft_actual), \n",
    "                                      z_mean[:, ind_ft])\n",
    "mse_quant3 = {key: moist_static_energy(temp_quant3[:, ind_surf], sphum_quant3[key], z_quant3[:, ind_surf]) for key in r_mean}\n",
    "mse_mean = {key: moist_static_energy(temp_mean[:, ind_surf], sphum_mean[key], z_mean[:, ind_surf]) for key in r_mean}\n",
    "mse_mod_ft_quant3 = moist_static_energy(temp_quant3[:, ind_ft], sphum_sat(temp_quant3[:, ind_ft], pressure_ft_actual), height=0, \n",
    "                                        c_p_const=c_p + lnp_const)\n",
    "mse_mod_ft_mean = moist_static_energy(temp_mean[:, ind_ft], sphum_sat(temp_mean[:, ind_ft], pressure_ft_actual), height=0, c_p_const=c_p + lnp_const)\n",
    "\n",
    "epsilon_quant3 = {'no_approx':mse_quant3[humid_calc] - mse_ft_sat_quant3, 'just_z': mse_mod_quant3[humid_calc] - mse_mod_ft_quant3}\n",
    "epsilon_mean = {'no_approx': mse_mean[humid_calc] - mse_ft_sat_mean, 'just_z': mse_mod_mean[humid_calc] - mse_mod_ft_mean}\n",
    "\n",
    "_, q_sat_s_x, alpha_s_x, _, beta_s2_x, _ = get_theory_prefactor_terms(temp_quant3[0, ind_surf], p_surface, pressure_ft_actual, \n",
    "                                                                      sphum_quant3[humid_calc][0, ind_surf])\n",
    "_, q_sat_s_mean, alpha_s_mean, beta_s1, _, _ = get_theory_prefactor_terms(temp_mean[0, ind_surf], p_surface, pressure_ft_actual, \n",
    "                                                                      sphum_mean[humid_calc][0, ind_surf])\n",
    "_, _, _, beta_a1, beta_a2, _ = get_theory_prefactor_terms(temp_adiabat_mean[humid_calc][0], p_surface, pressure_ft_actual)\n",
    "\n",
    "scale_factor_cqe = {key: np.zeros((n_lat, n_quant_all)) for key in ['no_approx', 'just_z']}\n",
    "delta_temp_theory['just_z'] = np.zeros((n_lat, n_quant_all))\n",
    "for i in range(n_lat):\n",
    "    for j in range(n_quant_all):\n",
    "        scale_factor_cqe['no_approx'][i, j] = \\\n",
    "            scipy.optimize.fsolve(scale_factor_theory_fit_func, 1, \n",
    "                                  args=(temp_mean[:, ind_surf, i], temp_quant3[0, ind_surf, i, j], r_mean[humid_calc][:, i], \n",
    "                                        r_quant3[humid_calc][:, i, j], temp_mean[:, ind_ft, i], temp_quant3[:, ind_ft, i, j], z_mean[:, ind_surf, i],\n",
    "                                        z_quant3[:, ind_surf, i, j], z_mean[:, ind_ft, i], z_quant3[:, ind_ft, i, j]))\n",
    "        scale_factor_cqe['just_z'][i, j] = \\\n",
    "            scipy.optimize.fsolve(scale_factor_theory_fit_func, 1, \n",
    "                                  args=(temp_mean[:, ind_surf, i], temp_quant3[0, ind_surf, i, j], r_mean[humid_calc][:, i], \n",
    "                                        r_quant3[humid_calc][:, i, j], temp_mean[:, ind_ft, i], temp_quant3[:, ind_ft, i, j]))\n",
    "        delta_temp_theory['just_z'][i, j] = \\\n",
    "            scipy.optimize.fsolve(scale_factor_theory_fit_func, 1, \n",
    "                                  args=(temp_mean[:, ind_surf, i], temp_quant3[0, ind_surf, i, j], r_mean[humid_calc][:, i], \n",
    "                                        r_quant3[humid_calc][:, i, j], temp_mean[:, ind_ft, i], temp_quant3[:, ind_ft, i, j], \n",
    "                                        None, None, None, None, epsilon_mean['no_approx'][:, i], epsilon_quant3['no_approx'][:, i, j]))\n",
    "delta_temp_theory['just_z'] = delta_temp_theory['just_z'] * sf_denom"
   ],
   "execution_count": 302,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T15:24:56.114381Z",
     "start_time": "2024-05-20T15:24:56.090084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# theoretical epsilon change from temp_ce\n",
    "epsilon_change_theory_term1 = -beta_a1[:, np.newaxis] * np.diff(temp_ce_quant - temp_ce_mean_anom[:, :, np.newaxis], axis=0)[0] / 1000\n",
    "epsilon_change_theory_term2 = (beta_s1 * beta_a2 / (beta_a1**2 * temp_adiabat_mean[humid_calc][0])\n",
    "                             )[:, np.newaxis] * 1000*(epsilon_quant3['no_approx'][0]-epsilon_mean['no_approx'][0, :, np.newaxis]\n",
    "                                                      ) * np.diff(temp_mean[:, ind_surf], axis=0)[0, :, np.newaxis]/1000  \n",
    "\n",
    "# Theory but using epsilon rather than temp_ce\n",
    "delta_temp_theory_cont_new['wtg_epsilon_r'] = copy.deepcopy(delta_temp_theory_cont_new['new_wtg_r'])\n",
    "del delta_temp_theory_cont_new['wtg_epsilon_r']['temp_ce_change']\n",
    "delta_temp_theory_cont_new['wtg_epsilon_r']['epsilon_change'] = 1000*np.diff((epsilon_quant3['no_approx']-\n",
    "                                                                              epsilon_mean['no_approx'][:, :, np.newaxis]), axis=0\n",
    "                                                                             )[0] / beta_s1[:, np.newaxis]\n",
    "delta_temp_theory_cont_new['wtg_epsilon_r']['epsilon'] = -(beta_a2 / (beta_a1**2 * temp_adiabat_mean[humid_calc][0])\n",
    "                                                           )[:, np.newaxis] * 1000 *(epsilon_quant3['no_approx'][0] - \n",
    "                                                                                     epsilon_mean['no_approx'][0, :, np.newaxis]\n",
    "                                                                                     ) * np.diff(temp_mean[:, ind_surf], axis=0)[0, :, np.newaxis]\n",
    "delta_temp_theory['wtg_epsilon_r'] = delta_temp_theory['new_wtg_r']-\\\n",
    "                                     delta_temp_theory_cont_new['new_wtg_r']['temp_ce_change']+\\\n",
    "                                     delta_temp_theory_cont_new['wtg_epsilon_r']['epsilon_change']+\\\n",
    "                                     delta_temp_theory_cont_new['wtg_epsilon_r']['epsilon']\n",
    "\n",
    "scale_factor_cqe['no_epsilon_change'] = (delta_temp_theory['wtg_epsilon_r']-delta_temp_theory_cont_new['wtg_epsilon_r']['epsilon_change'])/sf_denom\n",
    "scale_factor_cqe['no_temp_ce_change'] = (delta_temp_theory['new_wtg_r']-delta_temp_theory_cont_new['new_wtg_r']['temp_ce_change'])/sf_denom"
   ],
   "execution_count": 337,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T15:24:57.557925Z",
     "start_time": "2024-05-20T15:24:56.518639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "_, _, _, beta_a1_hot, _, _ = get_theory_prefactor_terms(temp_adiabat_mean[humid_calc][1], p_surface, pressure_ft_actual)\n",
    "plt.plot(quantiles_all, np.average(delta_temp_theory_cont_new['new_wtg_r']['temp_ce_change'], axis=0, weights=lat_weights))\n",
    "plt.plot(quantiles_all, np.average(delta_temp_theory_cont_new['wtg_epsilon_r']['epsilon'] + \n",
    "                                   delta_temp_theory_cont_new['wtg_epsilon_r']['epsilon_change'], axis=0, weights=lat_weights))\n",
    "plt.plot(quantiles_all, np.average(1000*(epsilon_quant3['no_approx'][1]-epsilon_mean['no_approx'][1, :, np.newaxis])/beta_a1_hot[:, np.newaxis]-\n",
    "                                   1000*(epsilon_quant3['no_approx'][0]-epsilon_mean['no_approx'][0, :, np.newaxis])/beta_a1[:, np.newaxis], axis=0,\n",
    "                                   weights=lat_weights))"
   ],
   "execution_count": 338,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T15:24:57.706414Z",
     "start_time": "2024-05-20T15:24:57.560121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_sf_cqe_theories_fig = False\n",
    "fig, ax = plt.subplots(2,1, figsize=(width['one_col'], 2*width['one_col']/ar), sharex=True)\n",
    "ax[0].plot(quantiles_all, np.average((temp_quant3[1, ind_surf] - temp_quant3[0, ind_surf]) / sf_denom, weights=lat_weights, axis=0), color='k',\n",
    "           label='Simulated')\n",
    "ax[0].plot(quantiles_all, np.average(scale_factor_cqe['no_approx'], axis=0, weights=lat_weights), color=default_colors[0], \n",
    "           label='CQE', linestyle=':')\n",
    "ax[0].plot(quantiles_all, np.average(scale_factor_cqe['just_z'], axis=0, weights=lat_weights), color=default_colors[0], \n",
    "           label='CQE (z approx)')\n",
    "ax[0].plot(quantiles_all, np.average(scale_factor_cqe['no_temp_ce_change'], axis=0, weights=lat_weights), color=default_colors[1], \n",
    "           label='$\\delta \\Delta T_{CE} = 0$')\n",
    "ax[0].plot(quantiles_all, np.average(scale_factor_cqe['no_epsilon_change'], axis=0, weights=lat_weights), color=default_colors[2], \n",
    "           label='$\\delta \\Delta \\epsilon = 0$')\n",
    "for i, key in enumerate(epsilon_quant3):\n",
    "    ax[1].plot(quantiles_all, np.average(np.diff(epsilon_quant3[key] - epsilon_mean[key][:, :, np.newaxis], axis=0)[0], axis=0, weights=lat_weights),\n",
    "               color=default_colors[0], linestyle=':' if 'no_approx' in key else '-')\n",
    "ax[1].plot(quantiles_all, np.average(epsilon_change_theory_term1, axis=0, weights=lat_weights), color=default_colors[1])\n",
    "ax[1].plot(quantiles_all, np.average(epsilon_change_theory_term1+epsilon_change_theory_term2, axis=0, weights=lat_weights), color=default_colors[2])\n",
    "ax[0].axhline(1, color='k', lw=ax_linewidth)\n",
    "ax[1].axhline(0, color='k', lw=ax_linewidth)\n",
    "ax[0].set_ylabel('Scaling factor, $\\delta T(x)/\\delta \\overline{T}$')\n",
    "ax[1].set_ylabel('$\\delta \\Delta \\epsilon$ Approximation [kJ/kg]')\n",
    "ax[0].legend()\n",
    "ax[1].set_xlabel(percentile_label)\n",
    "ax[0].set_xlim(0, 100)\n",
    "\n",
    "if save_fig or save_sf_cqe_theories_fig:\n",
    "    file_name = f\"sf_cqe_theories_{region.lower()}_{season}\"\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/{file_name}.pdf\",dpi=dpi['combination'] if publish_fig else low_dpi, \n",
    "                bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "execution_count": 339,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T15:24:58.095995Z",
     "start_time": "2024-05-20T15:24:58.010149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_delta_temp_theory_fig2 = False\n",
    "fig, ax = plt.subplots(1,1, figsize=(width['one_col'], width['one_col']/ar))\n",
    "ax.plot(quantiles_all, np.average((temp_quant3[1, ind_surf] - temp_quant3[0, ind_surf]) / sf_denom, weights=lat_weights, axis=0), color='k',\n",
    "           label='Simulated')\n",
    "ax.plot(quantiles_all, np.average(delta_temp_theory['just_z'] / sf_denom, weights=lat_weights, axis=0), color=default_colors[0], \n",
    "        label='Just $z$')\n",
    "ax.plot(quantiles_all, np.average(delta_temp_theory['new_wtg_r'] / sf_denom, weights=lat_weights, axis=0), color=default_colors[1], \n",
    "        label='$\\Delta T_{CE}$ Form')\n",
    "ax.plot(quantiles_all, np.average(delta_temp_theory['wtg_epsilon_r'] / sf_denom, weights=lat_weights, axis=0), color=default_colors[2], \n",
    "        label='$\\Delta \\epsilon$ Form')\n",
    "ax.legend()\n",
    "ax.set_ylabel('Scaling factor, $\\delta T(x)/\\delta \\overline{T}$')\n",
    "ax.axhline(1, color='k', lw=ax_linewidth)\n",
    "ax.set_xlabel(percentile_label)\n",
    "ax.set_xlim(0, 100)\n",
    "\n",
    "if save_fig or save_delta_temp_theory_fig2:\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/delta_temp_theory2_{region}_{season}.pdf\",\n",
    "                dpi=dpi['combination'] if publish_fig else low_dpi, bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "execution_count": 340,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T15:28:41.566885Z",
     "start_time": "2024-05-20T15:28:41.289018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "exp_new_plot = 'wtg_epsilon_r'\n",
    "colors_breakdown['epsilon'] = colors_breakdown['temp_ce_change']\n",
    "colors_breakdown['epsilon_change'] = colors_breakdown['temp_ce_change']\n",
    "linestyles_breakdown['epsilon'] = '--'\n",
    "linestyles_breakdown['epsilon_change'] = '-'\n",
    "\n",
    "save_sf_theory_breakdown_new_fig2 = True\n",
    "fig, ax = plt.subplots(1,1, figsize=(width['one_col'], width['one_col']/ar), sharex=True, sharey=True)\n",
    "ax = [ax]\n",
    "ax[0].plot(quantiles_all, np.average((temp_quant3[1, ind_surf] - temp_quant3[0, ind_surf])/sf_denom, weights=lat_weights, axis=0), \n",
    "           color='k', label='Simulated')\n",
    "ax[0].plot(quantiles_all, np.average(delta_temp_theory[exp_new_plot]/sf_denom, axis=0, weights=lat_weights), color='k', \n",
    "           linestyle=':', label='Theory')\n",
    "for key in delta_temp_theory_cont_new[exp_new_plot]:\n",
    "    if 'temp_a' in key:\n",
    "        continue\n",
    "    if 'epsilon' in key:\n",
    "        continue\n",
    "    # if key not in ['temp_s', 'humidity', 'r_change', 'temp_ft_change']:\n",
    "    #     continue\n",
    "    ax[0].plot(quantiles_all, np.average(delta_temp_theory_cont_new[exp_new_plot][key]/sf_denom, weights=lat_weights, axis=0)+1,\n",
    "               color=colors_breakdown[key], linestyle=linestyles_breakdown[key], alpha=1 if 'epsilon' in key else 0.2)\n",
    "for i in range(len(ax)):\n",
    "    ax[i].axhline(1, color='k', lw=ax_linewidth)\n",
    "    ax[i].set_ylabel('Scaling factor, $\\delta T(x)/\\delta \\overline{T}$')\n",
    "    ax[i].legend(loc='upper right')\n",
    "ax[0].set_xlim(0,100)\n",
    "ax[-1].set_xlabel(percentile_label)\n",
    "ax[0].set_ylim(0.92, 1.18)\n",
    "\n",
    "if save_fig or save_sf_theory_breakdown_new_fig2:\n",
    "    file_name = f\"sf_breakdown_{exp_new_plot}_{region.lower()}_{season}\"\n",
    "    fig.savefig(f\"/Users/joshduffield/Desktop/{file_name}.pdf\",dpi=dpi['combination'] if publish_fig else low_dpi, \n",
    "                bbox_inches='tight', pad_inches=save_pad_inches)"
   ],
   "execution_count": 344,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:42:56.958640Z",
     "start_time": "2024-05-21T15:42:56.956210Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "execution_count": 349,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
